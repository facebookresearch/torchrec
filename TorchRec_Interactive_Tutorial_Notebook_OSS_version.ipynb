{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBgIy9eYYx35",
        "language": "markdown",
        "originalKey": "4766a371-bf6e-4342-98fb-16dde5255d73",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## **Open Source Installation** (For Reference)\n",
        "Requirements:\n",
        "- python >= 3.9\n",
        "\n",
        "We highly recommend CUDA when using TorchRec. If using CUDA:\n",
        "- cuda >= 11.8\n",
        "\n",
        "Installing TorchRec will also install [FBGEMM](https://github.com/pytorch/fbgemm), a collection of CUDA kernels and GPU enabled operations to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "customOutput": null,
        "executionStartTime": 1726000131275,
        "executionStopTime": 1726000131459,
        "id": "sFYvP95xaAER",
        "language": "python",
        "originalKey": "27d22c43-9299-46ec-94f2-28a880546fe3",
        "outputsInitialized": true,
        "requestMsgId": "27d22c43-9299-46ec-94f2-28a880546fe3",
        "serverExecutionDuration": 2.2683702409267
      },
      "outputs": [],
      "source": [
        "!pip3 install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121 -U\n",
        "!pip3 install fbgemm_gpu --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "!pip3 install torchmetrics==1.0.3\n",
        "!pip3 install torchrec --index-url https://download.pytorch.org/whl/nightly/cu121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4DFtQNDYao1",
        "language": "markdown",
        "originalKey": "07e2a5ae-9ca2-45d7-af10-84d8e09ce91e",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "# Intro to TorchRec\n",
        "\n",
        "### Embeddings\n",
        "When building recommendation systems, categorical features typically have massive cardinalities, posts, users, ads, etc.\n",
        "\n",
        "In order to represent these entities and model these relationships, **embeddings** are used. In machine learning, **embeddings are a vectors of real numbers in a high-dimensional space used to represent meaning in complex data like words, images, or users**.\n",
        "\n",
        "\n",
        "### Embeddings in RecSys\n",
        "\n",
        "Now you might wonder, how are these embeddings generated in the first place? Well, embeddings are represented as individual rows in an **Embedding Table**, also referred to as embedding weights. The reason for this is that embeddings/embedding table weights are trained just like all of the other weights of the model via gradient descent!\n",
        "\n",
        "Embedding tables are simply a large matrix for storing embeddings, with two dimensions (B, N), where\n",
        "* B is the number of embeddings stored by the table\n",
        "* N is the number of dimensions per embedding (N-dimensional embedding).\n",
        "\n",
        "\n",
        "The inputs to embedding tables represent embedding lookups to retrieve the embedding for a specific index/row. In recommendation systems, such as those used in Meta, unique IDs are not only used for specific users, but also across entites like posts and ads to serve as lookup indices to respective embedding tables!\n",
        "\n",
        "Embeddings are trained in RecSys through the following process:\n",
        "1. **Input/lookup indices are fed into the model, as unique IDs**. IDs are hashed to the total size of the embedding table to prevent issues when the ID > # of rows\n",
        "2. Embeddings are then retrieved and **pooled, such as taking the sum or mean of the embeddings**. This is required as there can be a variable # of embeddings per example while the model expects consistent shapes.\n",
        "3. The **embeddings are used in conjunction with the rest of the model to produce a prediction**, such as [Click-Through Rate (CTR)](https://support.google.com/google-ads/answer/2615875?hl=en) for an Ad.\n",
        "4. The loss is calculated with the prediction and the label for an example, and **all weights of the model are updated through gradient descent and backpropogation, including the embedding weights** that were associated with the example.\n",
        "\n",
        "These embeddings are crucial for representing categorical features, such as users, posts, and ads, in order to capture relationships and make good recommendations. Meta AI's [Deep learning recommendation model](https://arxiv.org/abs/1906.00091) (DLRM) paper talks more about the technical details of using embedding tables in RecSys.\n",
        "\n",
        "This tutorial will introduce the concept of embeddings, showcase TorchRec specific modules/datatypes, and depict how distributed training works with TorchRec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000131464,
        "executionStopTime": 1726000133971,
        "id": "AbeT4W9xcso9",
        "language": "python",
        "originalKey": "48b50971-aeab-4754-8cff-986496689f43",
        "output": {
          "id": 1222542955741095,
          "loadingStatus": "loaded"
        },
        "outputsInitialized": true,
        "requestMsgId": "48b50971-aeab-4754-8cff-986496689f43",
        "serverExecutionDuration": 2349.9959111214,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0918 202025.568 _utils_internal.py:314] NCCL_DEBUG env var is set to None\n",
            "I0918 202025.571 _utils_internal.py:323] NCCL_DEBUG is INFO from /etc/nccl.conf\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "bjuDdEqocso-",
        "language": "markdown",
        "originalKey": "4b510f99-840d-4986-b635-33c21af48cf4",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## Embeddings in PyTorch\n",
        "[`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html): Embedding table where forward pass returns the embeddings themselves as is.\n",
        "\n",
        "[`torch.nn.EmbeddingBag`](https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html): Embedding table where forward pass returns embeddings that are then pooled, i.e. sum or mean. Otherwise known as **Pooled Embeddings**\n",
        "\n",
        "In this section, we will go over a very brief introduction with doing embedding lookups through passing in indices into the table. Check out the links for each for more sophisticated use cases and experiments!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000133982,
        "executionStopTime": 1726000134201,
        "id": "1X5C_Dnccso-",
        "language": "python",
        "originalKey": "06ebfce4-bc22-4f5a-97d7-7a8f5d8ac375",
        "output": {
          "id": 528413836225076,
          "loadingStatus": "loaded"
        },
        "outputId": "6ee71ccd-7857-4e20-d047-6a02e460f47a",
        "outputsInitialized": true,
        "requestMsgId": "06ebfce4-bc22-4f5a-97d7-7a8f5d8ac375",
        "serverExecutionDuration": 31.60185739398,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights: tensor([[0.6269, 0.3844, 0.3567, 0.2157],\n",
            "        [0.1389, 0.4360, 0.5552, 0.1743],\n",
            "        [0.7882, 0.6698, 0.5491, 0.7563],\n",
            "        [0.2951, 0.1978, 0.1244, 0.5379],\n",
            "        [0.0659, 0.5433, 0.4665, 0.8800],\n",
            "        [0.9593, 0.1084, 0.5537, 0.6705],\n",
            "        [0.5422, 0.8178, 0.1714, 0.2302],\n",
            "        [0.0637, 0.1407, 0.3465, 0.3193],\n",
            "        [0.4163, 0.1239, 0.6150, 0.0990],\n",
            "        [0.6188, 0.5297, 0.2801, 0.1449]])\n"
          ]
        }
      ],
      "source": [
        "num_embeddings, embedding_dim = 10, 4\n",
        "\n",
        "# Initialize our embedding table\n",
        "weights = torch.rand(num_embeddings, embedding_dim)\n",
        "print(\"Weights:\", weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000134203,
        "executionStopTime": 1726000134366,
        "id": "bxszzeGdcso-",
        "language": "python",
        "originalKey": "b2f21375-8d36-487f-b0c3-ff8a5df950a4",
        "output": {
          "id": 1225309662083850,
          "loadingStatus": "loaded"
        },
        "outputId": "a91d8d5e-c8f1-45f5-dbac-83c56c639e17",
        "outputsInitialized": true,
        "requestMsgId": "b2f21375-8d36-487f-b0c3-ff8a5df950a4",
        "serverExecutionDuration": 8.956927806139,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Collection Table:  Parameter containing:\n",
            "tensor([[0.6269, 0.3844, 0.3567, 0.2157],\n",
            "        [0.1389, 0.4360, 0.5552, 0.1743],\n",
            "        [0.7882, 0.6698, 0.5491, 0.7563],\n",
            "        [0.2951, 0.1978, 0.1244, 0.5379],\n",
            "        [0.0659, 0.5433, 0.4665, 0.8800],\n",
            "        [0.9593, 0.1084, 0.5537, 0.6705],\n",
            "        [0.5422, 0.8178, 0.1714, 0.2302],\n",
            "        [0.0637, 0.1407, 0.3465, 0.3193],\n",
            "        [0.4163, 0.1239, 0.6150, 0.0990],\n",
            "        [0.6188, 0.5297, 0.2801, 0.1449]], requires_grad=True)\n",
            "Embedding Bag Collection Table:  Parameter containing:\n",
            "tensor([[0.6269, 0.3844, 0.3567, 0.2157],\n",
            "        [0.1389, 0.4360, 0.5552, 0.1743],\n",
            "        [0.7882, 0.6698, 0.5491, 0.7563],\n",
            "        [0.2951, 0.1978, 0.1244, 0.5379],\n",
            "        [0.0659, 0.5433, 0.4665, 0.8800],\n",
            "        [0.9593, 0.1084, 0.5537, 0.6705],\n",
            "        [0.5422, 0.8178, 0.1714, 0.2302],\n",
            "        [0.0637, 0.1407, 0.3465, 0.3193],\n",
            "        [0.4163, 0.1239, 0.6150, 0.0990],\n",
            "        [0.6188, 0.5297, 0.2801, 0.1449]], requires_grad=True)\n",
            "Input row IDS:  tensor([[1, 3]])\n"
          ]
        }
      ],
      "source": [
        "# Pass in pre generated weights just for example, typically weights are randomly initialized\n",
        "embedding_collection = torch.nn.Embedding(\n",
        "    num_embeddings, embedding_dim, _weight=weights\n",
        ")\n",
        "embedding_bag_collection = torch.nn.EmbeddingBag(\n",
        "    num_embeddings, embedding_dim, _weight=weights\n",
        ")\n",
        "\n",
        "# Print out the tables, we should see the same weights as above\n",
        "print(\"Embedding Collection Table: \", embedding_collection.weight)\n",
        "print(\"Embedding Bag Collection Table: \", embedding_bag_collection.weight)\n",
        "\n",
        "# Lookup rows (ids for embedding ids) from the embedding tables\n",
        "# 2D tensor with shape (batch_size, ids for each batch)\n",
        "ids = torch.tensor([[1, 3]])\n",
        "print(\"Input row IDS: \", ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000134369,
        "executionStopTime": 1726000134545,
        "id": "xkedJeTOcso_",
        "language": "python",
        "originalKey": "cb5c5906-e9a6-4315-b860-b263e08989be",
        "output": {
          "id": 535238395656174,
          "loadingStatus": "loaded"
        },
        "outputId": "5f77e32a-563c-47f2-855e-d6c0818acadb",
        "outputsInitialized": true,
        "requestMsgId": "cb5c5906-e9a6-4315-b860-b263e08989be",
        "serverExecutionDuration": 5.9817284345627,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Collection Results: \n",
            "tensor([[[0.1389, 0.4360, 0.5552, 0.1743],\n",
            "         [0.2951, 0.1978, 0.1244, 0.5379]]], grad_fn=<EmbeddingBackward0>)\n",
            "Shape:  torch.Size([1, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "embeddings = embedding_collection(ids)\n",
        "\n",
        "# Print out the embedding lookups\n",
        "# You should see the specific embeddings be the same as the rows (ids) of the embedding tables above\n",
        "print(\"Embedding Collection Results: \")\n",
        "print(embeddings)\n",
        "print(\"Shape: \", embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000134547,
        "executionStopTime": 1726000134718,
        "id": "PmtJkxLccso_",
        "language": "python",
        "originalKey": "a8e90b32-7c30-41f2-a5b9-bedf2b196e7f",
        "output": {
          "id": 1471525710208374,
          "loadingStatus": "loaded"
        },
        "outputId": "5ca1b383-1c6a-4b32-91e3-ef3735821452",
        "outputsInitialized": true,
        "requestMsgId": "a8e90b32-7c30-41f2-a5b9-bedf2b196e7f",
        "serverExecutionDuration": 7.8675262629986,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Bag Collection Results: \n",
            "tensor([[0.2170, 0.3169, 0.3398, 0.3561]], grad_fn=<EmbeddingBagBackward0>)\n",
            "Shape:  torch.Size([1, 4])\n",
            "Mean:  tensor([[0.2170, 0.3169, 0.3398, 0.3561]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# nn.EmbeddingBag default pooling is mean, so should be mean of batch dimension of values above\n",
        "pooled_embeddings = embedding_bag_collection(ids)\n",
        "\n",
        "print(\"Embedding Bag Collection Results: \")\n",
        "print(pooled_embeddings)\n",
        "print(\"Shape: \", pooled_embeddings.shape)\n",
        "\n",
        "# nn.EmbeddingBag is the same as nn.Embedding but just with pooling (mean, sum, etc.)\n",
        "# We can see that the mean of the embeddings of embedding_collection is the same as the output of the embedding_bag_collection\n",
        "print(\"Mean: \", torch.mean(embedding_collection(ids), dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "SuCV1cJ8cso_",
        "language": "markdown",
        "originalKey": "4643305e-2770-40cf-afc6-e64cd3f51063",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "Congratulations! Now you have a basic understanding on how to use embedding tables --- one of the foundations of modern recommendation systems! These tables represent entities and their relationships. For example, the relationship between a given user and the pages & posts they have liked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "QIuAYSZ5cso_",
        "language": "markdown",
        "originalKey": "7dfcffeb-c7c0-4d74-9dba-569c1d882898",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "# TorchRec\n",
        "\n",
        "Now you know how to use embedding tables, one of the foundations of modern recommendation systems! These tables represent entities and relationships, such as users, pages, posts, etc. Given that these entities are always increasing, a **hash** function is typically applied to make sure the ids are within the bounds of a certain embedding table. However, in order to represent a vast amount of entities and reduce hash collisions, these tables can become quite massive (think about # of ads for example). In fact, these tables can become so massive that they won't be able to fit on 1 GPU, even with 80G of memory!\n",
        "\n",
        "In order to train models with massive embedding tables, sharding these tables across GPUs is required, which then introduces a whole new set of problems/opportunities in parallelism and optimization. Luckily, we have the TorchRec library that has encountered, consolidated, and addressed many of these concerns. TorchRec serves as a **library that provides primitives for large scale distributed embeddings**.\n",
        "\n",
        "From here on out, we will explore the major features of the TorchRec library. We will start with torch.nn.Embedding and will extend that to custom TorchRec modules, explore distributed training environment with generating a sharding plan for embeddings, look at inherent TorchRec optimizations, and extend the model to be ready for inference in C++. Below is a quick outline of what the journey will consist of - buckle in!\n",
        "\n",
        "1. TorchRec Modules and DataTypes\n",
        "2. Distributed Training, Sharding, and Optimizations\n",
        "3. Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000134724,
        "executionStopTime": 1726000139238,
        "id": "5vzmNV0IcspA",
        "language": "python",
        "originalKey": "8395ed9c-8336-4686-8e73-cb815b808f2a",
        "outputsInitialized": true,
        "requestMsgId": "8395ed9c-8336-4686-8e73-cb815b808f2a",
        "serverExecutionDuration": 4317.9145939648,
        "showInput": true
      },
      "outputs": [],
      "source": [
        "import torchrec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "42PwMZnNcspA",
        "language": "markdown",
        "originalKey": "0c95b385-e07a-43e1-aaeb-31f66deb5b35",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## TorchRec Modules and Datatypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdSUWBRxoP8R",
        "language": "markdown",
        "originalKey": "309c4d38-8f19-46d9-a8bb-7d3d1c166e84",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### From EmbeddingBag to EmbeddingBagCollection\n",
        "We have already explored [`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) and [`torch.nn.EmbeddingBag`](https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html).\n",
        "\n",
        "TorchRec extends these modules by creating collections of embeddings, in other words modules that can have multiple embedding tables, with [`EmbeddingCollection`](https://pytorch.org/torchrec/torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection) and [`EmbeddingBagCollection`](https://pytorch.org/torchrec/torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection). We will use `EmbeddingBagCollection` to represent a group of EmbeddingBags.\n",
        "\n",
        "Here, we create an EmbeddingBagCollection (EBC) with two embedding bags, 1 representing **products** and 1 representing **users**. Each table, `product_table` and `user_table`, is represented by 64 dimension embedding of size 4096."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customOutput": null,
        "executionStartTime": 1726000139247,
        "executionStopTime": 1726000139433,
        "id": "Iz_GZDp_oQ19",
        "language": "python",
        "originalKey": "219c4ee9-c4f1-43ff-9d1c-b15b16a1dc8e",
        "output": {
          "id": 1095398565339190,
          "loadingStatus": "loaded"
        },
        "outputId": "2fadb955-6f0c-4ffb-ec0b-bb9535dd2888",
        "outputsInitialized": true,
        "requestMsgId": "219c4ee9-c4f1-43ff-9d1c-b15b16a1dc8e",
        "serverExecutionDuration": 13.643965125084
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleDict(\n",
            "  (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
            "  (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "ebc = torchrec.EmbeddingBagCollection(\n",
        "    device=\"cpu\",\n",
        "    tables=[\n",
        "        torchrec.EmbeddingBagConfig(\n",
        "            name=\"product_table\",\n",
        "            embedding_dim=64,\n",
        "            num_embeddings=4096,\n",
        "            feature_names=[\"product\"],\n",
        "            pooling=torchrec.PoolingType.SUM,\n",
        "        ),\n",
        "        torchrec.EmbeddingBagConfig(\n",
        "            name=\"user_table\",\n",
        "            embedding_dim=64,\n",
        "            num_embeddings=4096,\n",
        "            feature_names=[\"user\"],\n",
        "            pooling=torchrec.PoolingType.SUM,\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "print(ebc.embedding_bags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "xjcA0Di1cspA",
        "language": "markdown",
        "originalKey": "c587a298-4d38-4a69-89a2-5d5c4a26cc2c",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "Let’s inspect the forward method for EmbeddingBagcollection and the module’s inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000139437,
        "executionStopTime": 1726000139616,
        "id": "UuIrEWupcspA",
        "language": "python",
        "originalKey": "c9d2717b-b753-4e0b-97bd-1596123d081d",
        "output": {
          "id": 8849152198449371,
          "loadingStatus": "loaded"
        },
        "outputId": "94c0b3b5-247a-47d9-b3bd-aff2c374dcdc",
        "outputsInitialized": true,
        "requestMsgId": "c9d2717b-b753-4e0b-97bd-1596123d081d",
        "serverExecutionDuration": 6.011176854372,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def forward(self, features: KeyedJaggedTensor) -> KeyedTensor:\n",
            "        \"\"\"\n",
            "        Args:\n",
            "            features (KeyedJaggedTensor): KJT of form [F X B X L].\n",
            "\n",
            "        Returns:\n",
            "            KeyedTensor\n",
            "        \"\"\"\n",
            "        flat_feature_names: List[str] = []\n",
            "        for names in self._feature_names:\n",
            "            flat_feature_names.extend(names)\n",
            "        inverse_indices = reorder_inverse_indices(\n",
            "            inverse_indices=features.inverse_indices_or_none(),\n",
            "            feature_names=flat_feature_names,\n",
            "        )\n",
            "        pooled_embeddings: List[torch.Tensor] = []\n",
            "        feature_dict = features.to_dict()\n",
            "        for i, embedding_bag in enumerate(self.embedding_bags.values()):\n",
            "            for feature_name in self._feature_names[i]:\n",
            "                f = feature_dict[feature_name]\n",
            "                res = embedding_bag(\n",
            "                    input=f.values(),\n",
            "                    offsets=f.offsets(),\n",
            "                    per_sample_weights=f.weights() if self._is_weighted else None,\n",
            "                ).float()\n",
            "                pooled_embeddings.append(res)\n",
            "        return KeyedTensor(\n",
            "            keys=self._embedding_names,\n",
            "            values=process_pooled_embeddings(\n",
            "                pooled_embeddings=pooled_embeddings,\n",
            "                inverse_indices=inverse_indices,\n",
            "            ),\n",
            "            length_per_key=self._lengths_per_embedding,\n",
            "        )\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import inspect\n",
        "\n",
        "# Let's look at the EmbeddingBagCollection forward method\n",
        "# What is a KeyedJaggedTensor and KeyedTensor?\n",
        "print(inspect.getsource(ebc.forward))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "C_UAtHsMcspA",
        "language": "markdown",
        "originalKey": "d6b9bfc2-544d-499f-ad61-d7471b819f8a",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### TorchRec Input/Output Data Types\n",
        "TorchRec has distinct data types for input and output of its modules: `JaggedTensor`, `KeyedJaggedTensor`, and `KeyedTensor`. Now you might ask, why create new datatypes to represent sparse features? To answer that question, we must understand how sparse features are represented in code.\n",
        "\n",
        "Sparse features are otherwise known as `id_list_feature` and `id_score_list_feature`, and are the **IDs** that will be used as indices to an embedding table to retrieve the embedding for that ID. To give a very simple example, imagine a single sparse feature being Ads that a user interacted with. The input itself would be a set of Ad IDs that a user interacted with, and the embeddings retrieved would be a semantic representation of those Ads. The tricky part of representing these features in code is that in each input example, **the number of IDs is variable**. 1 day a user might have interacted with only 1 ad while the next day they interact with 3.\n",
        "\n",
        "A simple representation is shown below, where we have a `lengths` tensor denoting how many indices are in an example for a batch and a `values` tensor containing the indices themselves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000139620,
        "executionStopTime": 1726000139790,
        "id": "RB77aL08cspA",
        "language": "python",
        "originalKey": "13225ead-a798-4db2-8de6-1c13a758d676",
        "outputsInitialized": true,
        "requestMsgId": "13225ead-a798-4db2-8de6-1c13a758d676",
        "serverExecutionDuration": 3.692839294672,
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# Batch Size 2\n",
        "# 1 ID in example 1, 2 IDs in example 2\n",
        "id_list_feature_lengths = torch.tensor([1, 2])\n",
        "\n",
        "# Values (IDs) tensor: ID 5 is in example 1, ID 7, 1 is in example 2\n",
        "id_list_feature_values = torch.tensor([5, 7, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "aKmgGqdNcspA",
        "language": "markdown",
        "originalKey": "65d31fca-7b7f-4c0f-9ca2-56e07243a5c0",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "Let’s look at the offsets as well as what is contained in each Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000139794,
        "executionStopTime": 1726000139966,
        "id": "t5T5S8_mcspB",
        "language": "python",
        "originalKey": "9510cebd-1875-461e-9243-53928632abfa",
        "output": {
          "id": 2337665543231723,
          "loadingStatus": "loaded"
        },
        "outputId": "b7c61b24-7a09-4788-82b1-df05d8ece4d5",
        "outputsInitialized": true,
        "requestMsgId": "9510cebd-1875-461e-9243-53928632abfa",
        "serverExecutionDuration": 6.6289491951466,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Offsets:  tensor([1, 3])\n",
            "First Batch:  tensor([5])\n",
            "Second Batch:  tensor([7, 1])\n"
          ]
        }
      ],
      "source": [
        "# Lengths can be converted to offsets for easy indexing of values\n",
        "id_list_feature_offsets = torch.cumsum(id_list_feature_lengths, dim=0)\n",
        "\n",
        "print(\"Offsets: \", id_list_feature_offsets)\n",
        "print(\"First Batch: \", id_list_feature_values[: id_list_feature_offsets[0]])\n",
        "print(\n",
        "    \"Second Batch: \",\n",
        "    id_list_feature_values[id_list_feature_offsets[0] : id_list_feature_offsets[1]],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000139968,
        "executionStopTime": 1726000140161,
        "id": "2OOK2BBecspB",
        "language": "python",
        "originalKey": "4bc3fac5-16b9-4f63-b841-9b26ee0ccfc0",
        "output": {
          "id": 1155071062256886,
          "loadingStatus": "loaded"
        },
        "outputId": "56caf27f-a7f6-4af1-c42c-022f938bc68b",
        "outputsInitialized": true,
        "requestMsgId": "4bc3fac5-16b9-4f63-b841-9b26ee0ccfc0",
        "serverExecutionDuration": 7.3191449046135,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Offsets:  tensor([0, 1, 3])\n",
            "List of Values:  [tensor([5]), tensor([7, 1])]\n",
            "JaggedTensor({\n",
            "    [[5], [7, 1]]\n",
            "})\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchrec import JaggedTensor\n",
        "\n",
        "# JaggedTensor is just a wrapper around lengths/offsets and values tensors!\n",
        "jt = JaggedTensor(values=id_list_feature_values, lengths=id_list_feature_lengths)\n",
        "\n",
        "# Automatically compute offsets from lengths\n",
        "print(\"Offsets: \", jt.offsets())\n",
        "\n",
        "# Convert to list of values\n",
        "print(\"List of Values: \", jt.to_dense())\n",
        "\n",
        "# __str__ representation\n",
        "print(jt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000140165,
        "executionStopTime": 1726000140355,
        "id": "fs10Fxu2cspB",
        "language": "python",
        "originalKey": "ad069058-2329-4ab9-bee8-60775ead4c33",
        "output": {
          "id": 2349443512054827,
          "loadingStatus": "loaded"
        },
        "outputId": "8f675894-cf26-4fdf-e839-7624d1ed78a8",
        "outputsInitialized": true,
        "requestMsgId": "ad069058-2329-4ab9-bee8-60775ead4c33",
        "serverExecutionDuration": 10.361641645432,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys:  ['product', 'user']\n",
            "Lengths:  tensor([3, 1, 2, 2])\n",
            "Values:  tensor([1, 2, 1, 5, 2, 3, 4, 1])\n",
            "to_dict:  {'product': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x7f4f9ac06260>, 'user': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x7f4f71200310>}\n",
            "KeyedJaggedTensor({\n",
            "    \"product\": [[1, 2, 1], [5]],\n",
            "    \"user\": [[2, 3], [4, 1]]\n",
            "})\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchrec import KeyedJaggedTensor\n",
        "\n",
        "# JaggedTensor represents IDs for 1 feature, but we have multiple features in an EmbeddingBagCollection\n",
        "# That's where KeyedJaggedTensor comes in! KeyedJaggedTensor is just multiple JaggedTensors for multiple id_list_feature_offsets\n",
        "# From before, we have our two features \"product\" and \"user\". Let's create JaggedTensors for both!\n",
        "\n",
        "product_jt = JaggedTensor(\n",
        "    values=torch.tensor([1, 2, 1, 5]), lengths=torch.tensor([3, 1])\n",
        ")\n",
        "user_jt = JaggedTensor(values=torch.tensor([2, 3, 4, 1]), lengths=torch.tensor([2, 2]))\n",
        "\n",
        "# Q1: How many batches are there, and which values are in the first batch for product_jt and user_jt?\n",
        "kjt = KeyedJaggedTensor.from_jt_dict({\"product\": product_jt, \"user\": user_jt})\n",
        "\n",
        "# Look at our feature keys for the KeyedJaggedTensor\n",
        "print(\"Keys: \", kjt.keys())\n",
        "\n",
        "# Look at the overall lengths for the KeyedJaggedTensor\n",
        "print(\"Lengths: \", kjt.lengths())\n",
        "\n",
        "# Look at all values for KeyedJaggedTensor\n",
        "print(\"Values: \", kjt.values())\n",
        "\n",
        "# Can convert KJT to dictionary representation\n",
        "print(\"to_dict: \", kjt.to_dict())\n",
        "\n",
        "# KeyedJaggedTensor(KJT) string representation\n",
        "print(kjt)\n",
        "\n",
        "# Q2: What are the offsets for the KeyedJaggedTensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000140357,
        "executionStopTime": 1726000140549,
        "id": "JeLwyCNRcspB",
        "language": "python",
        "originalKey": "b13fdf10-45a7-4e57-b50e-cc18547a715b",
        "output": {
          "id": 1584305125770017,
          "loadingStatus": "loaded"
        },
        "outputId": "d3afa2c0-e28a-4de2-b1b7-927bcf276776",
        "outputsInitialized": true,
        "requestMsgId": "b13fdf10-45a7-4e57-b50e-cc18547a715b",
        "serverExecutionDuration": 17.695877701044,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x7f4f71200730>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we can run a forward pass on our ebc from before\n",
        "result = ebc(kjt)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000140552,
        "executionStopTime": 1726000140732,
        "id": "R2K4v2vqcspB",
        "language": "python",
        "originalKey": "57a01464-de39-4bfb-8355-83cd97e519c0",
        "output": {
          "id": 1021776262932642,
          "loadingStatus": "loaded"
        },
        "outputId": "c2e72ff0-b0d2-4631-abfc-a0fab83fc2a3",
        "outputsInitialized": true,
        "requestMsgId": "57a01464-de39-4bfb-8355-83cd97e519c0",
        "serverExecutionDuration": 6.0368701815605,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['product', 'user']\n",
            "torch.Size([2, 128])\n",
            "product torch.Size([2, 64])\n",
            "user torch.Size([2, 64])\n"
          ]
        }
      ],
      "source": [
        "# Result is a KeyedTensor, which contains a list of the feature names and the embedding results\n",
        "print(result.keys())\n",
        "\n",
        "# The results shape is [2, 128], as batch size of 2. Reread previous section if you need a refresher on how the batch size is determined\n",
        "# 128 for dimension of embedding. If you look at where we initialized the EmbeddingBagCollection, we have two tables \"product\" and \"user\" of dimension 64 each\n",
        "# meaning emebddings for both features are of size 64. 64 + 64 = 128\n",
        "print(result.values().shape)\n",
        "\n",
        "# Nice to_dict method to determine the embeddings that belong to each feature\n",
        "result_dict = result.to_dict()\n",
        "for key, embedding in result_dict.items():\n",
        "    print(key, embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "EE-YYDv7cspB",
        "language": "markdown",
        "originalKey": "d0fc8635-dac3-444b-978b-421b5d77b70c",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "Congrats! Give yourself a pat on the back for making it this far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "djLHn0CIcspB",
        "language": "markdown",
        "originalKey": "70816a78-7671-411c-814f-d2c98c3a912c",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## Distributed Training and Sharding\n",
        "Now that we have a grasp on TorchRec modules and data types, it's time to take it to the next level.\n",
        "\n",
        "Remember, TorchRec's main purpose is to provide primitives for distributed embeddings. So far, we've only worked with embedding tables on 1 device. This has been possible given how small the embedding tables have been, but in a production setting this isn't generally the case. Embedding tables often get massive, where 1 table can't fit on a single GPU, creating the requirement for multiple devices and a distributed environment\n",
        "\n",
        "In this section, we will explore setting up a distributed environment, exactly how actual production training is done, and explore sharding embedding tables, all with Torchrec.\n",
        "\n",
        "**This section will also only use 1 gpu, though it will be treated in a distributed fashion. This is only a limitation for training, as training has a process per gpu. Inference does not run into this requirement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customOutput": null,
        "executionStartTime": 1726000140740,
        "executionStopTime": 1726000142256,
        "id": "4-v17rxkopQw",
        "language": "python",
        "originalKey": "df0d09f0-5e8e-46bf-a086-dd991c8be0b4",
        "output": {
          "id": 494586476747887,
          "loadingStatus": "loaded"
        },
        "outputId": "d670cd23-7bd8-48de-bb89-ef957c3ea86a",
        "outputsInitialized": true,
        "requestMsgId": "df0d09f0-5e8e-46bf-a086-dd991c8be0b4",
        "serverExecutionDuration": 1350.0418178737
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0918 20:20:51.492902 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_SLEEP_AFTER_EXCEPTION = True from JK ai_infra/pytorch_distributed:sleep_after_exception\n",
            "W0918 20:20:51.494689 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_DUMP_ON_TIMEOUT = True from JK ai_infra/pytorch_distributed:dump_on_nccl_timeout_1\n",
            "W0918 20:20:51.495571 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_TRACE_BUFFER_SIZE = 2000 from JK ai_infra/pytorch_distributed:torch_nccl_trace_buffer_size\n",
            "W0918 20:20:51.497527 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_TRACE_CPP_STACK = False from JK ai_infra/pytorch_distributed:torch_nccl_trace_cpp_stack\n",
            "W0918 20:20:51.498366 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_ENABLE_TIMING = False from JK ai_infra/pytorch_distributed:torch_nccl_enable_timing\n",
            "W0918 20:20:51.499985 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_ENABLE_MONITORING = False from JK ai_infra/pytorch_distributed:torch_nccl_enable_monitoring\n",
            "W0918 20:20:51.502395 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_ABORT_IN_DESTROY_PG = True from JK ai_infra/pytorch_distributed:torch_nccl_abort_in_destroy_pg\n",
            "W0918 20:20:51.503769 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_DISABLE_NATIVE_FUNCOL = 0 from JK ai_infra/pytorch_distributed:torch_disable_native_funcol\n",
            "W0918 20:20:51.505401 3508277 torch/_utils_internal.py:1050] Set ENV TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN = True from JK ai_infra/pytorch_distributed:torch_nccl_log_cpp_stack_on_unclean_shutdown\n",
            "W0918 20:20:51.507221 3508277 torch/_utils_internal.py:1005] In FBCODE, but not able to access mast runtime env, skipping flight-recorder dump registration\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed environment initialized: <module 'torch.distributed' from '/mnt/xarfuse/uid-28984/b2995003-seed-nspid4026533636_cgpid73128133-ns-4026533633/torch/distributed/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "# Here we set up our torch distributed environment\n",
        "# WARNING: You can only call this cell once, calling it again will cause an error\n",
        "# as you can only initialize the process group once\n",
        "\n",
        "import os\n",
        "\n",
        "import torch.distributed as dist\n",
        "\n",
        "# Set up environment variables for distributed training\n",
        "# RANK is which GPU we are on, default 0\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "# How many devices in our \"world\", since Bento can only handle 1 process, 1 GPU\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "# Localhost as we are training locally\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "# Port for distributed training\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
        "\n",
        "# Note - you will need a V100 or A100 to run tutorial as!\n",
        "# nccl backend is for GPUs, gloo is for CPUs\n",
        "dist.init_process_group(backend=\"nccl\")\n",
        "\n",
        "print(f\"Distributed environment initialized: {dist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "hQOjNci3cspB",
        "language": "markdown",
        "originalKey": "480e69dc-3e9d-4e86-b73c-950e18afb0f5",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Distributed Embeddings\n",
        "\n",
        "We have already worked with the main TorchRec module: `EmbeddingBagCollection`. We have examined how it works along with how data is represented in TorchRec. However, we have not yet explored one of the main parts of TorchRec, which is **distributed embeddings**.\n",
        "\n",
        "GPUs are the most popular choice for ML workloads by far today, as they are able to do magnitudes more floating point operations/s ([FLOPs](https://en.wikipedia.org/wiki/FLOPS)) than CPU. However, GPUs come with the limitation of scarce fast memory (HBM which is analgous to RAM for CPU), typically ~10s of GBs.\n",
        "\n",
        "A RecSys model can contain embedding tables that far exceed the memory limit for 1 GPU, hence the need for distribution of the embedding tables across multiple GPUs, otherwise known as **model parallel**. On the other hand, **data parallel** is where the entire model is replicated on each GPU, which each GPU taking in a distinct batch of data for training, syncing gradients on the backwards pass.\n",
        "\n",
        "Parts of the model that **require less compute but more memory (embeddings) are distributed with model parallel** while parts that **require more compute and less memory (dense layers, MLP, etc.) are distributed with data parallel**.\n",
        "\n",
        "\n",
        "### Sharding\n",
        "In order to distribute an embedding table, we split up the embedding table into parts and place those parts onto different devices, also known as “sharding”.\n",
        "\n",
        "There are many ways to shard embedding tables. The most common ways are:\n",
        "* Table-Wise: the table is placed entirely onto one device\n",
        "* Column-Wise: columns of embedding tables are sharded\n",
        "* Row-Wise: rows of embedding tables are sharded\n",
        "\n",
        "\n",
        "### Sharded Modules\n",
        "While all of this seems like a lot to deal with and implement, you're in luck. **TorchRec provides all the primitives for easy distributed training/inference**! In fact, TorchRec modules have two corresponding classes for working with any TorchRec module in a distributed environment:\n",
        "1. The module sharder: This class exposes a `shard` API that handles sharding a TorchRec Module, producing a sharded module.\n",
        "    *  For `EmbeddingBagCollection`, the sharder is [`EmbeddingBagCollectionSharder`](https://pytorch.org/torchrec/torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder)\n",
        "2. Sharded module: This class is a sharded variant of a TorchRec module. It has the same input/output as a the regular TorchRec module, but much more optimized and works in a distributed environment.\n",
        "    * For `EmbeddingBagCollection`, the sharded variant is [`ShardedEmbeddingBagCollection`](https://pytorch.org/torchrec/torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection)\n",
        "\n",
        "Every TorchRec module has an unsharded and sharded variant.\n",
        "* The unsharded version is meant to be prototyped and experimented with\n",
        "* The sharded version is meant to be used in a distributed environment for distributed training/inference.\n",
        "\n",
        "The sharded versions of TorchRec modules, for example EmbeddingBagCollection, will handle everything that is needed for Model Parallelism, such as communication between GPUs for distributing embeddings to the correct GPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000142261,
        "executionStopTime": 1726000142430,
        "id": "FX65VcQ6cspB",
        "language": "python",
        "originalKey": "eb2a064d-0b67-4cba-a199-c99573c7e6cd",
        "output": {
          "id": 2655288431329505,
          "loadingStatus": "loaded"
        },
        "outputId": "7e7148c5-7194-4a4d-9580-19f6811783a8",
        "outputsInitialized": true,
        "requestMsgId": "eb2a064d-0b67-4cba-a199-c99573c7e6cd",
        "serverExecutionDuration": 8.3460621535778,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmbeddingBagCollection(\n",
              "  (embedding_bags): ModuleDict(\n",
              "    (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "    (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Refresher of our EmbeddingBagCollection module\n",
        "ebc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000142433,
        "executionStopTime": 1726000142681,
        "id": "1hSzTg4pcspC",
        "language": "python",
        "originalKey": "1442636d-8617-4785-b40c-8544374253b6",
        "output": {
          "id": 1812572762609085,
          "loadingStatus": "loaded"
        },
        "outputId": "be6bc55e-2742-4940-e2a6-ad9f8eb02198",
        "outputsInitialized": true,
        "requestMsgId": "1442636d-8617-4785-b40c-8544374253b6",
        "serverExecutionDuration": 4.4135116040707,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process Group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x7f4f71258ff0>\n"
          ]
        }
      ],
      "source": [
        "from torchrec.distributed.embeddingbag import EmbeddingBagCollectionSharder\n",
        "from torchrec.distributed.planner import EmbeddingShardingPlanner, Topology\n",
        "from torchrec.distributed.types import ShardingEnv\n",
        "\n",
        "# Corresponding sharder for EmbeddingBagCollection module\n",
        "sharder = EmbeddingBagCollectionSharder()\n",
        "\n",
        "# ProcessGroup from torch.distributed initialized 2 cells above\n",
        "pg = dist.GroupMember.WORLD\n",
        "assert pg is not None, \"Process group is not initialized\"\n",
        "\n",
        "print(f\"Process Group: {pg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "qU7A980qcspC",
        "language": "markdown",
        "originalKey": "29cc17eb-9e2f-480b-aed2-60b15024fbf7",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Planner\n",
        "\n",
        "Before we can show how sharding works, we must know about the **planner**, which helps us determine the best sharding configuration.\n",
        "\n",
        "Given a number of embedding tables and a number of ranks, there are many different sharding configurations that are possible. For example, given 2 embedding tables and 2 GPUs, you can:\n",
        "* Place 1 table on each GPU\n",
        "* Place both tables on a single GPU and no tables on the other\n",
        "* Place certain rows/columns on each GPU\n",
        "\n",
        "Given all of these possibilities, we typically want a sharding configuration that is optimal for performance.\n",
        "\n",
        "That is where the planner comes in. The planner is able to determine given the # of embedding tables and the # of GPUs, what is the optimal configuration. Turns out, this is incredibly difficult to do manually, with tons of factors that engineers have to consider to ensure an optimal sharding plan. Luckily, TorchRec provides an auto planner when the planner is used. The TorchRec planner:\n",
        "* assesses memory constraints of hardware,\n",
        "* estimates compute based on memory fetches as embedding lookups,\n",
        "* addresses data specific factors,\n",
        "* considers other hardware specifics like bandwidth to generate an optimal sharding plan.\n",
        "\n",
        "In order to take into consideration all these variables, The TorchRec planner can take in [various amounts of data for embedding tables, constraints, hardware information, and topology](https://github.com/pytorch/torchrec/blob/main/torchrec/distributed/planner/planners.py#L147-L155) to aid in generating the optimal sharding plan for a model, which is routinely provided across stacks\n",
        "\n",
        "\n",
        "To learn more about sharding, see our [sharding tutorial](https://pytorch.org/tutorials/advanced/sharding.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000142687,
        "executionStopTime": 1726000143033,
        "id": "PQeXnuAGcspC",
        "language": "python",
        "originalKey": "64936203-2e59-4bc3-8d76-1b652b7891c2",
        "output": {
          "id": 3666087663721362,
          "loadingStatus": "loaded"
        },
        "outputId": "03670001-a4ef-43ca-bddf-1f6cc3e12a0b",
        "outputsInitialized": true,
        "requestMsgId": "64936203-2e59-4bc3-8d76-1b652b7891c2",
        "serverExecutionDuration": 145.92137932777,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0918 203945.841 stats.py:522] ##################################################################################################################################################################################################################################################################################################\n",
            "I0918 203945.842 stats.py:522] #                                                                                                                                   --- Planner Statistics ---                                                                                                                                   #\n",
            "I0918 203945.843 stats.py:522] #                                                                                                          --- Evaluated 256 proposal(s), found 256 possible plan(s), ran for 0.05s ---                                                                                                          #\n",
            "I0918 203945.844 stats.py:522] # ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
            "I0918 203945.845 stats.py:522] #      Rank     HBM (GB)     DDR (GB)                              Perf (ms)     Input (MB)     Output (MB)     Shards                                                                                                                                                                           #\n",
            "I0918 203945.846 stats.py:522] #    ------   ----------   ----------                            -----------   ------------   -------------   --------                                                                                                                                                                           #\n",
            "I0918 203945.847 stats.py:522] #         0   0.002 (0%)     0.0 (0%)   0.003 (0.0006,0.0004,0.001,0.0004,0)           0.01            0.25      TW: 2                                                                                                                                                                           #\n",
            "I0918 203945.847 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.848 stats.py:522] # Perf: Total perf (Forward compute, Forward comms, Backward compute, Backward comms, Prefetch compute)                                                                                                                                                                                          #\n",
            "I0918 203945.849 stats.py:522] # Input: MB/iteration, Output: MB/iteration, Shards: number of tables                                                                                                                                                                                                                            #\n",
            "I0918 203945.851 stats.py:522] # HBM: estimated peak memory usage for shards, dense tensors, and features (KJT)                                                                                                                                                                                                                 #\n",
            "I0918 203945.853 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.855 stats.py:522] # Parameter Info:                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.856 stats.py:522] #               FQN     Sharding     Compute Kernel                               Perf (ms)     Storage (HBM, DDR)     Cache Load Factor     Pooling Factor     Num Poolings     Output     Weighing                         Sharder     Features     Emb Dim (CW Dim)     Hash Size     Ranks   #\n",
            "I0918 203945.857 stats.py:522] #             -----   ----------   ----------------                             -----------   --------------------   -------------------   ----------------   --------------   --------   ----------                       ---------   ----------   ------------------   -----------   -------   #\n",
            "I0918 203945.858 stats.py:522] #    .product_table           TW              fused   0.001 (0.0003,0.0002,0.0006,0.0002,0)     (0.001 GB, 0.0 GB)                  None                1.0              1.0     pooled   unweighted   EmbeddingBagCollectionSharder            1                   64          4096         0   #\n",
            "I0918 203945.859 stats.py:522] #       .user_table           TW              fused   0.001 (0.0003,0.0002,0.0006,0.0002,0)     (0.001 GB, 0.0 GB)                  None                1.0              1.0     pooled   unweighted   EmbeddingBagCollectionSharder            1                   64          4096         0   #\n",
            "I0918 203945.859 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.860 stats.py:522] # Batch Size: 512                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.861 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.863 stats.py:522] # Compute Kernels Count:                                                                                                                                                                                                                                                                         #\n",
            "I0918 203945.865 stats.py:522] #    fused: 2                                                                                                                                                                                                                                                                                    #\n",
            "I0918 203945.866 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.867 stats.py:522] # Compute Kernels Storage:                                                                                                                                                                                                                                                                       #\n",
            "I0918 203945.868 stats.py:522] #    fused: HBM: 0.002 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                           #\n",
            "I0918 203945.869 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.872 stats.py:522] # Total Perf Imbalance Statistics                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.873 stats.py:522] # Total Variation: 0.000                                                                                                                                                                                                                                                                         #\n",
            "I0918 203945.874 stats.py:522] # Total Distance: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 203945.875 stats.py:522] # Chi Divergence: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 203945.876 stats.py:522] # KL Divergence: 0.000                                                                                                                                                                                                                                                                           #\n",
            "I0918 203945.876 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.878 stats.py:522] # HBM Imbalance Statistics                                                                                                                                                                                                                                                                       #\n",
            "I0918 203945.878 stats.py:522] # Total Variation: 0.000                                                                                                                                                                                                                                                                         #\n",
            "I0918 203945.881 stats.py:522] # Total Distance: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 203945.882 stats.py:522] # Chi Divergence: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 203945.883 stats.py:522] # KL Divergence: 0.000                                                                                                                                                                                                                                                                           #\n",
            "I0918 203945.884 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.886 stats.py:522] # Total Variation: higher means more imbalanced (ranges 0 to 1)                                                                                                                                                                                                                                  #\n",
            "I0918 203945.887 stats.py:522] # Total Distance: higher means more imbalanced (ranges 0 to 1)                                                                                                                                                                                                                                   #\n",
            "I0918 203945.888 stats.py:522] # Chi Divergence: higher means more imbalanced (ranges 0 to 0.000)                                                                                                                                                                                                                               #\n",
            "I0918 203945.889 stats.py:522] # KL Divergence: higher means more imbalanced (ranges 0 to 0.000)                                                                                                                                                                                                                                #\n",
            "I0918 203945.889 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.890 stats.py:522] # Longest Critical Path (Maximum of Total Perf): 0.003 ms on rank 0                                                                                                                                                                                                                              #\n",
            "I0918 203945.891 stats.py:522] # Maximum of Forward Compute: 0.001 ms on rank 0                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.893 stats.py:522] # Maximum of Forward Comms: 0.0 ms on rank 0                                                                                                                                                                                                                                                     #\n",
            "I0918 203945.894 stats.py:522] # Maximum of Backward Compute: 0.001 ms on rank 0                                                                                                                                                                                                                                                #\n",
            "I0918 203945.895 stats.py:522] # Maximum of Backward Comms: 0.0 ms on rank 0                                                                                                                                                                                                                                                    #\n",
            "I0918 203945.896 stats.py:522] # Maximum of Prefetch Compute: 0.0 ms on rank 0                                                                                                                                                                                                                                                  #\n",
            "I0918 203945.897 stats.py:522] # Sum of Maxima: 0.003 ms                                                                                                                                                                                                                                                                        #\n",
            "I0918 203945.899 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.900 stats.py:522] # Estimated Sharding Distribution                                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.902 stats.py:522] # Max HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                  #\n",
            "I0918 203945.903 stats.py:522] # Min HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                  #\n",
            "I0918 203945.904 stats.py:522] # Mean HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.905 stats.py:522] # Low Median HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                           #\n",
            "I0918 203945.907 stats.py:522] # High Median HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                          #\n",
            "I0918 203945.908 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.909 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.909 stats.py:522] # Top HBM Memory Usage Estimation: 0.002 GB                                                                                                                                                                                                                                                      #\n",
            "I0918 203945.910 stats.py:522] # Top Tier #1 Estimated Peak HBM Pressure: 0.002 GB on rank 0                                                                                                                                                                                                                                    #\n",
            "I0918 203945.912 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.914 stats.py:522] # Reserved Memory:                                                                                                                                                                                                                                                                               #\n",
            "I0918 203945.915 stats.py:522] #    HBM: 4.8 GB                                                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.916 stats.py:522] #    Percent of Total HBM: 15%                                                                                                                                                                                                                                                                   #\n",
            "I0918 203945.918 stats.py:522] # Planning Memory:                                                                                                                                                                                                                                                                               #\n",
            "I0918 203945.919 stats.py:522] #    HBM: 27.2 GB, DDR: 128.0 GB                                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.919 stats.py:522] #    Percent of Total HBM: 85%                                                                                                                                                                                                                                                                   #\n",
            "I0918 203945.920 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.921 stats.py:522] # Dense Storage (per rank):                                                                                                                                                                                                                                                                      #\n",
            "I0918 203945.922 stats.py:522] #    HBM: 0.0 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                                    #\n",
            "I0918 203945.923 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.923 stats.py:522] # KJT Storage (per rank):                                                                                                                                                                                                                                                                        #\n",
            "I0918 203945.926 stats.py:522] #    HBM: 0.0 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                                    #\n",
            "I0918 203945.927 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 203945.928 stats.py:522] # Top 5 Tables Causing Max Perf:                                                                                                                                                                                                                                                                 #\n",
            "I0918 203945.929 stats.py:522] # Top 5 Tables Causing Max HBM:                                                                                                                                                                                                                                                                  #\n",
            "I0918 203945.930 stats.py:522] ##################################################################################################################################################################################################################################################################################################\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharding Plan generated: module: \n",
            "\n",
            "    param     | sharding type | compute kernel | ranks\n",
            "------------- | ------------- | -------------- | -----\n",
            "product_table | table_wise    | fused          | [0]  \n",
            "user_table    | table_wise    | fused          | [0]  \n",
            "\n",
            "    param     | shard offsets | shard sizes |   placement  \n",
            "------------- | ------------- | ----------- | -------------\n",
            "product_table | [0, 0]        | [4096, 64]  | rank:0/cuda:0\n",
            "user_table    | [0, 0]        | [4096, 64]  | rank:0/cuda:0\n"
          ]
        }
      ],
      "source": [
        "# In our case, 1 GPU and compute on CUDA device\n",
        "planner = EmbeddingShardingPlanner(\n",
        "    topology=Topology(\n",
        "        world_size=1,\n",
        "        compute_device=\"cuda\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run planner to get plan for sharding\n",
        "plan = planner.collective_plan(ebc, [sharder], pg)\n",
        "\n",
        "print(f\"Sharding Plan generated: {plan}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "2TTLj_0PcspC",
        "language": "markdown",
        "originalKey": "bbbbbf60-5691-4357-9943-4d7f8b2b1d5c",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Planner Result\n",
        "As you can see, when running the planner there is quite a bit of output above. We can see a ton of stats being calculated along with where our tables end up being placed.\n",
        "\n",
        "The result of running the planner is a static plan, which can be reused for sharding! This allows sharding to be static for production models instead of determining a new sharding plan everytime. Below, we use the sharding plan to finally generate our `ShardedEmbeddingBagCollection.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000143037,
        "executionStopTime": 1726000143259,
        "id": "JIci5Gz6cspC",
        "language": "python",
        "originalKey": "533be12d-a3c5-4c9e-9351-7770251c8fa5",
        "output": {
          "id": 1165874004484283,
          "loadingStatus": "loaded"
        },
        "outputId": "a9675129-080e-46b5-927d-721491bd3604",
        "outputsInitialized": true,
        "requestMsgId": "533be12d-a3c5-4c9e-9351-7770251c8fa5",
        "serverExecutionDuration": 5.2368640899658,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ShardingPlan(plan={'': {'product_table': ParameterSharding(sharding_type='table_wise', compute_kernel='fused', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[4096, 64], placement=rank:0/cuda:0)]), cache_params=None, enforce_hbm=None, stochastic_rounding=None, bounds_check_mode=None, output_dtype=None, key_value_params=None), 'user_table': ParameterSharding(sharding_type='table_wise', compute_kernel='fused', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[4096, 64], placement=rank:0/cuda:0)]), cache_params=None, enforce_hbm=None, stochastic_rounding=None, bounds_check_mode=None, output_dtype=None, key_value_params=None)}})"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The static plan that was generated\n",
        "plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000143262,
        "executionStopTime": 1726000147680,
        "id": "2__Do2tqcspC",
        "language": "python",
        "originalKey": "5dcbfda0-0abb-4a51-ba8f-a6a4023f0e2f",
        "output": {
          "id": 1180884489797754,
          "loadingStatus": "loaded"
        },
        "outputId": "cffbb5ae-f4ff-4173-d025-6efd443d036a",
        "outputsInitialized": true,
        "requestMsgId": "5dcbfda0-0abb-4a51-ba8f-a6a4023f0e2f",
        "serverExecutionDuration": 4229.5375689864,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0918 203946.974 split_table_batched_embeddings_ops_training.py:712] Using global weight decay = False\n",
            "I0918 203946.976 split_table_batched_embeddings_ops_training.py:1025] [TBE=9117d22d-957a-4e51-ab31-2924018e5b97] Contents: ['product_table', 'user_table']\n",
            "I0918 203946.977 split_table_batched_embeddings_ops_training.py:1025] [TBE=9117d22d-957a-4e51-ab31-2924018e5b97] Using fused exact_sgd with optimizer_args=OptimizerArgs(stochastic_rounding=True, gradient_clipping=False, max_gradient=1.0, max_norm=0.0, learning_rate=0.01, eps=1e-08, beta1=0.9, beta2=0.999, step_ema=10000, step_swap=10000, step_start=0, step_mode=2, weight_decay=0.0, weight_decay_mode=0, eta=0.001, momentum=0.9, counter_halflife=-1, adjustment_iter=-1, adjustment_ub=1.0, learning_rate_mode=-1, grad_sum_decay=-1, tail_id_threshold=0, is_tail_id_thresh_ratio=0, total_hash_size=8192, weight_norm_coefficient=0.0, lower_bound=0.0, regularization_mode=0)\n",
            "I0918 203946.978 split_table_batched_embeddings_ops_training.py:1025] [TBE=9117d22d-957a-4e51-ab31-2924018e5b97] Using rowwise_adagrad_with_counter=False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharded EBC Module: ShardedEmbeddingBagCollection(\n",
            "  (lookups): \n",
            "   GroupedPooledEmbeddingsLookup(\n",
            "      (_emb_modules): ModuleList(\n",
            "        (0): BatchedFusedEmbeddingBag(\n",
            "          (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "   (_output_dists): \n",
            "   TwPooledEmbeddingDist()\n",
            "  (embedding_bags): ModuleDict(\n",
            "    (product_table): Module()\n",
            "    (user_table): Module()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "env = ShardingEnv.from_process_group(pg)\n",
        "\n",
        "# Shard the EmbeddingBagCollection module using the EmbeddingBagCollectionSharder\n",
        "sharded_ebc = sharder.shard(ebc, plan.plan[\"\"], env, torch.device(\"cuda\"))\n",
        "\n",
        "print(f\"Sharded EBC Module: {sharded_ebc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "QBLpkKYIcspC",
        "language": "markdown",
        "originalKey": "3ba44a6d-a6f7-4da2-83a6-e8ac974c64ac",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "#### Awaitable\n",
        "Remember that TorchRec is a highly optimized library for distributed embeddings. A concept that TorchRec introduces to enable higher performance for training on GPU is a [`LazyAwaitable`](https://pytorch.org/torchrec/torchrec.distributed.html#torchrec.distributed.types.LazyAwaitable). You will see `LazyAwaitable` types as outputs of various sharded TorchRec modules. All a `LazyAwaitable` does is delay calculating some result as long as possible, and it does it by acting like an async type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000147687,
        "executionStopTime": 1726000147874,
        "id": "rwYzKwyNcspC",
        "language": "python",
        "originalKey": "e450dc00-bd30-4bc2-8c71-4c01979b0948",
        "output": {
          "id": 959409226201271,
          "loadingStatus": "loaded"
        },
        "outputId": "ac678a80-cd99-4c88-a3a0-e8a7e38c73d2",
        "outputsInitialized": true,
        "requestMsgId": "e450dc00-bd30-4bc2-8c71-4c01979b0948",
        "serverExecutionDuration": 9.098757058382,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "\n",
        "from torchrec.distributed.types import LazyAwaitable\n",
        "\n",
        "\n",
        "# Demonstrate a LazyAwaitable type\n",
        "class ExampleAwaitable(LazyAwaitable[torch.Tensor]):\n",
        "    def __init__(self, size: List[int]) -> None:\n",
        "        super().__init__()\n",
        "        self._size = size\n",
        "\n",
        "    def _wait_impl(self) -> torch.Tensor:\n",
        "        return torch.ones(self._size)\n",
        "\n",
        "\n",
        "awaitable = ExampleAwaitable([3, 2])\n",
        "awaitable.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000147878,
        "executionStopTime": 1726000154861,
        "id": "cs41RfzGcspC",
        "language": "python",
        "originalKey": "c958c791-a62c-423a-9a95-1e6ae4e8fbd9",
        "output": {
          "id": 383713518112995,
          "loadingStatus": "loaded"
        },
        "outputId": "f3f27715-6fec-4465-c962-569ee9ed7a01",
        "outputsInitialized": true,
        "requestMsgId": "c958c791-a62c-423a-9a95-1e6ae4e8fbd9",
        "serverExecutionDuration": 6806.3651248813,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torchrec.distributed.embeddingbag.EmbeddingBagCollectionAwaitable object at 0x7f4f6ef31120>\n"
          ]
        }
      ],
      "source": [
        "kjt = kjt.to(\"cuda\")\n",
        "output = sharded_ebc(kjt)\n",
        "# The output of our sharded EmbeddingBagCollection module is a an Awaitable?\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000154865,
        "executionStopTime": 1726000155069,
        "id": "_1sdt75rcspG",
        "language": "python",
        "originalKey": "6f2957f2-2e7e-47e4-9237-f0b6c8b0da94",
        "output": {
          "id": 534532578992110,
          "loadingStatus": "loaded"
        },
        "outputId": "e1288888-2584-4185-f851-670df9ba303c",
        "outputsInitialized": true,
        "requestMsgId": "6f2957f2-2e7e-47e4-9237-f0b6c8b0da94",
        "serverExecutionDuration": 6.0432851314545,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchrec.sparse.jagged_tensor.KeyedTensor'>\n",
            "['product', 'user']\n",
            "torch.Size([2, 128])\n",
            "product torch.Size([2, 64])\n",
            "user torch.Size([2, 64])\n"
          ]
        }
      ],
      "source": [
        "kt = output.wait()\n",
        "# Now we have out KeyedTensor after calling .wait()\n",
        "# If you are confused as to why we have a KeyedTensor output,\n",
        "# give yourself a refresher on the unsharded EmbeddingBagCollection module\n",
        "print(type(kt))\n",
        "\n",
        "print(kt.keys())\n",
        "\n",
        "print(kt.values().shape)\n",
        "\n",
        "# Same output format as unsharded EmbeddingBagCollection\n",
        "result_dict = kt.to_dict()\n",
        "for key, embedding in result_dict.items():\n",
        "    print(key, embedding.shape)"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAAGOCAYAAABbgKbDAAABUWlDQ1BJQ0MgUHJvZmlsZQAAKJFjYGBSSSwoyGESYGDIzSspCnJ3UoiIjFJgf8HAySDEIMZgwiCemFxc4BgQ4MMABDAaFXy7xsAIoi/rgszClMcLOFNSi5OB9AcgjksuKCphYGAMALKVy0sKQGwgZhApAjoKyO4AsdMh7DkgdhKEvQGsJiTIGcg+AmQnJCGx05HYULtAgKU0wBjFISWpFSC7GJydDRhAYQAR/RwI9huj2BmEWPN9Bgbb/f///9+NEPPaj2JGfkFlUWZ6RomCIzBEUhU885L1dBSMDIxMGMg0e6M5AwPXToSYhgUDgyAXA8OJncmlRWVQL2gBcQ3DD8Y5TKXMzSwn2fw4hLgkeJL4vgieF/kmkSWjp+CsskYzS6/O+LXlZvtrbuG+ZiFlMeIpsjltpWF1vR06k8zmrF7es+n2vpmnjl9PfVL+8ef//wB4W3cixTZUjwAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAADOKADAAQAAAABAAABjgAAAACQwrkaAABAAElEQVR4Aex9BXwc17X+EeyKGS1bki2ZGWI7DjMnTSkpwyszvz5oX9vXNu2/mLavjGmbYto02KRhsB3HMbNlybJsixl2tdJK+z/fXd/ZmdWutCtLWtA5v99qZu7cufDdmdH95sBN8LCQiCAgCAgCgoAgIAgIAoKAICAICAJxgEBiHPRBuiAICAKCgCAgCAgCgoAgIAgIAoKAQkAIjtwIgoAgIAgIAoKAICAICAKCgCAQNwgIwYmboZSOCAKCgCAgCAgCgoAgIAgIAoKAEBy5BwQBQUAQEAQEAUFAEBAEBAFBIG4QEIITN0MpHREEBAFBQBAQBAQBQUAQEAQEASE4cg8IAoKAICAICAKCgCAgCAgCgkDcICAEJ26GUjoiCAgCgoAgIAgIAoKAICAICAJCcOQeEAQEAUFAEBAEBAFBQBAQBASBuEFACE7cDKV0RBAQBAQBQUAQEAQEAUFAEBAEhODIPSAICAKCgCAgCAgCgoAgIAgIAnGDgBCcuBlK6YggIAgIAoKAICAICAKCgCAgCCRHAwSDu15Do85eS1OSyy4ne9XnLWlyIAgIAoKAICAICAKCgCAgCAgCgsB4CEQFwSHPKLfRY22nSrMmyZEgIAgIAoKAICAICAKCgCAgCEwvAkMnv0ajPfstlSRmLSF79RctadF6EB0EJ1rRkXYJAoKAICAICAKCgCAgCAgCswwBz2ADjfa3WnqdkJxmOY7mA/HBiebRkbYJAoKAICAICAKCgCAgCAgCgkBYCAjBCQsuySwICAKCgCAgCAgCgoAgIAgIAtGMgBAcjI7HQ57hjmgeJ2mbICAICAKCgCAgCAgCgsAsRkDmqqEP/uwmOExsRjqfoMG9byB38x9CR01yCgKCgCAgCAgCgoAgIAgIAjOIgOvQh8l17JM06qidwVpjs6rZGWQAxKbrSRo+9QsaHWhXI5dUGJsDKK0WBAQBQUAQEAQEAUFAEJgNCIzSSNs+/r2PkopWk638Q5SYXj0bOh52H2cXwQlAbMJGTC4QBAQBQUAQiBgCw64eSrJlUGLi1P778vD/B/dQL9lSciLWN6lYEBAEBIHQEOAP9UJ0xoVqav9DjFtVBE8KsYkg+FL1dCAwPNhFL//9DSEVnZJeQBfcPnMmmDXb76LWk8+ptuXPXU/LLv9aSO2c7kyYGO/8+xvZ5W4kQFUJlJScQsn2NMoqWkbzlr+ZMvIWBsg3fUkHn/ok9bQcUhWULrqeqjd+cvoqi0DJHaefp6MvfNWo+aI3PkYJCQnG8Xg7Pa376MT2/0ddTTU0MuxW16XnFdCCDe+msiV3hFyOfx3dLXuo8cifqa/9GPV1nKWRoWFKTrFTZv48yileRgsu+BilpBf5X3Zex+6hAWqpe5jmLr3TKGcmnpnB/iba9eA7jDrX3PB97ucS41h2BAFBIBYREKITbNTim+AYxObnbIomQQSC3QSSHnsIjI66qb/DGp8+WC/cQ85gp6Yl3ckTKd22tKyz01LHZAodcQ/yRLZpwks7Th+jU3seoLU33UXFVTdMmH+qMjh7zxq4Dc6ZuJ1TVe9MleMe6jP6560TiztPTHD62g/Ty397F426fcQU2paBznY6+MTXadjZQfPXfTCsbnhGR6j2le9Q3ct/ZMJrXWTa7Rqi7qY69Ws89iQtu+KzNGfRq8MqP1Bm1NN47K90fNv3yGZPtRCcmXhmRkeHLfjjeRARBASBeEFAiI7/SMZnkAEQGxU84E5yHf66kBv/UZdjQUAQGBcBTEb3PfY5crt6x80nJ6cfgfo9PzHITZLdxmTmVVRYudKo+MSOXzNJGTWOQ9mp3XU31e74wxhy43/t8KCL9j/2v0xM7vM/FfZx/Z4fMSH7Gg0NOMK+Vi4QBAQBQSA0BLxEZ3D3+zgYwSc4GMGJ0C6Lw1zxpcEBsVHBA0RjE4f3qnRpHASqN7+ZvzK/KmCOhERbwPTpSqy+4ONUtvh2VbwtLXqjdyzc8nY2b3q9aifM1lwDLXRy1w+p7eQ+lTY6MkIdZ1+kkqqbpgsqKTcEBBw9p41ceXOW0JJLvkjQYD75k83kGWGHWzZZc/Y2UHrOfCPfeDu9bQdYc3OvJUvlmptp3sq3UXp2JQ101xJIVePRF4w8x178DhXPv57N17KMtHB3RtzBNakz8cykZc2jDbd9y2h2Rk6VsS87goAgEG8IgOjs59/7ORjBqnPBCGbW7DrSiMYHwRFiE+n7SOqPMAIpGcXsM7Jo3FYM9jdS/e4fqTwJSXZauPkz7HeSZlxz7MUvkocnjpA5S15HOSVr1T7+DHTV0umDvyFH9ykaZHPPZFsapWQUUtGCa6i0+lZKZP8VLT2te6i3Za86zC3bxL4Ma9T+2aPs69B6QO3PWXqHKgNfxrub9qov8NnFy6ly9bspLbtcF2Vsm078g9pPPk39nScpPbecCisupaL511Hdzu9687Avx9JLv2zkD2UnJb2Q0rLmGlnTsyso7cqv03MnbzTSXAPNxj52htgc6vSh31Fv8z7GwRuB0Z6WQ9lFy6mC245x8BeYWDUd/xubB9UwiepQuGVxXytW/VtI/h2tdY9R55kXjWKz52yg3qZdxnHFmvfw5L5SHTu6T1LD/l8a56p5jLXTfHfzK9R8/B/qnI39sqov+ITa72h4jhqP30+DfU00PNjHfkjplJpVQiULb7aQu4HuOjq9/1fe69MKeAyupJN8P7kG2ii//EL2W3qLgWfj8b9T+6ln2IyMxytnLmtcrqAk++TIQXbRUr5H6lW97Q2HqKd1P7U3PKXIDRKTU1O43rH3jLogwJ9T+37J97nPLG3pZR+kSsZQS1bhclp17fd5nL7ChPdvKnnI4aS6Xd+jxRd9jsnUGTq19ycqPcmeQVUbPkZnj/6JOk9vo8H+Nspm352ypa+j3NILdJFUy/dpe72PMLkc/XT0+c9RcloeLdz4Ke5T4Gem9pXv0rCjQ5VTsebdfA8dY/+2x9nUsoaf90oqqrqG5iy8nUmegxoO/Jq6zu6gYdcA5ZWtpdJFt/N9ucpog5t90DAmkITEJG7fJrVf89LX2PdoQO0H+5ORv4jKV77dON1a9zi1nXpStSPZls5+a0uopPoWLnODkQc7p/b9nJw9p1Ra6eLXUPvpZxQOadllnP8GKl14myW/HAgCgsBUIzB7iU5sExwhNlP9JEh5cYyAy9HOE45HjB5iwqInxkhs2P8wQWsBySpebRCcs0f+SAef+qZaEFedNP7UUnPNDmpf+hytvvYHRmo7T5ibjnon5I6eBmMS017/jMqPjH082e9pPamcuvWFXWdP0NlD/6SNr/kVT8y8Jkjwldj/xEd4Yr5dZ6Pe1jPqOKf0z9TT7J084WS4BMco0LTTzpM2sxTMu9w4xAT/5b+9hTDZtcoZnjgeYjOmx+iCV/3KEpygbtf36cRL9/CE2mRC1dZIbfX72c/nPg7+8GPLRNhaLlHH6Rdo7z//27jelp5G5aveyQ733+OJY4/KnpJZQgvWf0Ttt9Q9ahnjvLlbeCJ5szp3+tC91Hj4WbWfW1alCM7RF7/A7XhQpVn/1FLTsW3sZL+HFm/5b3VqsO+spexT+/7C/i9ePw4QkMKKq5gUlND+xz9ILSd2GsX1tp7lcX+Z0PbJCMh2w/7HvJfyO/+lP/sm2kgsW3ylmrCHWnY/kwMt6bn5imjqY/O2ijWRZw49zKTPpZK7mvaorcvRYuCQkJTIY7TDch/2tDTQmYP/IhAnkF5I49GH+ONAl9rHH/j54FlMy85WBCfYM9N4xHddd/N+DkLh02bhOWg6tpV61+9jcvUy9fJ9pQU+RA0HHqLNr/0NgbBBhtkHyvz8g3Dg48PpQw8xifK/p3VJ3m1hxXJFcEZHhujQ05+2aLeQo+P0EdZ6PUDQJIOwaWmueUz5MuG4qeZp49nBczvs7DbeDTq/bAUBQWC6EJh9RCc2fXBAbMTHZrqeAik3BhFoqfknHePJqv8PX53PR/Bl+PAz3zbIDXwgckrKyZaWahQLMtNc+5BxHMpO55njitxggpiQ6HM0d3MUq5O7fGTpzOHfW8gNytZ1m8lNKHX652nY/0fa++i7ac+j76LdD7+Dtv7hBjr0FPf1nBRWrmCyUq0P6ciznzMmaEhMZiw4fJdxfrCvj7/y+9qOr+U129g/xExujNykTKt2P/JRCubsDc3Pnkc/ZVyP+i647WeqTSVVPuLVVv+8UWrn6a3GPnY6z3iP4VPUXv+yca504XUckWynldxwX1SfjFxEJ1+5T2ksTEnGriY3SEjLzqG8ORuZEPzWQm5wTo/XRJNo5A0k0ArMWXJxoFOspdjEJmtfCnguUCJ8dfo7W4xTRZVbgpKjZHsma0K85AAXOLrHBn6AiZy+D80R4YD3ked/xBqXo0ZdgXagSQlVNLnBM2iW+t3/MMiNuQ2ICHeY79kpkXP3ef3eH48hN0b53Ofal37P5P0JI8m84/9hYM5S0d6Y8ZF9QWBmEPASncHd7497H53Y0uCA2EyTj427gSdoXL6IIDATCNgqPjql1XScPspfUcdOptJz85QJzWQr62nda2h1UMaWO/9EGblVyjn7lX+8gSdW9fyFuIIG2WwnXKlYfQOb/Hyey3fR9r+82tBIwAxNy4kdP9O7bDaVxRqSX6sJPsjDnkc+zdeaNCNGztB2+viLN36BBHWtu9lrjoXzCO072N/qJTT8nlhy6fto/tr3q/RXHnizMcl1dDcYxR3b+jVjPzUrkxZf8ikqrryOv6z/ko5v9ZaNSX9L3SOshXitkRc7rv4W2vXQ+wwNV2JyEq2/9QeGZquY/YLqz2leuptquR39lJiUQp2Nxy3ldJ7dpY572RZ7yOEwzhVX3cJE5EEVEhnaBPT3ojc8QLbUPGqpfYSJn29i7GCflLTseca1egcT7SUXf4hcznZKTfea5tW+/At9mlIyM5RGKzN/MWu4nmYS+RmDrBmZJtgBUTjBJlTNNdvG5MwqKqM1N/x0TPp4CQ7WwmktJfKlBuiX+fq07Ll86NXcYILudvWZT6t9aKbW3XQ3a+I2KlPEA0/c5f1fgrbv+BZH4/sFbbj1l6w9+ZmhiQLp2/Sa3zD+uWPKGy9h7U1fURo5lHX0+R8bWTEWF77uHtaglXJwjA8pjQpO9ndM/Fyuu/E7yqcpARHtEhKpu/llJua/McpO5I8QVRs/ypqsLjYJ/b2RXlC+jJZf9XW+KoE1vJ9mMu2992peupvNR6818pl3iqvXc2TC61jjtJXNH281n5rU/nDD9yd1nVwkCMQqAqP9XtPo829//Gt0YoPg8D+K6SI2+iaBk/FwwwP6ULaCwLQiMNUEZ7oaiwmTWbb+nn0Lyqopf95mWnjhp5R5VQJPisIVe0YGk4Qvq8Uak9iGv2zJTVTLIXshQ85+tXUNtFom5dUb32NoVAorr6S5y6+l0wceV3mn+g+0MTvuey2tvu67XOdC1mxk0CVveVJpWwb7zrAfUDU52WSrq2kH+4IMG9W7h7wkAoSjv6PNSK/a+F7lK4GE+es+xP4ujWRnc67sguWUy5oPf2mrP2BJWnvDXaxN2Gyk4Ro7T6wx6YY/Scfp55ic5BvRxnRGhOuGaaL5q3p28VzlKzN/3Qe4LR9Q/UhKTmU/qjTuD0ydrHUPD4+d1KP8BevfYPHL8I6XU1dN1Zvex+usLFbHhZVXsRbmEl5zxqdtMjKOs3PomU+z2eLTAXOAnJ45fC/7MZVQw75fU07ZeiqYe4kFJ/8LYWJlkYmir/nd2yNMxv1l4ab3sPZqk0ouY3M6kG+Y90F622rUNj13AWuyCtQ+/thT08Neg6a4ap1hbljEAQ/MBGfB+jdSZsEyVX7JwusNguPmAAwTSV7ZhUaW/o4jrLW71zjGzsrr/kf1D+aSCOigZcGGD3BQhgp1OH/tu5jgfFbtY1zgq2Y39RcnsL7QqqvvVoEazGsAqYsm+Uf+Z08SOLlMEDAQiF+iE90EZwaIjTHGsiMIxDACMNXJZedzf0ked1V2q8YSX8v9BdqabP5Sru37kQe+MvjV7rhX+VUsWPcmDg7wHkugAf9y/I8z8+ZaVqKH5kDL6DmTLkePT5ODc1mFq3QWtc0pXX9eBAcapOIqDijAfYIWaZhXsW+rf9owiYOPw/Ftd1k0OZ1nXmATnfuo8+xBC/myNIwPBrpOWJKyTW0HIQx38dOBnjoqMpWIMooWXMST/6dUalv9U6wxKTFywFRJj2dn44tsnuYjFiULfV/XQX6aa/7B/X5W+UoENqcbe1+govx5lxr1Ycd/vHKK11rO55auC4vgdHBgBTO5gb9MFZPcQ09/0wgwcOTZ71JqZhbX3c2BBw5TT8Uu2vCqP1jqNR+kmoJKIH2QI+eNJwgooAVaEgSmcPae0klqmzfHRzyRkDd3s0FwnEyUR5kAJyZZzcosBYR4kJHvM5fERwGzZJ0jN0hLTsn2nQrwTPtOWvcGOaDGrofey9pAH2FffPG7mJi/SmV08D1olr3//LSxwKp+ZvV5LCrqT3ByiqsVudF5ZCsICALRhMBYohNNrZtMW6Ka4Iw6T5L77O9lHZvJjKxcM6sQyC+/mMpXvC2sPuuIabgIk+HAk1ui9bfdQwf+9VHjq7C5EphYHd/6S46mdIS1HT80nxp3P4mjsJklkaO6+cuYsLomfxfkNfsb+F8bynFW0QoqKL/MkhVf4BMSPqyct3Gi/RSH2WQ/JEwoj2+/i79u/9WSPzEpieBHBH8HiNZmYVFLi/hpAiznQjio3fErFdLaPGksrb7RIDjtDTt5ou/TECy66F08Ll5zsZbjD1uc00vYPA2CyHi7Hvw3nrBb1/qBP42z1xvAAPkSEgL7iaT6afdG/RaO9B9TaIjCkeYaX/ADjPWm1/yRTbCK+V4dpUNPflMVBXMzkBstJQuZsI4jiCgH8zDtP9R5eqe69wPdS/CN6m72mX1m5PoIpLkK/2sTk3z+aVw4E5yhKSE45oiH/mOSZMvwNcnvOfGdCL4HE8zdD76TNYte7Slyzlt5LWvpPmxcNDTYaexjB6aNwcTFERvpXKAQnQdRF0UEAUEg2hHgd1bbQXIn/Y4nBqPR3thx2xfVBCcxvYpSVt1DIz3byN3wU976vqaN2ys5KQgIAmMQ8J+ImZ3bh/0mL+aL8dX6gtv/oEyZWjlKV+fZl1iDc8iILoW8MMlZcaWXCJivDbYfinO1f+jf/o7DRshplNvT7PWNCFbHZNPtHEJZCybQWBfFlpJnITdF81cTTHRySjZQHYfy1eZ1TAfUpek5C3QRauvsree2rzbSTuz4Bvs9DLNZ0VLKLV7PJm/W/MiICWbjkad4gjyqvqof3/41WnnVt4wyoEGBVgHkytXfr344mZKZqUzHarZxOGSeYLfUev1wcC6zoMgw80OEN01ukmzJHIXuoxzO+Wrlx/Gv//NpAxMosAkiQo2bJe1cqGqdhvDAmflL9CETkXpjP5Sdwd6zRjb4kukQ3POWvYl9pw6xWdqjxnnswASq9Jy2wXLC7yC7sJLJ+jGV2tfexNG9/j7GBwonG/b/3LIoZ1bhIr+SvIeIrqfNw5ACE0YtIFMwb/SXMBQrvkvHIS6aWPsyh76HSIX7Hnsff6TwhUTHQqrLL/f5kKG01My5lkJXXvPv7LsVODx3Zv5SS14c+N8vYzJIgiAgCEQUAbzrk0o3k23eByghdS65jnwgou0538qjmuDoziXlXERJqy6adqKTMAVmBLrNshUEog0B+CqYpbd9v+G03shr1AQSrO/ReOR+nuQ3Kg3PpW99XK0ZgklR7c5vmyb2MPdpVgEIApUzmTSsh4OoXtpkpu6Vn7PG5XKeaJURzJfOHJpa/xv0qa3+SQ73/ITRXGhoMFnDJNgsyy7/irFeT1ejj0CAtEBgCoXAAKNub9jtU/vuoeIFN6ov+f2dxy24LdjwGhVswVw+nLFXXPkNJlZf5qhy3rphjlax6qAxZtCQFM3fwCZ1L5kvpYJ56xi3TMouqTCCH+gMxVVX6V0mqfuM/eKqTTRvxVvVcefZ7UY6dkZGx/qdID3Jn+DwZDchMdHQBJ7a9ysqYN+bxMRkJsPdHDrZp5HB9RNJStYcznJYZRvo6uQJ+GEj5HHZ0jvHEBxoS/rYh8TsqxSojurNn2SC8z7j1MEn7yI3O9DPW/kO1dZRt4vqdv+Ax8hn6ob7oHrjJ4xrzDsnd/2UiiqvUSaa0PadPfyAcTo9u9jYN5MQmK1Fixx69rMqzLluTw7fN2tv/OmY6HL+62y5HK00d9kb1WV4T9Tt/BmHnS/j52UhZbFvmb8kTcP/V/mf7Y+yHMc7Amafz6nqqz+xmapyI11OTBAcDdJ0Eh1b5e280utHdFWyFQTiDgF8AcdXbm1acuyF73Ho25McHayZmnk9jcCSaERHwvldD76dncVv5om7i1rrnjEusWGxxXMOx0biee5gAl++6lZjgo91RF747W2UyNoG97m1Sc6nisPPfIdDP9+tighmoldQsVKREps9x1LV0Re+QMXV1zMG/7LgM+xyqHzQllWsvo0XVr1fHXc31tH2P9/C2hPWHjTstZRVtvQOyzEO7Gn5Kq1qA6/FcvhRw6Tq6PNfpE2vvc/IX8yLJfoTnPzyS9T5woqLxhAcLMaoBQt6sh5MHbbVv8JRvn5O7uEB1lxYzfCwQGRg8Wqr9Dlo5eat8AV+gJZkx19fzQ7qa3hxyhfH9VnSZZi3xfOvMUzwkL79T29hv5+lyjSx48wRc1a1DyK88/4P8Fosb+M1fj4+5rxOQECAucuvZCLivX8R6vnIcz+koy/+mNIys1lT2cMkzep3VLXxzQah1eXoLcI3b//LbUwsN7If0HZDK4bz5avfpLPxfZRi7COIxZ6H38l4O2jjqwN/XDAyT+MOAiJoPy5dDdbxefrnVtNNnLvqPc/zIqZzeR0qr2atZvs9fH/tU4Sm4cAD6r2CZ3RkeJADXuTq4kxb6/1iOjHp3bQtj036WrlQEIhFBAb33klTFUktXomNHtfAtgf6bJRuQXRgupay6iuUlDMvSlspzRIEog+B4qotRqNAdLDOCdax0Q7pxslzO3MWvZq1Jj5zEywgeOTZH/B6Oz+zmLQsvPB9lqAB/uVM9hgT/Nw5VcblMBnT5AbagvMRTGJRHn6B/I/gi7Ly6m+rKrBgJqKWaWmt20MHn/g6tdbu1klqi6hmcNyHVPOChzCt0oKIZlgAU2ukkA7tjdmMS+fV2+SULFq4+b36kLoaeXFVDu+spaiCNQfsA2QW7Vekt/pcWk6Oof1BWsmi6/QpNTk9yuu2nOBJ69CAl6Tpk/3tPj8UnRZsW73p05YFPRGoAYtLmn16gl3rn15cxSvdL/bdr7hHsaAkggmYCUgyk2stSHd01enDoNull/4vlS21BkkA0YE/j7lsZlMcae5VFl+UQIVibNFPaJq0QBNStsRHXrOLVulTatt6cq8ix6Ojbkv6TB643T6fG3O9+rkwb3F+6WVfIANvHg88B3Xsl6Y/muDc6uu/z7BZ70lz2bIvCAgCkUUAxCa59CJK3XgP2Rd+RZmjRbZF01N7TL+FknK2CNGZnvtCSo1yBPwduENt7oorv8mLI25WjvH6mvScXI4UdheHf67SSUZENER/WnfLr6nqgtf7JjZGLmKNRD6tvvGLbDr1TiPV/KXaSOSdxGTfRNScjn3zOTNxwQT/gtvvVZPMrMJSZQKF9U8WXvhWWnntfxnF+E/yjROmHX/HbNMpeNIrTGASB1JSseYm1pT8wYgEBef0dTd/n/vr88/B9Rn58E/6HgchOKcM50lfe8NTqmj4Xmy58yGau4LNtNjEySxYO2Xppe+nRVs+ZyQnBcEHwSNQj5YTL31f7yr/joLyFcYx8mnn/5zSC5SPjj5ZUnWF3lXbqvUfocq1t3DXfV/WETABaQt4vLW01W9Tu+YxQkKgSSz8tS668z6OJLZQX662mOxfeOdvfGmqTl+9vhPWvTXX/4hWXPVJC7nUOXDfrrnpf+nKd71IVZveoPqRWVBCy6/8fzpL0C1M+FZd+31eW+gbrJWYx/efdXzg24TnYdNrf8oLiX5RafGCFbbq+s8rvyd9HgvXli27nDa+5k8WbPPnXWIhbMgPQgANWbBnJpivmv/z7z82ui3mrf815nMT7eMewfODxVy33PFnNgOsHkOs8Xyuu+k7yoRUl5eUbNe7/OzGlMGI0W7ZEQTiBQErsfkyJaSUxUvXAvYjgb+KWXXxAbNNb+LgK7fT6GCfpZLkOZeRvfoLlrSJDkZ6tnMwgp9MKhiBmKhNhK6cjycEYGLW235AOQ6nZsLXYWKBjwrCvw72n+EJYZpaA8Mc3nniEsLPUbP9LiYeNl63ZR7b9y/gidWFRiH1e36sNElIAGG46l3eibiRYRp2EMHL2XuaMWhksrOQwwabgzcHrxDXwRxwyNmmHLOBeSCCELyE6TuDxSsRSAETUAQ9gM/MVMgwT9z7O46yhmqxWkD0fMsccnayhqSG22lTZYKkmKWnZS8T0sKAi5Ka8wXax79BZ28Dj+tZvr5SrRMUKB/Supt3sendu43Tl73jYZVfjS8H68gqXEFYVyiYQMPn6D6h7oM0v7DVwa6JxnRonhw8HsO85hOez1DfI9HYF2mTIBArCEzGRM1rinYhu2Fw8IAwSA2CDIx0HLdAk5RbSSkrf2VJi9aDqflPFiW9g0YnadUWJjiTJzpR0hVphiAwrQjgi28uf+EPR/A1GSvaB1rVPpxywsnbevJZy4KZK67+FJtZreMJ+XE6ufv3RlHZBZXG/nTugJSkc7Qw/MIRXJeRV61+4Vw3E3mhJcspWTvlVUHrNZHDfziVwi/JnmZdc8Z8/fn0ARqKyYyruX5EwkunBeakgPvQcuEX6wIibI4eF+v9kfYLAvGGwGSJTbzgEFcERw+KEB2NhGwFgdhGoGjB5UxwfE71h57y+sT492rB+vf7J8mxICAICAKCgCAw6xCY7cRGD3hcEhzdOSE6GgnZCgKxicDCTf/OZkMc5e34Vqvz97nuwPdm/oY7qKDi8tjsoLRaEBAEBAFBQBCYAgSE2FhBjGuCo7sqREcjIVtBILYQQJCD1df+gJZc1Mpr1DyuIpS5h/qU7wvCUsORPjXDur5PbPVQWhtrCGQXruTAEgj04FFNT2G/HxFBQBAQBCKFgBCbwMjPCoKjuy5ERyMhW0EgthDAGj56IcrYarm0Nt4QgP9aQbk1xHS89VH6IwgIAtGPgBCb8cdoVhEcDYUQHY2EbAUBQUAQEAQEAUFAEBAEYgUBITahjdSsJDgaGh/ReYlopF8ny1YQEAQEAUFAEBAEBAFBQBCIKgSSi2+gpGXXhxXuOao6MIONmdUER+OclONbW0OnyVYQEAQEAUFAEBAEBAFBQBCIFgSSy3yLakdLm6K1HYnR2jBplyAgCAgCgoAgIAgIAoKAICAICALhIiAEJ1zEJL8gIAgIAoKAICAICAKCgCAgCEQtAkJwonZopGGCgCAgCAgCgoAgIAgIAoKAIBAuAkJwwkVM8gsCgoAgIAgIAoKAICAICAKCQNQiIAQnaodGGiYICAKCgCAgCAgCgoAgIAgIAuEiEBVR1GyLPsNhmh2WtiekVFiO5UAQEAQEAUFAEBAEBAFBQBAQBASBiRCICoKTlHPxRO2U84KAICAICAKCgCAgCAgCgoAgMAMIJBXeSInpiy01JaSVW46j+SDBwxLNDZS2CQKCgCAgCAgCgoAgIAgIAoKAIBAqAuKDEypSkk8QEAQEAUFAEBAEBAFBQBAQBKIeASE4UT9E0kBBQBAQBAQBQUAQEAQEAUFAEAgVASE4oSIl+QQBQUAQEAQEAUFAEBAEBAFBIOoREIIT9UMkDRQEBAFBQBAQBAQBQUAQEAQEgVAREIITKlKSTxAQBAQBQUAQEAQEAUFAEBAEoh4BIThRP0TSQEFAEBAEBAFBQBAQBAQBQUAQCBUBITihIhWj+Wpqauhzn/scXXjhhTRv3jzKysqiDRs20Dvf+U765S9/SaOjoxHrmcvlole96lV00003UU9Pj2pHXV2dOn71q1894+1qbm6mxsbGsOr94x//SO94xzto3bp1Cts1a9bQ2972NvrhD39IIyMjYZU12cyHDh2yXPrlL39ZYfi3v/3Nki4HgRHAfXjffffRa17zGlq+fDnl5OSoZwX35X/8x3/QsWPHAl84Q6m/+93v1Hj+6Ec/MmqM5Bj7329GoybYefbZZ1U/gOu//vWvCXLLaTMC/u+mSL4nze2SfUFAEBAEohYBrIMjEn8I8OTa84UvfMGTmJiIdY6C/i6//HJPQ0NDRABgUmO0q7W1VbVhz549Ki09PX1G28STR092drbn0UcfDanewcFBD5NEo/2BML766qs97e3tIZU3mUynTp3yoI5NmzZZLmfSqNr1jW98w5IuB2MROHz4sGfZsmXjjiPuxZ/85CdjL56hlE984hOqfR/84AeNGiMxxsHuN6NRE+zwRwsDZ9y3IqEhEOjdFKn3ZGgtllyCgCAgCEQeAdHgRC31PL+GfehDH6IvfelLSkODr9LQ1rz88stKQ/HUU0/RZz7zGUpKSqLnnnuOrrzyyhnTNkzUq7y8PLr++uvpmmuumSjrlJ7/7ne/S729vSGXiS/ov/71r8lms9FnP/tZhW19fT298sor9MUvfpF4UkzAeTo1US+++KKqw7/RGzduVBguWLDA/5QcmxA4ceIEbd68mY4cOaKehY997GP08MMPE8aRiQ/de++9tHLlSnI4HPT+97+f7rnnHtPVkd2NxBgHu99CQYI/YChskZc/utDTTz9Nx48fD+XSWZ8n0LspUu/JWT8YAoAgIAjEDgKR51jSgqlG4PHHHze+lL773e/2QNsQSNhkxMMkR+X985//HCjLtKYF0uBMa4XjFL5o0SKFQ6gaHJ74qvzf/OY3A5bKZoHqfEJCgqepqSlgnvNN5Am4qsNfg3O+5c6G69k003PJJZco/AoKCjwvvfRSwG4zufHccsstKh9/KPDgupmWQBqcmW4D6juf++1b3/qWwvDGG2/03HzzzWof/RKZGIFw300Tlyg5BAFBQBCIfwSSY4eKSUtDReBrX/uaysqmN8oXxG63B7yUzdPojjvuIPiR/PznP1f7yMgTcvrDH/5Aixcvpurqavrxj39Mw8PDyl/muuuuU1+729ra6MEHH6SjR49SbW0tJScnK/+FN73pTeo6/wr7+/uVtoEJhNIWXXbZZcoe3z8fvvTC5wC+Qu9973stp+Ev9Pe//5127txJ+PpeVVVFPLmn1772teqrsM7c0tJCv//972nhwoV0ww03qGu2bdtGaDN8ZF73utcRTxpU9jNnzhCTO+rq6lLHKB9f79/61rdScXGxLtKyhc8G8kAqKios5/TBxz/+ccKXV/jhQEt255136lNqC60BfGSwBXarV6+m2267zWiXzow80CjArwf7zzzzjPKnSklJoa1bt6psJ0+epG9/+9tqrG6//XZ64IEHFD4Yq1WrVqk8999/P8FuH/0CPv/85z+Vtqm0tJS2bNlCb3jDG4jJmK7W2GJ8H3vsMQJ+wIwnp1RSUkL/+Mc/aMWKFQpfI3MM7Tz//PMEjQTk7rvvVpqcQM1PS0sjJrH0yCOPqDEHDhdffLHKGmxscD/q+wKaCtyvwLGzs1Nhh3sfzwk0Gf6C+wrPCLSt0B4F0wAGGmNdFp5HPJt79+5VGty1a9cS7gs8y2YJ5574y1/+ojDA9f73m7nMYPu/+tWv1Ck8j/n5+aosaMTuuusuSk1NDXhZuPceNG3AG/c23jfwO3zLW96ingfc8/yxR/lXhfJ+C/Vdoxseat06fyjvz/HeTSgn2HvS7Xar9/euXbvo9OnT6j14wQUXqPee+Z4L5z2p2y1bQUAQEARiBoH453Czq4dnz541/G5C8RvgybOHJ3oeJjAGUNu3b1dfWOGbwJMRtc83tIdJhwdftJkQeXJzc410nNM/nnh7mBwZZWEHPj5FRUVGHp2Xgx0YaRP54PA/as8VV1xh5NdlYIt09FsLm4mpfDyx81x11VVjrsnMzDR8bZh8jDmPMnlyoIsLuGUTIXXd+vXrPTzhC5hnaGgoYPp//dd/eZjUjKmXJ3oeJkWWa9hcT+XT2gbdbzY/G3P9rbfeqq4N5J+htRBsuujBGOly9JbJkOUeQEFsxjgmH3y6dFt0fZYGx8jB+973PtU3JnghtZid4j0cgMKSN9jYsPmip7u72wNMNb7+W2jdnE6npTw2dRyTH/cEE3mVHooPzk9/+lMPfIb860Maf8Sw1BfOPcFmrGPKDHX89fsE2kz48bApqNHG3/zmN5Y26YNw7z28xwK9Y5iEG+8w/Uzr9gR7v4XzrkF7w6kb+UN9f473bgrmg3Pw4MGgPmUXXXSRhz9yoAlKwnlP6mtkKwgIAoJArCBAsdJQaWdoCPCXW2MismPHjtAu8sulJwCYJGFCC5MSjnzk+fCHP+zhL6MGuWE/GQ9rSjysSfBgUsdfiFXd5eXlHgQ5gGASp4kMJhvs46AI1dvf/najnahnIoKDYAjIN2fOHA8mRfv27VMmM2VlZSodpi9a9D9u5IcJHn819vDXTuUoztoHlR9tgfBXdQ9M+ubOnavSYVqGY9bS6OICbn/xi194MGFDHSAraB9/jfYAu2DEBgXxl2x1Da5DkAJMYvirs+f1r3+9kf7QQw8ZdepJNPKzVsDDmhzP0qVLPRhnjvClrlmyZIlqM3/9V9eNR3BQDvqKyTR/wfe8+c1vNurlr/RGvZiEIS/GH4QM9xLMGNEGpOMX6gTXKDSKdkBM0QfzfRNu84KNDSa8X/3qV1X5ICjYhzko8DPjbSYcOKfx/u///m8Pa3DUs6XvV5ybiOCwdk+VgbysqVPPJT5ewEwVabhfcX9q0QQH5ya6J1gLFfR+0+UF277nPe9R9ZsDC7BmRaWxD9SYy8K99/DRhaMYqvJgRohngzVtng984AMqDf3Dz5/gIM3//YbG4FnGuVDeNeHWHc77c7x3UyCCMzAwoN4NaDvei7/97W9Vn3GfwQwT6SDW+t0czntyzCBJgiAgCAgCUY6AEJwoH6Bwm4eIO/hHhok9/vn6C4cbVV/x8CWPTVnUj8291FdInddMcDARNsvPfvYzVT40OGxmYT7l+etf/6rOoX78c4bgnyuOOfSukaYveuMb32jkH4/gsNmYkQ+TOLOwo7JxDl/ZIeZ/3J///OfN2T1svmLkN7d/Mnbu8EnABBb9M/+gIWIzJctkEo2A/4bWiEGT4i8aD2hntK+HnkSzU/EYDUIwn4jxCA7KMfcb9bCJmmq/uU36a/hXvvIVSzPZbMb4+h7LBIfND1WfQd78BT5reD7MzwieFTwn8BvTEmxsgKkmzCAr/gJyjfvlox/9qHFK5/+f//kfIw07IK2YhCP/RASHzRxVPkzQ/YVN4tQ5fMXXoglOqPdEsPtNlxdoi0k3NL9oPz4yaOEAHCoN6bt379bJahvuvcch2VVZmMRDc2YWYIw68AtEcPzfb+G+a8KtO9z3J/oS6N0UiOB873vfU/1ks0qlKTPjwKG9Da2x1ppN5j1pLlP2BQFBQBCIZgTGGoHzfwKR2EWASY1qPE+KlK+Mf09Yc6J8V+C/Apt8/OCrMn/+fOro6PDPTshvFqyfAxt/dsqmwsJC4xRrLQj+Clr6+vrULv8jVluUg8g/Zvn3f/9382HQfUQjg/DEkNgcTe3rP/ALgR8OBH4V/gK7e7PAFl1LOFHT9DXmLfwo2OSG2CxI+SfBbwgC+3/4Z8DX4v/+7/+MS9h8RPlhIIGJl5GudxB9DcImb8Qmd2pf/7n22muJvyjrw0lv4YthHjf43bA2Q5Wn8WCTQuWvhAhx8CUyC0/ElT+QOS0W9/Vzgj76C+5ZPB/mZ0Q/J0xY/LOT/9gAU4w1TyCJCZQlP7DFswbRzwj8MfR4I5KbWeBHx0TSnBRwn8OR0/79+9U5RFD0F/iiQFgTR3hWzRLKPWHOH84+f/RQ/cSzgXWGtCByY2VlpTqEj5+Wydx7wBnCZofKx0aXha0//uZz2Pd/v4X7rgm37nDfn/7tHe8Yvn4QrMulfcB0fkTSZC2xOnzhhRd0srGdzvekUYnsCAKCgCAwgwhIkIEZBHsmqmLTBFUNggIcOHBALepprpe1C8TaFyMJTvB6osVfno107IAkYZJnFjjEIw3/TOE4DCd5hHvlr90qEIHOy6xe7bIpmdqyGZU+ZWzxTxeTQZ3XOOG3g8VKIVhgkL/S+p0lgzTofDoD2ooJuVkwudd1+k/0zPlC3UcgAgRDwA/OvfyVWDmJ/+AHP1CBCz7ykY8Qf5FWQQb4S7UqFk76+PkLyBpIIpv1Kad0LMyqBeemQvSk0lyWDqag8dDtxCQpIyPDnFXtw/k91gXPCe5bjJe/4L4xPyM4z5oIdX/7PyM4F2hscD2eEzwjqAN14QciokXf9/oZwX0CB3x/Ad4IKjCemO99TFYR1toseB9A8LzjWWUzR+N0KPeEkTnMHR1cAPcRR02zXI3nBYKAJhxljXgdKprMvaevARn0FzxneObNuOs8gd5vGsdQ3zXh1h3u+1O3NZStbgsClgQSpLP5n3q3mM/PxHvSXJ/sCwKCgCAwEwgIwZkJlGewDmhjtCB6E/u/6EO1xYrtZsE/8mATVqzojmhdZsEkGF9iEVVKCwgDJheILsUmaTpZbfF1GsKmXGpr/oPobiBcmmCZz5n3EVkNgglQoAl3oDTkR51Y62eqBZMgfKHXEch0+ZgoYF0V/DDBRMQofFXH5BRR1DChggRrL3DEORAcf0wCESJdbzhb4D2R6DHT7fXPH2gs/fNE+zGeExAOPCP+Ai2fjqqnz+Hrt/+zo88FGhv241JRq6DN04L7l83C1FpUejKKcxrvYLgGIvW6TL3VzwiO8dwGEk3a2MzOcjqUe8JyQYgHeE60VpVNY4nNswJeCfKIiGDQPGkswrn3JnMNGhLo/aZxDPVdE27d4b4/AwIWJFFj5v/O1tm1htn/3TJd70ldr2wFAUFAEIgEAt4ZVyRqljqnBQFMzuafM4FByGN8sZ2sYMLtL1//+tcVuQFxgPkHQu1iEgei9KlPfcrIrr90IywzBBMcf4GZkP8/W/88ONb9gZYEJizBfn/6058CXT7laZiMgeT5h7E2VwRzMoRkhsCcD6LNRgJhgfMgNvpLM77mR0pgjgVBOF2tZTC3BfjHumhzHYTK1ZPwqeoTJuwIRY7nAuZ/0FBw4AECseAAEkYYdf9nBJPrQHhjHCYS/YzgmcWzGOwZQToI+EwIFsKFQIuKd1Ggn26LNlObzL2nr+Eod2O6BS1RMPwCvd80jqG+a8KtO9z355gOjZOg3y+adPlnRchoSCTfLf5tkmNBQBAQBKYLASE404VshMrFP22OHqRqf+KJJ9R6G9oUJFCTMBkKR9iRX2WHGQxHh1JaGw5Bq9K0vw0OdJ3a5wUrxPuLtnf3T/c/xno8EKwPosvVeTBJxGQS/i4cFlsnh73Vkx096RyvAKxXA4EWBxgHE+0TgXVmINqUCcRO42i+FmvLQEAezSZE5jzm/XDabL5uon1o9OCbggm6v2kUCDPMXGJdsFaNNs2DVgXr2wQT+CbpyWGwPOZ0DtKhsEMa7lkOHmH4m4DAYH0aiL6XMdbQomB9pUD3RSjPCe4t3A8oHyTKX3Cfgmzh3g3ka+efP9BxOPcb7hOscwPhyHFqPR+s6eP/48iMKg/eQ/ANmcy9xxHUVBkcBGEMQcS9Gs5HnnDfNeHWrcc31PcnOhYq7vr9ot8jCpRzf4AB1kaCwJdRRBAQBASBeEdACE4cjjA0KbxWieoZFuiDEzH+6ekvezC/waQJWgi9ACXMG0Ix59J59ORdw4fJvp6sII0jUalTHGlKTZYx6YNfihZ8VeUwx/pw3O2//du/qTKwCCJHPbJMWLCYJhz6sTAiHJcnK9qsAwuITiQw+9NfSzl8NmFhVQQG0IIvyRzxSpndIE0TIvh96H0475s1IceOHaP//M//VEVw6GJLIABdrv9WtxkLAmJyPFWCiT8wh8CHCI7pEGgmOOQvaT8FlRijf2Cugwk4Jo/QIsKcEPcSTMcwGQTRxf2GexYTR41BoKAE/hDoZwTp2r9G58F9gQUsIfoZwbOHMYfg2TVrHDgyluGXojIE+YOPDFpj+OlPf1ppcXRWLDCKCTU+QMDHJxSTN32teRvO/QYTPa1R0e0yl6X3QTS1SR20OJO59z75yU8SzF1BHDlqmvEscGhuAhbhSLjvmnDr1vdGqO9PtF3jPtG7CUEWcC/hXYvFabWA9HJ0PuUvifpBOEUEAUFAEIh7BPjlJxKHCDCZUWvX8A0Mb3/jx+YJxr5OZ98ZI4QqoNBhohHS2F++853vGNdjPRYsmIhFANmOW4Uh5QmjOo+1KLT88pe/NK5BmNo77rjDw46/xjoyaAeb56jsPAlTebEwoVkQPle3F+u+IKQym4cYaeZwxjr8KX8VNxdh7Os2coAEIw1r5aB8nANGWLdkPEHIYKy5oduELfs4eBBy15zGE1Zj3QmUh3DDPKFTebBl8ulh0uNh3xuVhgVEzaFudSji73//+2Oaw6ZvRl3oK9YqgowXJpqduceU86UvfUmVw2TXOMeTbA9/TTfKByY8uTeO0UfUE+uCNVfY38LSL4wF7j/zOCIN69kghLSWYGPDhMkIE41yML4crcujF2flybgqG2vxaEH4aR0+Gs8GnhE8K+Y2TBQmGmPGBEFdg+cR61dhnR/soxycY+2NrtKjw0SHek8Eu9+MAk07/PFE1YnFdicSvV4NcMF7YDL3HkIk8+Re1YlygCH6bB5HvFsg473fcD6cdw3yh1P3ZN6fgd5Nwd6T/EFC9Rt9x9pAWG9IP8fAxxyqezLvSfRXRBAQBASBWEAAKn2ROEWAv0KrxTCvuuoqC5nAPz+QFxAT9g8Y03ss6qcnRP4n+eu2WuFeT9KQD/842UTMw1HbPHq9jXe9612WSzFBX7VqlfHPF5NKrMegCZcmOCgDZfoTHBSGxRA5sphRBvJh4om1LNh516iPv+SqPCAcgURP1FkTYZzGwqF6LRKUG4hQGJnP7WBSin6CaGnShGuBDZvmqf75X4Nj1twoMsJfU42+YGE+LOKp1w/S12GSijKxvpG/YHwxOdTlaEKKNXhwzTe+8Q3jEhAppN19991Gmt7Ri1JiEUqzYKKOCRP7UXn4K7IaP5AhrB2DsjB5igdh7ZuHv8R7OFiA6hf6hh9wxWr3IPEcxnlMV8cbGzxDel0aXR7uR/bB8LA5llEPm74Z5aIdGDvWLqnzuKeuuOIKtYguyjATnEBjjILwHIEcmZ9PXMu+LmrxS6My3gn3ngh2v5nLxD6eC/2Mffvb3/Y/PeZYv2/QTtaiqfOTufc48IkidHinYE0cEH5NBFA2PkpAdH0gfMEk1HeNvj7Uuifz/gz0bhrvPYm1xzTRRb8xFiDL7KOom6u2k3lPWgqQA0FAEBAEohiBBLSNX4IicY4AzIvgR8ATIBW+1hyCeDJdh38G1sOBHwEiqDEhCakYrBsDnwbYgcOcYjICR3xEwIKpzXwOqKBNOCZTlvkaPApoH0I18wTBsH035wm2DwdymOnhWvgR8AQzWFYjHWZlCLMN7LTtv3EyjB3UDb8KBDYwr0UURhGWrMAB5j3AlrUOlnM4YFKnwh/DHAgmVPEiMEtDAAg8J4iIh3sUEaYmK8AR5oMwRSwvLzfMGicqD5G2YG6FSG8wKZuM4LnEMwLzO4wh7uepkqm+38ztmsy9h/cQzG61L5O5PIylNieFqZ7/WlzmvIH2J3rXTLbucN+fk3k3wUQQ9x5/WAoauTFQnyVNEBAEBIF4QEAITjyMovRBEJhCBDCZgl8EJsdYqBFBHLSAkMGxGuQMTt1Y7FREEJgqBCZz77GWSPnaYCIPYmj+cMJaUeULBz8qEL6plkjWPdV9kfIEAUFAEIgnBGQdnHgaTemLIDAFCLBpFF1++eWEyHdwin/mmWcI0fAwebz//vsVuUGgBR0wYQqqlCIEAYXAZO49RFAEqcHCxtdccw2x6aA6RiAVrNeFc1/4whemBeFI1j0tHZJCBQFBQBCIEwREgxMnAyndEASmEgGYMiKyl3lBSl0+yA3CDodr7qOvl60gMB4Ck7n3EO0OERaxlpRZYGqI8PEwq5wuiWTd09UnKVcQEAQEgVhHQAhOrI+gtF8QmEYEoL1BSFtMOuGTgjV9AvnlTGMTpOhZikC49x7u0X/+859qUVX4ouFeheZxKvzSJhqCSNY9UdvkvCAgCAgCsxEBITizcdSlz4KAICAICAKCgCAgCAgCgkCcIjC5MFZxCoZ0SxAQBAQBQUAQEAQEAUFAEBAEYhsBCTIQ2+MnrRcEBAFBIKoQ4KWyfO1JIEpK5D8igoAgIAgIAoLADCIgJmozCLZUJQgIAoJAvCNw+yefsXTxH9+50nIsB4KAICAICAKCwHQjIBqc6UZYyo8qBGTyFVXDIY2JMwSwjo2IICAICAKCgCAQaQTEByfSIyD1CwKCgCAQJwiMjsZJR6QbgoAgIAgIAjGNgBCcmB4+abwgIAgIAtGDwPCIMJzoGQ1piSAgCAgCsxcBITizd+yl54zA6KiY1MiNIAhMFQLDwyNTVZSUIwgIAoKAICAITBoBITiThk4ujAcE5ItzPIyi9CFaEGjpHIyWpkg7BAFBQBAQBGYxAkJwZvHgS9eJOnpcAoMgIAhMEQJNHc4xJQ27xWxtDCiSIAgIAoKAIDCtCAjBmVZ4pfBoQmAowESrqX3shCya2ixtEQRiCYGW9rEanNausWmx1CdpqyAgCAgCgkDsISAEJ/bGTFo8SQRaO8eSmRYhOJNEUy4TBMYi0BxAgxMobeyVkiIICAKCgCAgCEwdArIOztRhKSVFOQLNHWO/JMvkK8oHLc6a5xh0087D7TQ0HIdmWxyv48kdTWNG7Bf311DnVfFpClqQm0JrF+VTYmLCmH5LgiAgCAgCgkDkEEjghdkkjFTk8J81NQ843RRpU5W/PnmKtu1ttWCen5NCn3/PakvaTB9kZyRTQU7qTFcr9c0wAiDTn/jWTnK6JNLYDEM/rdWtqM6lr35o3bTWIYULAoKAICAIhIeAaHDCw0tyTwKBR188Q/c8XEuuoej7at3JQQYw6Yy0XL6hhD7x5uWRbobUP40IPPtKs5CbacQ3UkUfqu2mhuYBqijNiFQTpF5BQBAQBAQBPwTEB8cPEDmcWgRGeJ2ZvzxRH5XkZmp7en6lPberheqb+s+vELk6ahGAovy53S1R276pblh6ahLlZNmmutioLe/ZV8aa5kVtY6VhgoAgIAjMAgREgzMLBjmSXdxX00ndfcORbELM1I0v/O+4dWHMtFcaGjoC/c5hamrzBbko56/9H7pjcegFxFDO9FSb0ma4R0ap9kwfxaMV9PCIhz7/w73GqBw91Wvsy44gIAgIAoJA5BEQghP5MYjrFuw71mXp35UbS6l6XpYlbSYP4Au8cUUhZabbaPv+VnIMRs4fYoQngL9+sNbo/r7jVqyME7IT8wg0+0Xru3bzHFo6Pzfm+zVeB5KTEmlJZc54WWL63NIFOXT0ZI/qQ2uAACYx3TlpvCAgCAgCMY6AEJwYH8Bob745SpktOZE++oallJAQHRGHrto4J+Lw7avpot1HOlU7WtgJHV+7owWfiIMTRw3wXwCztDAtjno3O7syh8dQE5z2bhdhnS07v+NEBAFBQBAQBCKPgLyNIz8Gcd2CFtOXzZKCVJm8+412aYFvogttUr9DzPn8IIqLw2a/BTCF4MT+sJqfXfSmrXNsGPrY76X0QBAQBASB2ERACE5sjltMtBraCGgltMikTiPh2+IrsFnMGi9zuuzH1KPa0gAAQABJREFUNgL+41qSL2HBY3tEiUoLrWPor6WL9f5J+wUBQUAQiGUEhODE8uhFedv7BoYtYXFLZVI3ZsRKTBocnJRJ0hiI4iKhu2/I6EcWr3uUYksyjmUnNhEoyrUSnO7e+FzMNDZHR1otCAgCsx0BITiz/Q6Yxv539PomdaimON+qrZjGqmOmaH+C095lxSxmOiINHReBEY66pcUu5EZDEdNbW7LVlxAh8UUEAUFAEBAEogMBITjRMQ5x2YphtzVCWYpdbjf/gU6xWTFBaF2R+ENg2DSuiC4mEvsIJCdbtXButxCc2B9V6YEgIAjECwLynzZeRjIK++H/D18mdmMHKTnJ+hVYCM5YjOIhxazBSfIb83jo32zsQxJizptEnl0TGLIrCAgCgkCEEZAw0REegHiu3j1q1UYk+5l0xHPfQ+2bP8ExT4RDLUPyRT8Cc4vSyTU0SpgEI5qgSOwjAI30HB5XPMP4ZWXYYr9T0gNBQBAQBOIEASE4cTKQ0dgNt8nvAO0TDc7YUfLHROz4x2IUDykffeOyeOiG9MGEQAn7FP74PzebUmRXEBAEBAFBIFoQSOBQvmI4HC2jEYftwO2FSfsw26fDKdd/Qh+HXQ6rS8BnkL/sw2wpmU1eEv3MXsIqTDILAoKAICAICAKCgCAgCJAQHLkJBAFBQBAQBAQBQUAQEAQEAUEgbhCQIANxM5TSEUFAEBAEBAFBQBAQBAQBQUAQEIIj94AgIAgIAoKAICAICAKCgCAgCMQNAkJw4mYopSOCgCAgCAgCgoAgIAgIAoKAICAER+4BQUAQEAQEAUFAEBAEBAFBQBCIGwSE4MTNUEpHBAFBQBAQBAQBQUAQEAQEAUFACI7cA4KAICAICAKCgCAgCAgCgoAgEDcICMGJm6GUjggCgoAgIAgIAoKAICAICAKCQLJAIAgIAtOPgGfETe2Pf2/6K5IaohKB3IvfQrackqhsmzQqMgh09AzSidN9VNPQq7anmgbINTRCQ8OjNCrrb0dmUPxqtSUnkt2WSIW5qbSwPEv9FlVkU0Vphixa7YeVHAoC0YaAEJxoGxFpT3wi4Bklwk9kdiIwKmM/Owfe2us+xxA98VIzPb69kVo6nNaTchR1CLiGRpl0jlLfQD+dPNvPY9ek2gjic/HaIrr50rm0qDwn6totDRIEBAEiIThyFwgCgoAgIAgIAtOIQN3ZPnrkhTP03O4Wcrs901iTFD0TCAy7R+nZV1rUb2FFFt3CROfiNSUE4iMiCAgC0YFAgoclOpoirRAE4hcBj3tITNTid3gn7FnuRWyiljdnwnySIb4QcLpG6DcPnaDHtzXGV8ekN2MQmFeSTh9/0zI2Y8sec04SBAFBYOYRkM8NM4+51CgICAKCgCAQ5wgcrO2ij33zZSE3cT7OuntnWhz0mbt30b3/rCNoeEQEAUEgsgiIiVpk8ZfaBYGZQyCBv2ckJk2uvtGRmPAhSszIJ3vBPBruaqSRvvbJ9VWuEgTOA4HRUQ/d83AtPfDs6fMoRS6NRQRgD/PXJ07RzkMd9B/vXEmlBWmx2A1psyAQFwgIwYmLYZROCAITI5B36dspOatw4owBcgzUvkyOo88FOBM9SQm2NMrd9HpKSs+m/sPPkFMITvQMzixpCcjND/9ylJ56uXmW9Fi6GQiB+sZ++u8f7qGvfmidkJxAAEmaIDADCAjBmQGQpQpBIBoQcDXXGATH1XZywiYlZxVRUmomedzDNHhy14T5I5khMSWLsjfcpshNJNshdc9eBITczN6xD9Tzjm6XkJxAwEiaIDBDCAjBmSGgpRpBINIIOGp3UFr5Kkpk0uKse4WG2+vHbVLOZtaGcF5H3cs06uofN28kT6ZWrKXMZZdRQnJKJJshdc9iBITczOLBH6frQnLGAUdOCQLTjIAQnGkGWIoXBKIGgZFhGqjZSlmrrmdCcAV1vfCboE2zFc0ne+F8GhnsZ4Kz05uP/Xcyllym9od7mih13krCAqZDLTXkOnOIEuzplDZ/PSVnF1GCLZVGBjppuPOMOqcuYh+gtOrNlMjnnGzyNjo0oJLhN5NWsUbtW9IzOb3cmz5w5Fk+PzbgY3J2CffnWnWth/2EEibrY6RKmL4/7t4WxspFttwyJmL26atISo4IAo9tOytmaRFBPvorBcn5xj0H6Rsf2yCLg0b/cEkL4wgBIThxNJjSlcgioCKuj7p5PU92yOcftno/ISUjso07V/tgwwFKq+R/tExCUlib4zp9IEC7Eihz6ZUqfeD4i0RMjJQwQUmvumBMfltOCY04einnglczeTFpUfLnMUFZTUPzVlDPzvspkTUsGYsvpoSEBHL3txt1p5YtM8p197UxITqo6kidu1Kljzh6aODIM2PqRcIotw24D3ecYr+bZyl77S3ct8KAeSOZOHj6ILmZFBIlUHJOMSXnzSMbB0Ow582lxCi5N6YDH6dzkPodTuofcNDQkPc+stttlJmRTpnpaZSWljod1c5omU3tDg4FXTujdUplsYVA3Zl+uu/JU/SG6xfEVsOltYJADCMgBCeGB0+aPrMI9B18kobaT/GsmkOAKvLCZMYDMuM9DqRhQAvtxVWUve7WmW1s0No81H/0GeWMn7H4EnI1HvURmHPXpFasUiTB3dNqkJBAxeE8orK5Wmq5f7cocgONzsCJl5jwdFPq3OWUwn23F1RS+sIt5Dj2PE/yW1iLUUr2ogVG2XbWFmmxF1YYBCeluFolu1pO6NNjtqOsJep8+qc0Otg35lw0Jbj72841x6MwAA6D9V6/psT0PEV2bEwIbUx8ktJzFAmMpvaH0xaXy0XdvX3U3NxKiWnZrNnLIudQGofO9ZIZG5O8AUqk5q52GnX2UmlpMeVmZ1FKiokch1NhBPPCNO17fzxKQ8MSFjiCwxATVf/liXratLKQquZmxUR7pZGCQKwjIAQn1kdQ2j9jCKTMXUqDp/aEVV8im21lrb4xrGumO/NwWz0hyEAKk4z0qo3kqNnmqzLJRumLLlbHfcoszHfKvDfUXk89O/6qkuxzlrCvzia137vvURpqOqb2hxqPEPx4YOoGzY/j+AtMhmq8BKeggvMkECXbKJkJjxYbkyFIYmq2oYlBcITxJNrJDdqevuRS8rgcbLJ31qvJgZbvnIw6usiF3zltWqI9g5IL5iqyY8svVzgkIMR3DIjT6aSWtg5yJmZT43A+9fa6aWQ0MPnEou/ZaRzW22UnZ0sblRQVsEYntsLqPvzCGTp6sicGRkaaGGkE8B3s7j8coe988gIxVYv0YEj9swIBITizYpilk1OBgJ2/rkMbM9RaF3JxmWtvYhOkdI5ENhTyNTOREWGU7ZexZoUJzuCpfYY/THrVJhVYwMV9dLPZVzBxNflIh43NrCAj/DVekxt9naN2pyI48I1JTMtlfx3WxvBkP9GepogNAh6YJ+8IaqDWsmFNDmR0yElu9uOJdbHngrDMUd2Almu4p1mRneHO07xmz1ki0/0B36ShpuPqpy5gnx1bXhn/ylnTw+XkzKGEpKl5dXt41tXP5n/wyTpf/6WhYTed6XLTiXYbdQ30TjhkWAuxc8BNnSd7KS/DRsPJbqrkn902NX2bsAHnmWGIO3DfU8GfkfMsXi6PQwQamgZox8F2unhNcVT37tlD7bTzRFdUt1EaN30IzM1PpTddWj59FcxQybHxn2SGwJBqBIGJEICTfagEJ5Ud7qEliUYZ7e+gwdP72bl/LWsXLqb+A/9iIpapCI/Hw5NeJkDjCUzQ/AUTd3+B/4yWxLQsJk0NbL7Wo8ywbKzZSUrNUKed3BZ7UZUiV3bW7tgt5mljgwvoMmNxC3JiZ3M0/Ig2Kx8iLEo6dI7suDvOWKPWMfmB1g0/JazNSc6dw4SHyU4Bkx4mPwjcMBnxmsrtJjfXn7P+NkU8J1MOyM3hUx3U0uehPqdPOxVqWX1ON51sGSCHw0HLKgtiguRs29dCvf3DoXZR8gkCCgFo/WaC4MB8MjGRteSTkDp+FutbHJO4Ui6JBwRc+PoUByIEJw4GUbowcwjAOd9estCriRin2iReUDNz6eXj5Ij8KcexrZRatpxSORCAg9e5gRlZApuMOdkMD74t44lHBx7gTAmJXvMpc5q+NtEcMeyclgI+NekLNjCJmc8T6kyVFb5N0CAkzV1B9tKFPPn3fj1ChLZ4FwRdwH2FHzEpRtAE+KYgAt1w1xkaAuExjwcTUDdrffBzcghvCO43+O8gcIHy42EyGYqgfAiIZ9fW31POxtdSMkevC0dgltbQNqDITZdjhF3Swiekbr6mawDEKIlSm7qpoigj6s3VHnmBNW8igkCYCByp66GTvBDogjLvuy/My0PO/vyRDspnzejSeVlkhz2oiCAwyxAQgjPLBly6O3kEEBHNeWrvhOQGjvfZa2+dMjOiybd4/CtHhxwcEGAHE7FLKW/zHYRIb6PDLhpg4hOOuPu9pgzJPMmG78zooM88ycYmfVpGB71hoRGUQBEcnpBrGW5vUAQnlQmO1nqBMKmgDjrTLNmC8CDQAH6pHIEOMgr/ne5GjhbnNWlzs4kbMyEDEWiA8Bts2KvSMA5essNaHiaLSUxaUK6/gERpGWWtXNfW3ylNDoJAhCIIKNDc2kE1TcPkGLUHJTdJ/CU5PcU7yXK4RtgvZ2zpI9yfHtbk1DY5KYUGaU4JR/qL0sADNad7qKYhsG/R2J5JiiBgReAR1uJ8+M6l1sQpPhrmr/AHT/fRUSZTS5lMCdGZYoCluKhHQAhO1A+RNDDSCOCL+iCHLnYc32aZvAdrVwZrbqIxVHGg9jpPvsJho9dS0rkv/gO1L5Fn2Bkoa9A0hGgGRtDAZK29gXp3PchlDFJyYSVlVG9U17l723iS7p0QutkUa5TPa7MqnPMw2RpuO2WpwwWTrABmb5ZMs+QAflwprDnED+JxD7MfDwjPWRpiLYy7q9ESDQ8k03X2sPohP9YlsuXDD4hN2nibzKG9ecCUHxDOG8Jatp6X/0YZK66k9PkbjORgO4iWNpiUzeSml9wjPsLlnz8jNZEWzfF+sa7hCVdvEDO2YVbi9JOdXMnZKhJbSVF0RlZ7cQ9HEBQRBCaJwNa9rfTB1y+ZtAlZONXiuRSiEw5iU5d3w8JcsiUl0kvHxreImLoapSQzAkJwzGjIviDgh8AgR/Aa4PDGo/2mFxRP5O2liwlRwvwFC2RCOxEzwuv2oH/Za29Wa9k42VQtXNGag7TKdSokdMHVH1AEBgEDIAgU0Lv3YV+xbGI1xFHcsP4NZIjNoyCjrn5eH6fTMJGaDeZpquOT+ANTQoTfxg9eTAgW4O5tVQELVOACNmszE1UQziHWnOGnJDFZrUtkzuNrhocGDj3NGqFOylxxNfOg4OYtCAXdxNHSvORmrIZIl5nCJjLFOSlK6XSqFbb9MEcLLCM8IYP9f2lyB0dWi741jdDq46K9CTx4khoSAk7WYjby+knzir0+iCFddJ6ZhOicJ4BhXn7NmiJ69eYycnEIeSE4YYI3RdmF4EwRkFJMfCEw1NnAi0vyui3dWJxRSwKlzFtOGYsuYfOhbOpPzyXnie36JH8lT6PsKAsJbTRunB186R/mr/WOkzuZZQSfeOKcWfNiLrL/4FMqilrGwgvZjyeFkpIySUUL6z5LA7wAJ0iQWeCHownOcPtJ49QQ78MHBIEOjMm4cTb0nUABD0K/OvZygoRgfSH8iAk2NGojA91MeNikjUNTwxQNJmhazqSzyRiTnmxOCPZPAOZu7oEuNlm7NWDwASzimcTr3PRwKGiujk3gdOljtzCPU/7OKtM4GflSWK91s6na3OJcGhx0UWpqdGlxRthfqO6MmKeNHWVJCQeBE6d7Z5Tg6LYJ0dFITN/24mX59KpN3qiZ01eLlDwRAsH+t010nZwXBOISgWFevHLg2HO+iFXnemkvqSZEUIOfiRaYXw2yT47+Cp619kb2QfFqLXSeWNl2s+/FhMKko+NfPwiSzUPO2pfVLzEtR5mfufuZ1AQhTEO8wGgbFhn1E2gO8JusdL3w68leGlfXqcAFmXlMFvMojYNIQEYG+70aHvbj6XOdoNPJTCWYmaQNeyiLvyhnDY1QjmuUUkxBAhAqvGvrveeCD+RZMOp3sCkjL+KJdW4C+fdYModxAPoDLQ7ZsqhvwGEQHPjubD9u0qSGUeZUZu3sHiTXUAAnoqmsRMqKewSeYTPHEfv0TcHaesdfmkCIztTfYvlZdg6vPJeWzcOnI5FIIzB9T1ekeyb1CwJhIIAv1QPHX2SzM+ukO5kdtDOXXqZC8foXB01F+qItrKF4mlI53HLKudDG/vlm2/Gos4ejgPnCQ8+2/kdrf2EymMSLsqbyr7Q5l7pbOAIba1ScdvwSqZVsquk2dk7OYqKTzYQnm0lFOi9C2r3td5TNYaSxaKuWgQEnOYfHhqdGQAH43MAsTROfvLRkSsZipcxe8jLYPO6c1RvTGDbhGKEBrmfET3k4yKGnBxyDVFTgJVZuNsNr6Xbp6iO2rRfztIhhH08Vn2l2RMX9bCY6Fy/Np7n5sbHY7srKLOXXd7ZzkOYXpdO8gjSqbe6nrezv0t4zRKsXZNOq8hwqyrXTIL9fkA/nOpn4QZt83bpiSrMn0VP726jX4V3ioDQvhbYs8UaRtKancrr3PfSPHU1KYx3oXrzjojIhN4GAiVCaEJwIAS/VRgcC+KrtqNmu1oRhRwajUUlZRZSx7HIjopdxwm8HDvpDbXWUufwKvzPWwwQs1li6yJooR7MGgaTM3Kjqa649J2h7hpmYdOLHRASSxNqUTCY7WYf/QRXVV1Lh3DUq3TU0xNqbseZjiJaGgALwuVFmaZwb5CY1JUldt6w8m6/zPmtQFrX2uOg4Bx7wXz8HoaNdQ9Z1ZpSFmyolcn+cg9Y2Ra4lUnMsI+AcdI9r1nm+fYPZaKhSnGOnVRXZVJI79oNFqGXMdD68Y65ZbV0wtbo0g1qY3LxmcxatmW99566qzKErVxbRb59rUGtu3bKhVH2AaeaPJtuPejXD66tyjTKbulyG78ymRd70jj4X3f+S2Wzd2mv420DT/K99rYS877p6vjWDHM0oAkJwZhRuqSxaEIAviaN2Bznrd7M9jG+BykT2q8lYcgmlzFlqfH0er82IHJaz8XUh5c3dcPt4Rck5QWDGEMhwuiiBZ0CeEBjDSFIC9bAGhvIKKLN4YchthB+QnsF5xrjdeBNUnqAzMetF2Wk2euMlvtDiITdkijPeyxOXA4cibyo3xd2S4mYYgWRm/9N5Pz/Bk+yJzNRikdgEGiYnf4BpZA1NQZaN8jKTDXKDBUufO9xB2fz+unl9CaWyxuYtl5XTl/58hBo6nFRZmM4alyyD4Cwv960ftphDa+vgAKsqvSZn++p9SyAEasefXmRfR37tgeisZQ2SSGQREIITWfyl9hlGAM7nDiY1ThUO2WfukmjPoPTFW3jRyzXjRo0K1FxthhPonE4b4Whljx74uT6U7SxD4NLFr6PcNF7IMwpklDWVXZ0nQyI3urllOdW0tuJqSuboa1pS7HZKHrKSEJxz8GQDoaAb2nzR13JZG7RsHmuNmMwcPtNP3QNaC+KhITaJw1dPf8EEMMXuNZvzPxfJ42F3GJ/GI9lQqTuqEXBHcLX4eCE2eoB/9PhJqmvyrrP2+TuWqOSznU767oMnFOFAQj1Hb/zUbQuVWdpFywpoX32Pl+DMzVLfYVJtiepYl7lkrjfCXR771ZTlec329p0a3/TaKb55Gr6o2Pr+W0VFc6QRgsD0IICoXIOn9/NaNttVOGKjFjYdS6/erNb8QOjd6RJMKvl7+XQVL+VGOQK4/yIl7tFh6na0UEd/E3UONFGXo5ncTLhDlcXFF9CS0o1jtJQZGWk0AKcaP4EvjVrnxrTWDT4CeM3SEhS5ae8b3wEaRaayX1BmRrpf6XIoCAgCk0Ug3ogNcOhnUz9NbtLZDLb0nJnd0wfaDXKDfHXNA1TXOkBVHJobeaDhuu2CObwAcRJVsA8PPsIkaptazp+bbqcS9smBJgcywPXUniNRKkH+RD0CQnCifoikgeeDAExgXM3HaODoixwmt8tXFH+JTpu/TpGbRHtsOFX6Gi97gkBwBIbcTupgItPJhAbbHicvpDoJcp3EfjPQ2szNDew7lsXko7WrjUOCJ6h1cMZSneBtHO8MLNZsXCYNDzDBKRgvq5wTBASBEBCIR2Kju93aa7LE4NcGwrgj0Al8YPylnQMMgODkZ9qpsWNQ5SnISmHtciblMKGBbGN/nBUVWXxsU76EK9lnELL/VG/Q4AIqg/yJOgSE4ETdkEiDpgqBofZ671o2vS2+IvlLcmr5Ko5+djHphSh9J2VPEIg9BBxDvSZC00j9Lt96N4F6k51aQPkZc9guPZ/2n3k+UBaOgJZOmxbcSHnpJQHPIxHr07idvWx6V8BkanhcCoUPDbBNVz434+bkoAYJHv56auNIfB0cmKAsaP1yQhAQBMZHIJ6Jje65i01iDWGCA3IDSWGTM39JO5c2eO6afaf66KqVKbScSQz8dCBHG/vUR5vNi/JoNfveaA3OROZp/nXJceQRiEqC4+5tizwy0oIpQSDBlsqLAfoc96ak0AkKGe5qov5jvEhnR4Mlp33OYspYzGvZ8Nogs1ES2JwoEaF6JyHQAMDMLtolMyWHCjLmUiebYfUNxp8jOAhCL/erc6CRTc4aVT8HWdMRTDDeuUxSCpjQ5GeWUT7v25J8kc9Oth9gnEyaTS4oO62QNi+4mdJsXhv0YGUjvbS0mFKHU1hL1Ku0OMHyutjfoIXXj4HAAXc8gUZofgmbjNi8UdfGyyvnBAFBIDACFy7OoywOzDGbpJ/NYkFeEExgBYeIPsgERgt8bKpLveZmPQ6vD+AB9qm5amUhVZf43nXHzjLBYZIEgrPinPYGfoJHT/vK0mXKNroRiDqC03/4GXKefCW6UZPWhYxAgi2NCq/7cMj5zyeju7+TF+l8noaaayzF2Hjtjowll3pXebecmV0Hly+5k7JTvTH+w+15TcseOtK8PdzLZjS/PSmVLqy6jdJ58clDZ7fGBcEZ4YVSe5xe/xlldjYA/5ng/iu2JDtrXUqZ0JRRQeYcykkr5n/WwYkC8pkJTmn2AlpfeQ0HEwhtYpSbnUXOljbKTBpmfxwb8ZI2AWVgkAMPnLNfRxCCYJLMTc3gslJGWDNUGB1BGYK1VdIFgWhGYLaRGz0WR8700ToO94w1fY439dGe2h6yJyfQmy8vV/42yHfotDca2gkOhoIIbFgPB4LABCBJIDlmOXKml99t4kNrxiQW9qOO4MQCaNLG6EJgxNlHAzVbyXX6IDfM9xJKzinltWwuI3tBZXQ1OEKtae6uo+xSL8Fp7bNqtwI1CaZMqfwVH07qJ9v3BcoSNWlo58b51ytyEzWNmkRDhkdcrJVpYZMv1tCw/wyCA4ynOUO/lXYGGhomKyCwoUT1000rYK1OfcchdbioeD0tLd0c1vUpKSlUUlRALqY39R1u6hpwWxx7dT0jrLTxX+dGn9PbJFYuYkHQ+QWpVFyYQXaO0iYiCAgCgkA4CPydF+JcwWv62Hktr3dfPZ96Lxrm/2NJ6hjlvHikg/ad9BIcmM0ebOiljQu9Vh1Hz/arqnr4PdbMGmcdsGDvBOGhw2mf5J05BITgzBzWUtMUIzA65KSBE7xI56m9RPylW0tiRr7S2KSySZqID4ETbbupsmAZ2yZnUG3rXmrrP+M7GWBvS9WtiuAg76DbESBHdCRV5i+n5WUXselV7E2IYV7WoczNvBHOegc7xgU1MyVXaWfyWTsDYpNuP7+1FvLT5yizxbXlV9G8vMk9L2lpabRgjo1NQ9D2ZOrhaEPu0IO0qf5Cc5OXxhGQ2Jp1flku2ZLlX9O4N4KcFARmOQK9zsAvmU6O0Pj/7j9Ob+b1bhYUp7PJrVcb3c5BB1450U0P7Wy2ILefzdR8BMenuQHZAcEZZRZ0kAMMTFZcbt/cZLJlyHWTQ0D+i0wON7kqggh43EPkOLmLHHUvE/G+lsSULEpfchGlzlvJX6En52uiy4rHLUIDH23eSWvKr2BCcDE9d/zPQbtZnFVORfzDBPxE626VD/4cS0svVPs9zlYqz1/KEWv4S1fPSTrddYy/kKVRVcEqyk4vIDv7efS7epSfCM5B4AMELUEyn6tt20uuc6QJk/YKJikQa3oepy9T6UeatrNuzqedU4n8J4fXlkF/IDDnGs8cS2WK8B+Yg8F/ppNNzaChQYCAYAK80D+v/4yX0ADjqZQ0eyZduuh1XE/heRVrt/E6N5Ws8WvqphNN/OEhyaZ8cjxq1AMXjWhpiRxQIJl9bmCWBs3N/DlCbgKjJamCgCBgRuCpfW2EXyBp7nLRtx84oQINFOWmcIjnEeoKEpp+N5uw7a4da6Hw161nCb/Jyl7WEn3oZ2PLnWx5cl34CAjBCR8zuSJCCHh4Auts2EvOmpdodMinUUAgg/TqC1XY54QkuaXHG56GziO0oGgVT2gLqCJvKTV0HR2THRNraEQgR5t20IjH+wUKBGdh8dox+XPZz8Mx1Keibpkd2GEyBYJSnr+EdtQ9opzbl5RuUiZQ/a4uQlsgCEOsy+1nB3rdpvK8JSodZR9u2jamXiSMsPkcHO/bWRt1qHGb8h+BaV20yeHG7conaGjE62gfqH1YRBP+M4hwBv8ZBAcI1RcmUHmhpp0vudH1gORUFGVQaoKLBpOy1cJ63Q43jQSxXUcoaERLQ0ABu7uXTd0yyMZliAgCgoAgMBUIIKDJmTbnVBQlZcQgAvLfJAYHbbY1GRNYV+NhDiCwlUPH9vi6z1+J0+ZvYHKziRJtvshQvgzRsQfNieccSYh0i6AFgQP+lurbaOmczXS2u8YgMLptICUgCT3OdoNs6HPmLc4nJiQpDc6GymsVgYFGp6ZlNw0M9dA8JjYlWRVUmDmPFpds5CAFL1E3r8mSl16stEOa4BRnlxvFFmbNNeosyalU6U09dcZ5/x2ERH7yyO/IOey1nfY/Hy3HA6zN8ic3CIqgyIyKcIaAAEWTjnIXLf2EudqckiLq6uml0qQOmlecSx5bFmsCR9iXy6uBS+YIRVjEE+vcIBR0DtvH53FAAfG5iZZRlHbMdgTm5adSI2tURWYnAnPzp9ZSIFIoCsGJFPJSb0gIuFpreZHO52mkr92XnzUJqRWrKWPhFkpM9YZ99J2M/B5MpbBafHvfWWofOMthcQeUGVDkW+ZtAXxvEGSgmMnHwuJ1dKzFF7UQWgSsWg+BRiSYtPWfpu21D6nTZTnVtMi2Xu3vaXiKGntq1T7IE/x4YOpWVbSGzeN2UAubsymCw6QHmqIkjtaFSF9aQIYgaTwp1poYmMCNJ9FObtD2bNaYJbqSTOZmZQTTvHgUEJWSokL1Gxx0Ud+AgwYcTnINeUOzpthtvIBnOmWyKWNqqqxzE4/3gPQpthG4bm0J4SciCMQyAkJwYnn04rjtQ11nvIt0dlltYO1zl1HGoksoOSN6JoejrJ3pdrQahKaLfStGTGvGLC2BWVZ0+QQdatxKhYvnUTUTnPqOw4Y/THXROhVYoKX3lDL7CnaLNXFENi3QQkCcQ/0GudHnTrTuUQQHvjEI39zUe1JpjuzJqbxSdBGlJmdYtBaICoaJf2HmXFXEkHuQ/VWadHExu11cskFpa2K2A5NsOBYDxa+owBulaJLFyGWCgCAgCAgCgkBYCAjBCQsuyTzdCGCRV7WWTatvAo06bUULKHMJL9KZ4/vaP91tCVY+wvb2sKmV0tCwNgQTcO2n4n8N/FYqC70O9P7nInkMZ3eYiM0vWMGEYxPtO/0sk410JjxrVVhiEKDxBCZXWrTz/4hnbFQbsxN9GhOc9v6zyl8HZKc4s5xNlbwLrKEt0CiB4IDclOQsUMU3MyHS5ev6YnEbbQQ3FjGUNgsCgoAgIAgIAqEiENsEB1/Fx1nEblwQEFbY9JV93LzReJL7bi9dRKPDg+RuPzVtLbSXLaMExth1BmvMTJ+MOHpo4PiL5Dp72FJJcl4ZZSzltWzyfX4algwzeICoYAfPvqAIDdaGCUXm5FRRChOH4RFftLdQrpuJPMeaX1YO/hV5y6iubR9VF61VTu1Y3R6+LeMJfG20gMRBAmGCiGla3CNezJrZpwYma8XZFQobnG/rO600OfM4sEApkxssQAlpmsA8TWWSP4KAICAICAKCgCAgCJgQiGmCk3fp2yk5a3LhTQdqXybH0edMUMTWbkIy+y6sv001uvP5X1t9VKaoK2lVGylz2RWEsMzTRXBGXQO8SCevZdPA4RRNhDMxs4Ayl15OKSXVU9Sb8y8mMyWHJ+RpASfywUpfULgq2KmIp7vcThUCetmcC+miqts4zDOImIuOcSjpcERrc7JS8tl3JtPi8I8gA1oG3QNqt5nN30BwtGkbEttYs4OABSA40ORAEJyhnYmPiCAgCAgCgoAgIAgIAuEgENMEx9VcYxAcV9v4jsgAJTmriJLYKd3jHqZBXkclXiSBHcOnWlIr1rDm5PKpLtYoz+Pmtc+ZZDoxDue+7ONkYloOZSy+mFLmLg9rRXWj4GnewZor8DVB8ICJBE7y5kn8RPkjcb6O16OZX7CSsB4KBBHQ/KN9TdQuBC1ApDv42ayruIp21j+uiFIRBwyAjw8EC1hiTR1IB5MZECkdUhrnhphs+S882saBEIKZ/qmC5I8gIAgIAoKAICAICAIBEJj6mXGASqYryVG7g9LKV6lIWs66V2i4vX7cqnI2v14RHCwQOeqK7rCy43ZkGk+CYGStvo7shfOnpRbPiJucp/aS4wQv3MjmdVoSbGmUvmgLpVWuVSZxOj3attAybFxwPb1Q8/cJzbjmF66MtuaPaQ+CIRxpekmtH4P1ZuraWZMWpvTx2jWnOg8pooQoaNctf7siMPCngSBQwK5TTxilwqcGUdyw/g2krderpQEBgm9QVmqeSp8oeprKJH8EAUFAEBAEBAFBQBDwQyCmCQ6+/A/UbKWsVdcrU6quF37j1z3foa1ovpq0jwz2k6POZILDpl5p5WsoOW8uE6UMGuXzCEk8eGofLybp/eKsSuGv06nzVlJydjElZfIEjCe6yOtqOUFDjd4FC5EvMTWL0hZsoGGO/oUFKO2FlYqAububafDMIRrpb6dUrs9WxOn2ND7u5Pa8QqMDnaqalPLVlMzmWQiPnFKyUDnVwz9liJ3u8TNrO9QFAf6ovhZXK+0WCIW7t9Xbn8Hgq6brYjJXXj0t5MbDE+lB9uNxHN/GuPXp6litZqP0BZsoveoCSki2+9KjeM/G65dsqLyOnjv+l6CtxAKN8/IWBz0fTSfOdB9nk7HVVMvaHARQCCY4Z9a8mPMdOPMCOVx9tIijhdmS7KzNSeZFON0qXPZBDjcNEmQWkBeD4LAGSAt8cUBwUFdzb71ODnsbyB8o7ELkAkFAEBAEBAFBQBCISQRim+Aw5IMNB/ir/wYmHkWUwtoc1+kDAQYigf05rlTpcGQ3SAKTlpxNryc7kxuLzFnCC0iuo67tf6LR/g5FVHIvegsTD++XZXPe1LKl5GBH+IFDT6nk1Mp1PFnfyPv4+QRO8qlMXkBobHnesLrqLKenzFlKnc/8nDzsiJ69+nqVjAm/IZwnjcnVEJvh9bz8N072GKf8dzJWXE3p871rkuhzKf+fvfcAj+s6z4Q/ADODQe+FBFHYe68SJVGS1ZstxVbiEjs92d082TxxdtM2mz/ZtTfZPInjZOO113GKHRcVW82SrEJRhZRIip0gCZLoRO9lZjANwP++5+LO3BkOKtFxvocXc8u559z73gFx3vt93/vlrwJGO6Xv7MsSaK81d8f8ZL7NkH9AkcBBFNXM2Pl4zHaT2eltuYZaNh+ESJw6l4SxZAcknw+A6CVPprs5b8sQtTP1b495HcXZG2alCv2YFzGJg+9ff37c1iQdr5d/J2Y7emUq28+qJWaDqJ2NPZUoMloZtVekvOmoWm46MMEd7159ZoItdTONgEZAI6AR0AhoBBYrAvOrOMeUUB4WV8URdWbKujtEUN0+2pwlW0GAciXY2xZBgOw5xSFyM4Ak977zr4m78oTKJ+CkOxkkh8aikia5GYAXou/Cz1Q7eoNoSchXkYSbueKQDwXumEA/4uGJtycqckPPD7023hHFMO5PBKmKNm9zhfScfF4G6s+pQw5IJSevuz26WWjbUbgmRG6C7h5xXT0q/eVvg7B4hGOkbXs4Jj6hDrDiKn9LOt/5lgwg/E+oNHeLNoy3+P2nX4ogN4kga9l3/5qkbb53wZGbHshDkwxEeySiYZrP4gLR16q3NQIaAY2ARkAjoBHQCCwmBG6elS/Au6NXgiIDiSQA8J54rlsqsIPwJK89qO6q/8q7EXeXkBQuFkkVr2BvqzoeB7Jiz1wGYuBT2w6Et9H8CDtznX9drfPH0EAfwuPuVzkj8ShcODRoEB6zQe+ZlyTY1aA2bRnLVHHKYYTVdR/9XigHyA7vUUJyhsRjsZq/s176zxiV4gO4t/jEVBWylrh8E8K8YtcoSV51QHXBBH4VrjeSvM8QtazbP6fyj5wolOmtv2AdKmJ9OGDcc8TOad4IdDaI68oRhNAViC2zQOwI+4tPNPI1pnmoae2OIVNn6t5U6l7sOCMpTw6sfERudF+Xy83h7xzzUBZrlfppBVR3phHQCGgENAIaAY2ARmAGEFgUBIe4uC4fEcddpYrgWPNnklftUxN7H/JXgp2R9WKCPU0hSLPu+KLh4QGZ8DVfFTf6M0PBeo8j1wL5ISQZLDiZkJKl8mTsOaWh86Pr8TDMyyQ3bMSxbCmZEgCJsgocDA70KILDWjNWU+pilh1MzGdODskQ81ZimS0tW+2OsyVK8prbwk3i4kLrCSk5ofVZWUEOULQN4Z79XJqvhQ4RWxbxtGUUYgHxSS9QuUtxlmsPNZ6DFdaGKW88Gio6WZBehjyc+1UY2hoUx/T4e6W285K6sljiAsxLKUxfOQdXroecDwikOCJfYMyHa9LXoBHQCGgENAIagcWKwKIhOMyV8d64gHCxHZK8/qC4Lr6pCAk9OkxwJwGKNno23Eh6TxkJ+zIm2PmSsma/MLG/jx4YEBKKBaTteFSYyzJR4/lWY6gWjWFrVhsejB0GFt2OYW00TvhtyVnC/Bir8RpJbEzjPcSy+KS0WLtnbh/IWBwS7odNwQZ41OKwDCNszmokff42LhBSGDEqq9HDQ7Jjkh4SvNkkPZQ/vtR0DOpiYa8Xw8+2LL8j4jq2FN0JkuOCHHIHiEyZeQsRn/tWIkRQm0ZAI6AR0AhoBDQCGgGNwIwisGgIDlHyXD0mToRwMZnfg/oqhjKXHbLEZyNyQKyIeqDCxlwYFpR0YGHIGL0pnEin735Sut75pqTtfEyFv/E8Eg0/vDHM5+FEmzVbDAt7Sbg9PDRa5frhkfbjfICUWc1KXoa8bushtU4Cxck4rynY1y4DDbHEFnD9nrEr1N/U8S3uiIPaXNbBL0jPiWcxdrcSeCAZS7/tF1Q9IhLIYB8W4DkURdqGAwNKFCFCGAGeNHp5GNamSA/W6VGbCdLDQpNnIG/c0lejUIiTONm8/KBSHIuGJT4uXvaUPaDkj7kebVSz63jj69G79fYSQSATvwN2eCa1aQQ0AhoBjYBGQCMw8wgsKoLDZHqKBKRuuFOy9j8tccjrGEJOiRvEJ5Y5lm+Euth2TKz7pf/cqyg6eUqFojEZ37lsnSTA2xGfkq2knnm+F6FrRl6MQVKcZbvD3U5zKJU9pwST/pZQ/xQYoFHYgPLVcRANiDBMoEm+eM0Cid6IQqbwmKRBnS0exMJrCQuLOH8GNxKS05ED9FmlAEcyQ5novlMvKgW7FNS+MU2F9fW3IZyvTQJ9LQbpGZHPNtsIVN6CyE/iEjLcH+W71YJJpB0en4S0nFuqp+MLeuRE9atCUQFaAoja7rIHQ94Z19UPJGX1/ghpa0pDL89YHbqsiBUS1ijSGnFcbyxuBIYiX1gs7pvVd6cR0AgsZATevdQhH1fihaS2JYlAUbZTPndn8YK/90VFcPg0SFJYLFJN9LHtrjqOgpIDMR9UfGKyUL6ZxrozfhAYuEGwGGFjw1ARo2xyXOiNfNhLYwMBSV1/Z6jfuITIHJrQgSmuJK/eJwHkDNHDYcM1Jq80pJ9ZX2c083fUoKaPofjmhFS0t/aMUk1LhVqZE2SORm/WXBhFBDJv+3npAbEhOWGRz57jP5KMvU+KYySXiXWBuG5u8zqJfwChhGFPTyvqFHXySPg2IKYQBC5cQgYvnC0tV3l7TOJjS8tDeNz4X3kqpJHceAL9qrtEW7Lsh5hAZnK+2h7CtQ9UHhcf5K8z4OWzpRq5T6Gx9YpGQCOgEdAIaAQWKALVrW6pbY0MI1+gt6IvewoI+IKL44Xc+LO9KYAzp6cgrMh99X1JR87MoKcPhOf0qJfjReJ+ctkehKOlq3ovw9seQpJLfOjNP4UJhpEbwpAv1tmhV8fxwG+D/wSVcIG14wRMplkgdLqMk/3Mg7+I8eGtATlgCNYgVNvc5YdHHcKDWjOJheuUpyYN9XBS1t6uPAymgAE9UP7WqlHPn+kDDLPL3Ptz0nfuFfG3oAYKiEnvieclbdfj4sR1xzIW/3Rkr1CLeZxKdMG+Dizw8pD89CDErR+eFquHBORUkSIQxJABwwQUUVVCBvT4UMEtLT/CC9OBopMna34GpTQjxJBFJw+sfFySHKmhbjgmbQg1jbqPflfStj+E78aG0HG9ohHQCGgENAIaAY2ARkAjMHcILD6CAyx9yKkJIHzMU/MxZqGGNyYmxDjWd/5VSUaokSO3VCW/sx29Bt6my+K69I46rffsK5Kx4zFMjCFnjDAvgYgZw6nckGtOgqeEb/Dt6YXib6oIDXOzSIDxNmQIhMVq5rZVWY3HGYpGr0e8MxXz9kHxQ26a18PwtNGMIXrdH2DCve0BocIbSRKNuTm+1usQXnhrtFPH3E9CMV1GD0r6rk9KP0QgVFFWkBLWyRlGCB29TxMxihSwWKq1YCoxCsKzo0gP83qQ0xNEuJtYVdyAA0koF6sYNsMQmc/TnhQvV3x1IaW0PMg970FYmj0hMhyQfYcM2DBsMVDWKKkb7w6R49Dx+bRCT2SUWt+EL4+/R1YCOeETZ6dhPIQ3bAxLxHeeLwIG8YxG89zOzhXpUTQCGgGNgEZAI6ARmCsEFiXBIZg9x743IUwp5dzHWjVQ+7Kl5oJAeI1keMvZVGjrPvpvIBzIyXEirwckhXkkNG9UyJcH3iMu0ea59gHq13wQvVtcKBrKRZll8tl39qdqsm6DrHOQeSggXVZjvZr2V//aukutM1G/98RzKg+Hyfc0SlFLcPIkxd9yPeYYqtNb+MGQv7StRk7QQDVIKMx14Q2FfQpC86Zi9FLZQUC5SLHRA9XzBl3dCscAvTz09sDrE43FEPCtjO+XxnhHaOh8b5ysHxwSfzUEKqJq9TA/KNoYDhjsaQF5eyIUHhndZq63s+78kgrbm8p1uKtOiqfivamcOqPnKIXD7Q8rCXXrQCTlfAFhfr+sx/S6RkAjoBFYzAj0DQSko88vZfnJEj/N+cGLGbfpuDeHLU6K85IlJ80hQcwhWnv90tgRO01iOsbTfYyOwKIlOKPf8ihHQACCPc2jHDR2D/n6QW4MYjNmw+k6yGuyCA1MqluE6g0ybGueGkPulMfDkRyaOHMCTfnolA2HpkUVjUSKb/W5OIs2KyTozRqEkpxSbgPpCUD04Mpwm3TAezPSQFb0BaS4H9jLdQk2Xw8haNbqsUpZhw5ihbWOuj/4N5Ccx+ARLLMemhfrPhBW5iXRWBh3PGPOUgI9iPgeRohWjHfiLB5P2/6IUkDkkCQ1gxAMoUeVXj5+vwYpP954ZRavSA+lEdAIaATmFgFfYEiOX+uWi/V9srUkXROdWXocu9dkymduWy5pSQjzsVh1m1u+e+SGtPdaY0csDfTqjCCgCc6MwKo7nSgC9NjEO5zKg8Nz+MadSfxpWx5AuNcI6ZhoZxNoR2JlY6FWLP68Mjlf+7p0uo1xkH0lG+0lkpvkg8MMstWYHFvNrNVj3Re9zrAoetCS192BYqsHpoWoRY8x1W1P1QmEAW5VYY8D1ack0FE7ZlcZ+z+jCI6n+uRNWIx54iwdjE/KCJEbLwQf+s+/prxzDFfLvvOLKrcqqXSnJjiz9Dz0MBoBjcD8QsDtHdREZ5YeSSm8ZV+6u0QS4g0xqo5+nyQ7bJKcmCCr8lPkNx4olb/6CV6aDloEkmbp2pbqMJrgzLMnHxjJ75jtejVzCQNzb1jUsx+5TsyZYm7OMHKc0nc+PiHVs6lcu9vXKydqfioufNKYZ0OltOyUZaHuKLsdqeB2c62eUOOoFc+1o0LFO4pdmLlQUU1mf5NhW6j7xPBAeje6P/jXUa/BDvJHLxRzwTwjYYTM30lZf5c6J9DbLM4VW5Tghh/5Xb6GS8h/STZy0iDIwdCxQYT+BRD+yWPK4FFLQr4b89gGEPJm5pMxByqpZLtqErEfnpikYmO/+8q7OB75h8GWtVydwx9KTGQkDJP1ligQ4ly+Ad6cnFAbvaIR0AhoBJYiAprozPxTv2tTjiI3jBL5259WSXWzG9siTx4oknu25MryrCRZsyxFKhoiX5zO/JUt3RE0wZlPzx6T+x7k+ixFcxaulfh9Pye9H7+ApKEA1N4qpefjH0vmnk/hTXxkkv+t4tPlboFS2mviH/SqrlIc6bJ/1eOSmpgR0TUFHhK55K8K7Xdf/xC5VMdC22OtBBAGRtGH9N2fVGFTY7WdrWPe+ouQUd+tVAET4c1RQg83DY7wwQ33qL1uEDU+D2UgKCyeG20sYEnFwow9T4K8WJ4V1O9IXv0rNqvnGo/nyMK49KIFXRB6AJGlUcLc7JdqeL6GcmN/0Ra1f9DTK+4rR9Q+6w+F7/FnlQeQuXRWs4E00aLFPqxt9LpGQCOgEVhKCCwmorOlNE3WLkuVxi6vlCHnZUVOklS1uOTY1S7pQN7LtpXpsrU4Q/IyHeL1Dap2PNaF3CQ6WR7YmQ911AQ5fKFd+jxB9TUozEqU29Ybfzsi9zux38hpfvFEs6omEv29WVWQonZda3YpcsMNpODI4YvtiuBwuyDTqQkOgZgl0wRnloDWw4yPAOvfZB74eRQEfV7VyWG9nJ6PnkFB0E9D4CF5/A4m0KKxp1LO1r8tQyOKYPTY7Ct7WBw2qONNwDjZnpRBvIK5L/ExiMGk+pm2xsPiqjgimfs+A7Jxh/io/GcSmJExnCVbQYBylRKdSUJiDa/U5ODV8UF6PH3nY4rcUELdjRpBzHNyFm1S5JDPNXnNbUp8g9Ld9sxCYeFas28HvEWmOXJLQgQnMd8omuoD2Y1lrKUURK2oaHPkr1SKh9wf6LoRfVhvL1AEAqjN0NRjvJSYy1swJ0NzeQ167IWPwBDe9Nd1GOqq0303nZjEj2WLgeiQ3Ny3DaJCFltdmKKS+p/anybbyzItR0S2lmaAaOTJd9+rlxrU+Xlsd6F62dbS45OPKiDkBNu1KjPUZ3O3T46DENH2rTX2dyLs7IXjsXO1v/NOHSJA7NIehX1xTnhu0Q/xB22zh4AmOLOHtR5pAgjYM5dJ5u2fl168maegA8UAuj/8gWTuf1rVK5pAF6M2ud56Vq60fBQ6XpS5RnYU3ws38sR/DThBH8sYmmWH5Dgn8FyYpE+j9Ph8sUB7rRIZSMT1Ja/aKx54pUKG5PzktQfVZr8KCwsdiVjxI39HqfVhr2PZetznPnW8D3kwqmAutvxNV4R5PAx1o4eGKoKUK1cEB4VyUXTKUC8E4TGN8ua0eGe6IllcJ0GcqNnw/Unf+YRqzlwuz9WJedsm2r9uN3cIDAQG5dgVY8Ixd1cheBOsFZHmEv/FMnYQyvtz/X1eDESH34cB/6A0wZOTk2aXrFRbiNywYOl7lzslPckmj+4qECc8Nl+4q1j+/JkrUt85IKW5ybJxRVqI4GwqTgt9vdYtTw0RnK2l6Wr/+dq+0PHolYb2AeFiNYao3b/dIGFDQ8NS0xZ53NpWr08/AhOf2U3/2LpHjUBMBKiClXnwc9KDZH1KODOnoufD72Oy/LRSRIt50hg76a252PC+1HVdDrVam79LNhTun5QIAL0TgwitijSIFqAmjyOXhKYMxUP5VsgQLYhsN7+2XJePiOMueFZAcLx150P5MMmr9ilSxhyWWN4R8y58FnU5e1aR2s36Mya5Mdt5qj5WBIcy3vFJmSr0UNbfqfKSiBXDAK14kRAyJ4eeHBrrTUWHn5l9R386EEpIchMHr9nwEOorgWyZeT7RbfW2RkAjoBHQCBgIcPIdxAKnknrvtNBw+cYbNaGwsD99er26fL6I+NrLlYjWMO6mts0jX35ijQpLu31jDgSGeg2CU5SGv0EIlbbHq23z3tcXGSFnWZB7Zv4M7XzdxCM4GAb3xXtKxAxde/tCm3T3z58XneZ9LuZPTXAW89NdwPeWkJQuWbd9FrkbzyNUqlWpePV89APJ2PvpiAKf491iYNAvp2p/Ju2uBtU0Dl6D7cV3S0n2xvFOvel4EAVC+ReA3gVHfhk8NSA1mIir4q83tZ7fO1jbyXvjApL7d0jy+oMoAvsmwgBTFeFh/SASoLGMIWjRRgIYbdaQvvikNJCmeoSv9cIblwH8ykCmjD8iA7gWR94qRa4c8O44IsLTRv5CRXdu2XaWbJNUKu/hLxWvow+CFX6EzmlbPAg47QlyYJ0RBz+Xd9XW2C9X5/ICpjj2+rJ0KUaeQCbecnugrlXd6JKrmOSpSe0U+9SnTR0Bvt2fqe8zw6SqWtzjXlySI142Q0Z6Nb4XpvrXuCfNswYubzBEbqhYVog8F9o7FztC5Ibb1cCDcs1UNGObt863yRN7limVsxLk8GSm2CR+RAGN7TOTHVKAnBx6cmhujFMF4YCJGGvh/Op9ZbIF2NIqMfZPT40d/TGRfnWbySGgCc7k8NKtZxEB5t0wJ6fn1EvKm8Cci54TyMmB8MBE6swM+F1yHEpp/V4jrMUWb5e9ZQ9JXtpIJdBJ3guvJ+vQrwoLqHIivdCN4VvO5ZvECSEAT81pFUZG78cAitfSczaWseaMaaact3WfeSzeFi6eaharZU5N8srdiiTGO4w/Hv6OOsiCJ0gC6hU5CteII9t4RlRoG8+SVu6R1E33qGZDqKPUe+oFCXY3jXeaPr7AEHDY4kNvQ+fy0jMRZ7+QLD/bKf/lS5tkLRKuo+0GQnj+819Dmt98zR3dQG/PGAIkFObb/ekeJA0hWWMRnMVAbEzM2vrCtWXITwbxXSa2zJeJNhY/JcHJTnVIU6dXtclJS0SYWqpkgNDQPkQ+zuaSNGzblYjBlmKDpFyo65vQy4AUZ4L89iOrpAThb7QrDX3y/96sVdeldugfs4bAvCM4iUhMZuy8tsWBwK1KJFNBLXPvU9J37qfiZy4GJta9J38saZCQdi5bNypIPQPtcrL6VfEGPapNkj0VSmmPSrpz6rLB9CotJiMZcFeegGLanZKF8L+4xBT87vnEPcm8laCrW8HCIqL0bg15w3HKdosC3ZDXePtFUQJFcLJWhOAMdNQrgsOCrMwNopEwkfiMZU7UuTHJDa+DHr+lJLE+Fjb6mEaAb6T/+Fe3ShkSsmMZPTqpyTbpc4VfWMRqp/ctDgQWE7Exn4gP+TchA8ExPVGJCDmLtqSRfd6Rc87X9cu9WxJlE0gM83RoFU39kpAQJ/vXZsk25N6YHpyJhKdlwAv0O4+uDnmRjl/rku+/dyPCkxR9TXp75hCYdwSHkrP27Q/P3B3rnhccAnEJNknf9YS4yt8Sb/0FzHyRX3HmJRne+kCofor1plr76uR03RuIKTZCpjKS8lSNG6fdCIeytl3q6wM1p3k54aEAAEAASURBVCAbvUMSED5Gc1cdh4Ld5BIhA1Ayo/Y/PTBpOx6SvtMvKxU8G8QWUlbvVf0G+9qVaAQ3glA240sMM7SPx4ZBtgLtkWTG114LQntz2JvqED/inWkgZ4fMTXFDHY6EOoJU47qCvS2hNnpFI7CUEChDeI2V3Jyu6JT3ECpTmOuUBw4sl1yE6gShTqdtcSOwGIlNrCfmGhgUkheKCWyGx7IcBMY05tisLjSIfq/HIPQXkVNzL2rUMETPtKsIQSVJIsHZPOK98eN3pOJGuC+zrfWTGP8ecnxy4RGivXKqWX52ps3aRK/PMgLzjuDM8v3r4RYIAkxEVzkWKAg6UHVCXTXzRob8XklevS8UMlbTcVHKG4+iJKSRt1GQXiq7Sx8Qhqdpi4EASKD76vuqIClr2aiCmTGajbVrELlJ3vpzIEo7hZLQOZ/4D4rAmApyFAqgBy5kIKh+1Ahi/RuaH3k5tCGfC/VxukI1g8YLT2NoGkPqTMvY85S5GvpkPk7Hz74W2tYrGoGlhEAZCgta7XuvVkstcm9oPz5cL0XIPWA+jml/9CtbJCvdIXXINTh2rk2evr9MSJL8ULCrgILUj96oldom43yeU4DaI48cXC7b1mVLfpZTbMg9cGHyeAVtn0VYTr0lZ8HsuxHJ3g2tHnniULE4kFf1wpE6OXyyBWOVypbVWZKTmSgBjFeLc597u1YuXAvn+923f5ncgfolvC+7LUFutLrk3NVuef7tOl0h3nyIls+lQmwst4yQsH7ZCbnngxuy5Vpzv5yt6kUZiDj5PL5vzNGhXbphRBlU4rtMBTbWw6FRmIAkiSTHagwzCwyOnQv62N5lIXJzuqoH1+GS0vzI8hbdLn+o5o61f70+MwhogjMzuOpeZwAB5r2kbrhLvaE3KtuLqq1CpayUDXfL5eYPpboDHp4RW5mzRbYU3RkiP+Z+/RmJgK/xsgTKdiMP52OwjPBkJ7IVtnDM6nmxHneVHxaqqKWsOaAKsyYkpKpk/0BPo7gvvyskQVZjHo5JcAIdNaFDfqxTRY9CB+OJBMTZLfk9oR4iV3Shz0g89NbSQoCJ0Vb7nV/YIP/wowqpAckZxIStPioRfeeGHEwG42VdSYbcv3956NRkp00ObM2TrWuy5L/+/WlpBEFhGuLf/t4eSRkJ7TEbJ2YkyB3bnbILBRP/01+ekO6RuiDWvs22/FwNmd5P7FsmBdlJod18A791jUP45twkOF/+4ia5c0dBqA1XNqDWCZfdm7LlD75+BrlEEYeX7AYn9HvWZC5o8YCpPryfoBAnhRP4Pf61T5RJ3+0BKKQlqG32efRKp5yvMQgOU8/K6/tkL77XtIoR8t/rDkoLam6ZggXnxpCH5nkkkndtCoe/716N7ySWaHvxZJO8da49erfeniEENMGZIWB1tzOHAKWNWW/GdeENDDIs7trTcjFQLx1i5Ntw5M3LD8rqvO0zdxGLrOeeY98b/45AOjrf/IdR2g3Ds3ZSLaM0iNjtR4HRdhYZjTL3pXeEy0SMz9/4DkyktW6jEVh6CFQhrIZEhjkFtFWQxP3al/cKQ9WegYfl2jgTt2jESGY+iTfh33j2qlKcMsnNACrFV+KtOLc5Bo2k6J49BfKTd8YutpuRag+RmyBKvx851SLpEHLYBbJl2t4tORHk5lJ1N9TgEpUHim0ooHAv3qC/jcmtNlEJ82bS/GLFo28gkryb99kFKea/euGafB71blbCg5KeZHj5OyA6cKqyR175ODJk+QLC1MIEJ+y5IdkhwaEARzkEBsYyZ6KNVd3GtdGuedwTdYMpIaAJzpRg0yfNNQJJxVuVJ6fj7MtSkW0X9wi5SYhLkN1lD0hh+sq5vkQ9vkZAI6ARmFMEOlCl/YdvVMsXHlkdcR27QR64vPRuvfzLy1URx8yNfrdfvvov5dLSMSB/+Tu7QiTkAHIWSHBInJ59q1a6oGJ1BJNGn99wn/yP/7hDeXrYT+GIkpTZp/lJpavvvHhdWlBscQfC2+iFofW5AyBeddLR7ZV0EB+GsNEevWOF+uSP4xfb5S9xXbQ/+83tshOeItoOhCRpgqOgWBI/Dp9vFy6xrKXbJ3/zUqVQaCAPIY8saDpaDZozCGE7U3X+pm6eO9YoXCZi7Pu3vx2OHpnIObrNzCOgCc7MY6xHmCEE/Bk5cmlFlngHjaR4O8IZNgfSJD8pHFoxQ0PrbjUCGgGNwIJA4Pm360EkvPKlx1ZLHvJkrPbJu0ukDmFq7yAHJtq+/UKlXKk2Chu+drRBfvmJtapJOiR2mWsTDA7LD16vkRLkwzA3Jis9UXleMlEY0bREhO7EsmferJHXjhqTR5IY5uPQstHHt/74gJy41CEvv1cvFSOhRMwVMo1hclSGo5nkhusF2UZyN9e1aQSIgC8wJA3tkxPN0cgtHgQ0wVk8z3JJ3UkHCnd+jAKeLORJcwaGZVO7VxKHBqT3+I8kY9+nUbgyMsF2LgGKQz0Ye6ExQZjL69Bjzw0CCak3x2PPzZXoUZciAkfPtsmHeNt91658+YUHV0ohxAFMu2tXQUyC0+8JV123ChH4IABAlakgwoN/46m18ojFu2L2Od7ndeQ9mHayvEOuIkxofalRp4fhdLdvy1PLv79WpcQQcvEW3jSGwe3bnGtuhj7jIUSjbXoQyEKI4LKcSDI8PT3rXhYCAvkQGlkMpgnOYniKS+webnRXyPkb70Jb3giJyEtdITvz9ou790VVgyXY1ybdH/5AMlHbJSHZ+KM5HyDK3P2p+XAZ+ho0AhqBJYgAcwnehUQ0CcXX/8u+kDcnaURZKhoSazFj6zqTtxmexsR+K7np7PUiD6dfNkPBKhVFEidqvK4/+cez8tidK1QomtXL9LmHVsmbx5sh/Tsk5nX2QonqBO4h2k4jeVzb9CDwJAQmntw/PX3pXjQCc4WAJjhzhbwed0oIVDSflGttp0LnlmRvlG0rDgnf3tlv/5z0nHxWhiA1zGKPPSA5Gfs/IyxAOdc2CDnm1y5+e64vQ48/Rwjcue7Tkol6TNo0ArOJwL37CmXTygx54d0bSvmMY1OZjItpAcu6uY+fn394JULEelWYz/0HCkOHepBvEATBodKaae3Imfmtrx5XxOd3PrtBJfybx8b7ZBibA7kSLx65gZygGyrc7T89vUGdxkKlKUgSb4V8r1nP5xyKJzIHSNvMIfBvyM06db175gbQPc9rBJbnJskfPTl6IfV5ffGWi5t3BKfb06YkYi3XqFcXMALmm7+s5Eh5z8ne0iAkis/fOCINPddCp24s3C9rC3aHtlmsMuu2z6Ga/Y8l2NOs6qr0fASSs/fTYs+a27wcepvM2jyhC9YrSwYByl5r0wjMNgJbIFVLdbH78Eb++o1eae/2y5oVqZJvkWQ281yir231inT51n87IG7UBbGGtJ292qWaBoJhSfkM5N188dFVSjmN403GPnVPiaq38+GFNjlX0RVSRjP7YBHhK9U9IYJzaFchkscTpLyyW5zwPm1G7ZytkET+2+9fkQ9Ru0fbrSNAEQj807ZEEeDzXww27wgOCzLWWGqZLAaQl/I9JNqSZX2hUc1+qjj4g16Vb9PpblJd0Fuzs+QTUpR5c04Lq9gzNK339EsS6KiV4YBPek48Kxm7PymOPK2sNtVnoM/TCGgEFh4CPhQxNI1SymuNXH5zlzS2eyDjXBfajl5JS3ZIWji/X3lo6GmhlaOYoWkMW6NgwVQsHgV1mNPDGjfRdW5qUIiRKm4/fKNWDu0uVASKY7AmDxerUTFLm0ZAI6ARMBGYdwSnvuuy1HZeMq9Pfy5wBBwJzlsiOG5/n5yofkVcPkPNx56QKPtXPizZKaN7ZJjQn7H3Kek796r4mxHKMBiAV+cnkrbzUXEuM0IfFjis+vI1AhoBjcC4CLwAMpKdkahqythBQtyoHcIkfdabOXyyWX4E4mAVELB22IFChzk41/TCUw76b//9cqg4KD0/33npujBPhvkx7JselfKqbtm+1pBu9kPFyjSfP4hii0byMtWtTDt1uQPkpSDCS8Rjp650yDefMzz2fa6AfPlrp5WowY51WaFrYjt6eK6jBk/FJGv68FxtGgGNwOJFYN4RnMULtb6zySLQ7WkBuXlN/INedWqKI132r3pMUhPHV6SKi0+Q9J2PicueJN76c/grOCT9Z16R4S0DklS6c7KXsijax6EU2VSVhhheZ4o6zEcw0pxZku7MwR3GSbenVUiMtWkEljoCbV1e+V//XK5yXBhm5kFBThtUyrifyf1j2T8+WyE1KHZYgPO6+/zqnOj2r7zXIG9+1KTa9KOGDUkOSQ3JFMdhAVDTvvTfj4nTkaDyfygxbdr1+n75ra8cR9icUzKh3hRETlArZK3Zl9Wa4W3682+dVxLVvJfUZJsiZ+24F+s41nOW6jqLWta1eWRTcbokAXNtGoGliIAmOEvxqS+Ae27qrZKzdW/J4EjuQnZyoeyD58ZhC8ubjncbcQhlS91yn8QhbG2g8iPV3FX+tgz5vZK85kDEW8Dx+loMxw+t/3mQAOPN6mTv53rrWbnSYmA42XNnsj0J256yh1DYtSximN6BTjlR81PxBtwR+/WGRmApIkDSUY96N5O1nv6AcBnLWOCzvjmybwoXBCL5CQiVjOotYv8kXVzGM5KjhlbPeM2W9HHmUFxtcst1PJe1qFOkic7sfR2cCJUsK0iWLNSL6oQgR22rG6Q+TOhn70r0SJrg6O/AvEOgsu2sXG4OT6aLMtfIjuJ7Eac9+a8rwytS198hzM1xX35H3avn2lGQHI+kbrp3UiQnOBSQD67/WIoy1sjyrLXwJIVVhOYdiDEuqKWnWtILDYLT1l8fo0XkLnpEnPYU4X3XdNxc6Tmy9dxsleZsDpEb5moFhvxCT19GUo7cseYpOXzl37W4w9w8Gj2qRkAjMMcI0Emnic7sPYTNpWnyxUMlkuoMz1VINl840SRHLt4sbT57V7Y0Rwo/haV5//qu5xECDIG62PC+1CEPy7S1+btkA9TSzDhwc/9kP5NX7pZ4u1P6z7+OU4fFW3sGAgReSdv2kDCcbSJGAQxfcEAqWk+qhQSAQgdFWWskGZPq+W6V7WekNGcjFIhSpKrtnLSjWOpYdtuqxxXBYVtvcP69MbWB8K4bUdFr6auRU7VvqDC6VbnbZEvRHXgmUNVLKZQud/NYt6mPaQQ0AiMInIcEM+vQBFDMs7PHr3FZJAhoojPzD5IhmZ9D0VuT3DRDOj0H6oIU4Pj0bUWIJhiSj6ASqG32ENAEZ/aw1iONgUBg0C+n696Qtn5DoYe5FNuKD0lp9qYxzprcIeeKzQhXc0ofFNYEstO+xsuK5KTvekLiEiZWmI7eAT9IDq3P2yl9LZ0I3TquapwsJ9mBtynJkTq5C5ul1kHU4qlo+Vi2F98tm5YflPeuPTPqyPlpxZKHhSFelW1nVDuGg20oPKDWewfapDh7g7C+T0tvjdzovqrCB1flbJX05BxxQAyCwhCdriZ1jCfxmZKw2nCsqv0cyKJBmphTVTLynCP3Z2H/RjXeFXj0omW2M5LymWGsjl9rPR3KEarvqlAEhwcYkqcJjoJI/9AIjIvAV/7p4rhtdIOFi4AmOjP37O7ZmiuZKYaIxl9DfKMWYZQMV/uTp9dDFMkheyFlrgnOzOEfq2dNcGKhovfNKgIDmESfqP6pIgwcmJ6Svcir4AR7ui0xf7Uq/klVNQn6xd9WDRnp55TqGj0841mKI0MlsUe36xloFy6Xmz+ULOQLLc9crcgOQ7zmk9V3XZGVeVtVCFdJ1gap76646fJIRDYtv13tr2g+gTwoI1GYBGdN/o6b2meCaHj8/SpHiip3plHpjgSlOHs9nu+rwmPrC/cpb5zL1y28Fhq9YGa/Lm9X6JqKs9ar/eybuEYbZcPfuPxv+L5AFQpEy7QSEC/T+Ey0LQ4EvPAqVDT0z/nNtPX65vwa9AUsfASCYBvnasJS29N5R63jfEcXA9HZgnCwtctSpRF5W2V5ybICwhNVLS45hjpNHb1+2bYyXbZCGj0v0yFeiF2wHY91QTADquTywM58JcBw+EK79HmMvx+FWYly23ojjDtyvxP7s9QjevFEs/leLeKRleIa+EyvNvYrcsOD9NpchLrfoc25UmSpPRVxot6YMQQ0wZkxaHXHE0Ggd6BDkRszBCrJngqltEeVItZEzp9KG0d2sWQe+Kz0nnxOhpGLE+xulJ6PfigZ+z4jCc6xvS8pieOHolH9jculpmOSk7IMZGeNmsRP5Vqn+xx6QS41HpPbVj8hG5btl8ae6yECY45FUsLwOz6bWATIbMfj8XEJyoOzu/R+RWDo0bneegYqZr2yAsSmIK1EclNXIJRsr/J0kXBkJecr8moSnPz0MJHNTSsKjVmQUaqGau6tNoeM+WmSG15DbmqRsPYSrQsEqAeFg7UtDgT8SFy/3OCa85th4rA2jcCtIkDRhbn+PkcTne1lmUr97lbvbTbOJ7m5bxu8+BZbXZgirSA3T+1PE96L1baWZsg9W/Lku+/VSw0S/x9DXSWGvrf0+EKelV2rMkN9Nnf75PhIUdt9a439nVCne+F47JDnf3qrThEnazh9OpT+Nq5IU5dRBxVAbbOLgK6MNbt469EsCLT21cmxyp+E8jsyknLlzrU/N6PkxhzenpEvmbd/TuKTDKGAwf4O6fnwhxJ0h9+osb4CvQftrhuqNtPlpg/lausps4sJfTJMi/k5VHSbL8bcG4oM0Lu0Jj9SMpveELMw6yXc72hGTN679qwcufpDEKF21Rfbnq0/LNfaTiniRK9c+0jI4aq87SpErRXhbLQ8kB56imzxqFnEULMRIxmiJdnTQt8DhsCNZ06QGnqCTHLD9i29dWqM8c7VxzUCGgGNwFJGoBB5V2UFKQuG3EQ/qwEUtK2CSmCP2w/1MluI3FSDyPzLkXr58fEm8aINi8F+4a5iJZFe32mEmpsEhH1uKjbICNfXLQ+/7NxaarzYPD9OrSUSRooK0Lv05U+tka98fpPko5ZUcHBY3kO9J22zi8CC9uBwgrRY63qM9zXgfRemr5TAoG/cZPHx+oo+zkluRlKempjzjbzL1xMKH4tuO9Xtmo6LUt54NJRXUZBeKrtLH1DhaVPtc7Ln2VKyJO3A09J6+sfiBhHxJbik6sL3ZTBnmXgGPTIQcIXyOibbN9szH2dr0V3ITUHSLnKM5pPRu5S7boWsBsGp7bwcyodZnbdTkRWSz44xRAiaochmWja8VLQBv0so7201KuIx1DABQg5M+m+GGAA9R8QkIzlPnLaUiN9hki7m5NATQ6My2kRyaOgBPFP3tqRA2Y4hcSSVm5bfBq+Sc17KW1sx0usTQyAl0SaP7AqT4YmdNf2t+trdcvV6+EXI9I+ge1wKCNiRlD5T32eGqJ2u6h0XxuWoPcTJew4kjReyfeONGqkekSr/U+S80Bq7BuRrL1fib7hxZ7WoC/TlJ5gjmyC3b8yR87W9UpqbLBuL0vACUlS+DLdNW19khJdnQShgeZZRnuJ83fiY8vytJRmyKj8cnk7S04nQOG2zi8CCJjiLsa7HRB8/JZP3lD2omh+5+iPpR+7CdBgn5VSgsr4JZ79d7ha8nX/7lgso0itCT0iVRXZ4Zc4WjHmnchdPxz1E98FJMkOmPCj+6PaOfGKbxSBVnRT1csaSfzPQEt3FpLaZa7JtxSFFcCZ14iw27vcaOTBlkFnesGyfnL/xLshGMgjPDkXqSIDGMhJC08zk/8HhcB6MeYyYm5YEgtPhalReMZKd/NRiFP4z/ggwXC0f4WwkOCQ3BRkr1WlURzP7N/sZ7bOh55o6dLX1Y/nEhs8rsrMsc6UmOKMBtsD2JyBw3kzinctLd9onpro4l9eox57/CHBSPVPfZx/COceyxUJseI8ubzBEbpITE6Qw0/hb/g5kmU1yw3bV8PBUt7kV8WCbt863yRN7lgnPKUH+TGaKTeKZnDNimckOKUBOjunJcWOcqqh6T2bb6M/DF9ulCSpq61CDiKFx9Bz90VPr5Q+/V44XgWM/m+i+9PbUEVjQBGcx1vWYyqNMiJuex5iJ3IidJfeF3qhzcsoQIr5tz4bc7l4U2nz/2nNT9mowV+IMindy0mraZqh5rUb40q0YSROJCkmMIjI+EBlMwElgPNg3ae8J+nMgrz41KVvS0grhDcjAf4LpasJMFbW3kNhu5n1EXzcn6TuK7wmFbEUfn0/bV1tOqrCukqyNUt1+Hs9hh/Kg0btGr91YRs+eaaYXlfVyoo2KaaYFB43jLcipYchafnpJiEgzlI39rICwQCHITQ4ECmjNY4SnkYTngQwxDyg6V6ih+5oKtaM3KBHFYSnvrU0jsFgQcGDCtAIhRWWYQGVnoKAg8g4a8Ia6ESE5Hq8hCjIT97pzQ5Z86fE1kplql6Pn2uWfXrg+bcP8/pc2y+aVGeJBQvj/+ueLupjntCEb7mgxERvzrtr6wqIf5Cf0lvBlCPNloq0DXhR6VrLhsWrq9Ko2OWmJyJNJRUSB4cX6sKJLNpekYduuRAy2FBvhaRfq+mKKC0SPwe025PVwea+8Q/auzZJfuqdEhf9tKkmX05Vj/22N1Z/eNzUEpmdmPLWxb/msxVbX45YBucUOVuZuUZNMEoZjVS+q0CBOOjctux0T0m0qJ4ITz/Hqp8S6DEoCn6h5LZT0nYBJ6S6EpC0beVMf6xzrvkHIOg8E+g3iosgLCAyIDAkMiRhr6EzGeF8MYyJ5oXAA1dHoVRiuOifxzZWiMmbiBiRt+3ZxFkRKVSfhvGiPGcP6NsPzNZ2y1pO5n6m05aSfEtAblx2Q21c9ASKbrEIer0JKejJmenPSErORO5OqQvvM8ykyYJo3aFQ7b0H4GwmOGdrG4+3w7JCokOCQJNJIIjtGcnjUjqgflLLeWfIJ/NEZljbkBClv3EibBCjx0YagABdEGKc2jcBiQIBv/Z84tEI+/8hq/L7enNc3AHLw3Ver5GfHGic8GYvGJSUpQUqRfxCPwZo7BlAPJ/z7c2h3AUiVkZuwd3POtBGcAihg3bHdCD/MwgWtRmJ2A2R2tU0PAouR2JjI+JBbEzL8fpDc0Og1ibakkX3Mx6Gdr+uXe7ckIvcmXdKTjOlwRVO/JCB8cD+IyTaE75kenPHC09YVpap8m8pml7RAoMC0s9U98vm7ViBcGiqkhama4JjAzMLngiY4nADdSl0P4ktJ4tKcTaogIEN0GMvfP9ClksrNOh1sxwlxMWR1M5JzVY4Atylv3NJbqxKq2YbGCd5KFBqkipYd3o88KESx325PuzSgVggnxhwvF5OzRLzddmGCXoU8BSaj00qhYJWSmCVtmATyTTbH4wS+FQnTrX21NyleqZOifjCBm+emoQYIJX77MDbzLEgQxrKs5GXqcKe7MZT3QOJQhbf7JDi0VGfWpAkOw6FO1Lyq7oN98I36vpWPQE2rgJshYz4RvS6cMHtGyAtJDL0yzIeZrNkTHAaBASFhbobywpDQYGEolFXtxOx7eGeZuByHxVt3VtVY6T/3qgwFBiS5bLfZRJ1vJTgkfZxokyAtNKtGPZoyhAiatXuogOYf9E7qNkh4STKYZ7Oz5F75GAU3+Sz5PWSOD401g0wC0gkyw+OmpDSPsbZQNHFuhxCCKVEd64JMCWg+R3rNzt94T33HC9LL8Du4VZ3S7WlFH5Mjv7HG0vs0AnONAMnNf/+N7bJzRMY21vUkIdzmN59aJ6sw2frHZ67GajLuvidQif3nHyhT7c5CRerPv3U+dE5PX9hLy8Tp6TKXxx968z5dfep+RBYzsYn1fF0Dg0pMwIk8m82QiC4HgTGNNWlWg2DQej3G9/gicmru3ZIrq+ENNY0yzyRJJDibR7w3VHCsuBHuy2xr/fwCSAy9QUevdMoPP2gIHbK+iHB5w78/oQZ6ZcYQWNAEh6jcal2PA6sei3iTrJDOWI0J0hblxeDknBOxO9d+GsTGUNyyPg0qNzF862LjB2o3J4tmTQ9ruxyE0rCKPEN/rBP7HCmS5Rjv8JXv4421H0UY71GnWfvgBJrkispXrCcyVk7CVuSymJM7c3y+RS/D/ZyuezNUSNM8Zv1koU0SNBIKq2Uk5YQ2zSKXoR3jrPAN+tHKH4fCxEguNsBjwDoorSCHKqxshMRw0jtZI3kkeTE8MCAyTnpiDI8MQ+sma5wsp27+hMQ7ksRz3VARc196B3LSXklee7siRaZUdAJILgtfKoUwzj4WoHHyf6X5OLxp94GA9ku1JTdqordDslfXdUkRJaqgPbDpS4rAkETSmAN1GqGJpvH7y+8yf3do7X1GcVcSIP6+pYFE08ZTT+O4N1DHh78b9Prcv+kX1XnmD4bRXWh439zUnxqBBY3A3XsKI8gN30KfKG+X9i6flCEhes/G3ND93bdvmbwOL071LcpqR/+39sK79dKK5G3ahWkUWnBjYvqV71yQ4oJkaUHo0GlMErVNHQEKcjyIOi8LXTxgKghcQa2snZB7PrghW64198tZiC04bHHy+UPFKt+GfV66YeSGVja5kBMzqIQHuJ/CBCRJJDlWu9LQh79pYxP6G/B2kuCwjs5VeIHOVfcqL9KXEJ5G7w3t+gRzeKxj6/WpI7DgCQ4nS1Ot60HiYIbJ1HVdli5XM0hMlpLOdcDLQKLACRLDjkxywwlVJ9pxQk21Jk7i6JFh4nz022aSgdqOS2rSzckciRLJjQ8TuYbu6/jyozhV1jq1n4Uhzbog5uNs7KmUG6jKTm9MGZLBOYlbj3oiFa0nzSYRn1RVM8kNvSA81w/SsKFwL37Bk/CW+155p4JEKpw/Ye2AdU24WI2eKlNKmN4cig1MxjjJtBIyEhoSqYkaxyfpUh6YEeJikBiSmnS8aZn+rzBJTsq6gxIHkuO+dFhdKsnOkH9AkR9eSyZU5pivZE7GJ3o/87Edk/PpoauCN2esUD8es3perPdyseEDeN36ZW3BbnyfHeq58NnTk1mO3w2rx4vnkbyECI5FrY25OMSUY7XAYzmeXYA4ghfPZXX+NpwzrGSh6Umi54bCCdHjjtefPq4RmI8IxGN+9IVHVoYuzYOE5z/75jm5Xh+eiD2GN8i/9injpQH/D3vynmL5m+9dkT/6lS2Sle6QOkyujp1rk6fvL5MyhKD5WTgVsrc/eqNWajHRI5n5g1/aIge25oXGWY3chP/+m9tUuNvfff8yPENpcueuAvWGOzvDKd9/rTrUP0PKjpxqkU/eXSIbyzJkcBB1i2p6VRhbBpSofvHRVbIOOQgctxKT0H9+qUqakDdk2r0gZflI6vahOCLziVIQMvQLD5aZhyM+uxA2938sHqr79i+TOzChZ06S3ZYgN1pdcu5qtzz/dp2S6OXJJg6N6JvX+gQmvA4IRrxwpE6efbMuov+FvpHqtInhq1jodzL56/8JCnFuxveMnpNf+0SZ9N0ewDwtIRTSSQ/L+RqD4FCEoLy+T/auMV6qVTQakSK97iDq43hDggXn8Hsynv30dKsKdeO4v4px5RN8uTcUGvfjym65NtL/eH3p49ODwPTPDqfnuibVi1nXgwSAk3FrrZKx6nrwTb9pJCKs50HjpDkrpUACQcOjYBYiNJTE3jFPUSFX24vvVrkDJC+DCG+z2se1P5NOd7PalQliwwk5ycV7158PhevQ+8PrSLKHr4UnUG2KHhca33YzoZr5KkVZa0clOGsLdqn2TKp/79ozISLDEKA71jypyFhR5jq8bb+s2o33gzLcDL0ySWBV27lJh4rFSQIITmxCZY7PMEHldVGeGOTF8FPlxWQqcsM/1nNhyWW7JN7ulP7zr6lwNYatMVytcPO9UgLSS/IVbSRB9P4sNHsf38nxjKTj9fLvxGxGElvZflYtfJb8fejH9240wkTyziXaypuOghAdjd496rbyQLV8hN/5E+q7wndsAYTYTVpYYtQR9AGNwNwjwByVHBAK0974qCmC3HD/T99vkMdBcgpGKqavKDCmuDs35KhJ1jpI196/3xDvYPtkTIJJZrZicvdf//60yrWxkhu2SUPi9a71hgc/F8pTK5enyKaVmTykCNH38V+jtf9DKJ5o5kCwDfvbjxAgJn7bRt5ic9w9GxNlPfIbfuN/HBfmDdH2odq7Gc5DopOP+zDHVg0sP3iOSXC+/MVNcueOyHDnDSjyyGX3pmz5g6+fQd2TyOu0dKXInnVbry8MBPoGYs8rulCI969euIa8l2JZmZ+M3Bq7uqEOiA6cQoL/Kx9HvqS9gDC1MMEJvzAg2aHa2hC+u+UQGBjPmru88vevVcln71ghRfjuUiyDCm0kOW+ca5W38HJB2+wisCgIDiGbSl2PnoHwF+7Qus8o70VbX700YeLF/kzPw4dVL6tcHXprSKL4Bp9vmXMhc2tafJQngWE5Jrlhm254Pkhw+jCmmYvA/cyv4YSQCZ1Wo6qV1eo6LymCw7YkBLGM3ica36Cvzd9jaRLuOwWqUhMxEsPdZQ+pSvRs34mq8FdH8RyN1V9cHKacnHVajLlBzDUiiaQnjN6l+WrOok0SB5LTd/olZKwHxd9UIcMBryTu+hQTuCIue8jnlu6PfiQZe54SW6rxLCIaLJENfqdn20ikmL+lTSOwGBEoBMGx2ocXjJdx1n1cP4O30w8fXKF2F6DGyUSMnpJPwpvxf5+7qsgG83iijQSlzz1+/oCV3Jh98AWVDUnb0UbydHBHvryNN+6xrB0yu6OZz29MbvduyYkgN5equyUTYUJFkP2lrUUexr17l406BtvQ06Rt4SFw+Hy7cIllTPL/m5cqVYhYXmYiykMMSjeITyw7gxC2M1WR8y22ew4hnlwmYzUtHvnq89ckPdmQnCZhb0dNIgQXaJsDBBYNwZlKXQ+GY1ExyqzcnpGUiwKXuQiz2aWIB5Ol6dXh2+hdCEdiMcqJWvRky6wR4o2Sqx0tATpa1tYkRSp8CgQrehLJaySxMc305pjb5mdy4viJ8A4URzyw+nEVhsXzGDb0ce3ro76NN/uO9Uk1q4Orn5IrTR+FksgZNsS8j3UIt0vPC8eNxzp/PuxLzF8lGSgI2vfxj0FufBJor5Wek88qImN6a4awv/fk8zLk7hJvw0VJ3XBXxKXHwdtTDIUwbUsTAUdC5AR1aaKg73qqCBTmRJKVnlGKBkZPpKx1PTh2Pyq9f/VfyqUF+QJ/+Tu7Qt6eA/CyfOPZq/L5P3lfPvfQKvn0fcbfuvKqboTCnVcTNL7JHs8YOve//61c5Sr+2W+E5f8Hkb/wjecqpAo5QRyXSeC05SNEJFa/Z650yad+74g6xPCz3//FzaFmb3xkkKJH8bbctOOoPfKXuDfan/1mWIxhB3IxokkUCdt3XryOfJ8B6YLEtrbFiYAKd2yf/RIBfZ7Y3qXFifL8vatFQ3AI8VTqerAoYCNyEKi8xIUhY5SrpadkX9nD8taV78ru0vtD0rXMn+lEfH+fp0O56NcX7ov5dIdi1ASJ2XCUnVSlsprNQl68AY/1kFofYq4LcxDwtowhafWdV25qwx3RxCu6Eb1Ut0Ey2MwtYc7RufojIW9WdPuJbDNf5cCqx1X9m/LGY0rpivlKV1qOI+/osiryORnyOJExp7uNI6tIMg98VnpPoA6Q3y3B7iZ4a34omfufVmFsvadekGCf4RH0NSDvav0deBZhDw89YlszDSW66b423d/8R8CGkEttGoGpIhD51wCqniNSuNH9eS1FBBNVQdLIM7/9QqVcQfIz7bWjDfLLTxg5O+moC2JDInYwOKzCycx+qZRGcjJR+ybeXjP3hUYxAjNc7vnDdXL4pBEaRNJkCiJQkno8S8Xb8F9/0rhOtm1Ascbn3qpVp5meGm4w1O6Pf9VQT7QqzRVkJ6q21h/PvFmD+5/c23nr+Yt9fQW8f01RpHqx37O+vzACDLFbDLaoCM5k63owybksdzNUNFxypv5tJYfM8K8dkLqlshmlc1MdmQhFM94SMWeAhSrN0LVVkIM27WYHvHlkap+s5m4NoTPridCTQ/lqq7eGI5Aw8BivmQStuuNCaGBOrqnORi9Pc09VaH/0Cot6MleH5I5W0XxSrrWdim42pW0Sr2UZqyQPIX6Uxb7edlp5hEi4KCGdn1YqW1FHhuF/89Vs6XmScfvnDJIz0CNDrk7pOfbvCGFD/lV/R+iyh3wu8XfUSWLeytC+4aBfuj/419C2XllaCGTe/gWxZy1bWjet73baEIgO18pF2E0rvA/RVpgb9vS0I0mauSdW64ccs2nWgqA+JP4zvIySMLdi1v7dlhwJeo5Ms+439431+aufWiMZIGA0vsT7P89UKOEARnUTB9MYasc8nmiLlSt5HYnl2kZH4AHkNHHRphFYyAgsKoLDBzGZuh6sx0IlNUnB2yYoNjWpyT/oC+L5aSwuSVEA8z9ITtJNIwHZsGy/uYk3atMLJcUSKJ7AEDleY9lIXY8uqFKNZu0odliC3BZWb6eaGivSk9xsgXS0qVhV02G48GP1sQHeKJPckMy1ueolMzk/oinJoLU+UMTBCWzwehgSWJy9QcobjyqvDk9r66+TI1dvyOq8HUqJa7Q8owkMMaNNbCmZknX7ZxGi9pwiNUNeJCVyiTLvjYsRBCfqsN7UCGgENAITRqANUtBWO7g9Ty5V9Vh3KdWxPZvCE/ymjps9/da/YdZ15gpMxlMTMfAoG1FBCKO0Gnv3ToSX3bMn/GKA0tcVIwpY7J8eKzNnqNflh2x2+EWT2bOWnDaR0J8agaWFwPTOyucBdpOp61HbWa5qmLBA4+7SB+DlIJmJUx4Q3gon3d6gS4V8pTtzlFcnb8svK+Jj1vgwbzkdifPTKUnLGi53ofaOH94aVpjnHyOSC8rxjmbMa6GXhJ4a1sOhpLQtwR66H5IWErlYRo+QKTHN40WZa9QS3fYycmmolnWrRsz3rXxY5fewhhDrAzFR/HrbGdQ2uSqblx9UeFv/CN/qmNN1frwzVTJv+6x0vvkPo3bpb61UstJmjs6oDfUBjYBGQCMwDgLMmaF3hIn5tPsOLJfz11FA+aIxoecknzLIpgoZ23wUIwH78w+vBEHoVVLM9x8oZDNlPUjAjlW4M1rcwGw/G59O3NN//Ew4b5FerO++Wh0xNMPgypalqn3nrnWpPKKIBnpDI6ARWLIILDqCwyc5mboeZxGatiZ/lwpDo3eBFkT+TEP3NXgYDDJxqvZNlYdDAQI7EvAZ2kyVNObvsLAn81UykvIjZG+jxQT8kBem+aLyZ5jTo/ZHiQ8w3IzS0InIiWGxTNbeuQiPx1jeE4bovXftOdm+4pC6H7PQJd36zX01IEfvq7Fi/WB42kRsrPEncn50m7y0Yrl7/c/D83ZRrgFPYs97p0R2LTxXW1fcKSSX880G6m5WXYm4Rnj/vE1XhFLT2jQCGgGNwK0gEIDU7HNv1cmvfNLIRSGR+UPUrGlGmJp7ICAlqNBu5NwYo9S3um9KrOeR1SvS5Vv/7QDOGRQreTl7tSt0edZwMrb52u/vRW2ZOPn/vhUOew41nsGVRw4ul7yscMgd1//wl7eoEVnz6u++fwX5RD0hgnNoV6HCoBz1RkiONq/OQl5Opvwt2n2oJXpn8EnprjUC8xOBRUlwCPVE6nqwHaWcO5EDwpCoVBCVIApjulAk02ouXzeIw7OqjozTlqJIxkDApZowDMxqTJznEm1XWk5g/4no3XLuxhG18IAZCsd1Vn5neBrDzejd4MTfaqzz8fL5b1h3qXWqq31U/YokIME9ZUQ2mvuiz48+kffzyoX/G717VraZM7QmfweKnq5V6mr04NAoTf3e1WcRnrdFFSsluZwPNlB/XjxXRyeL5jX6bpRrgmOCoT81AhqBW0KASfG3IzSN9V1o9G4vzzXkkK0d09Px9R9cUcpn1v3mOr1AaZbTGJr24pEb5mG5diMy5HYlioJSQS1a+CZ0wgytZKeH82vMIXasy1arvBYSuh++USusvcPaOjTW3Ymu5ZNoD4u9qEb6h0ZAI7AkENC/+SOPmQSgx9N2E7mxfgvoWWDiv0lurMdmYl1dE0jOeOQk1tgM1aOaGpepnB+rz5nex7A/Fha9Y81T8IgZ1bQp6EASefjKD1SB0tn+Ixt9z97ma+K6+Gb07pjbwb5WKKvF1umPecJM76SqG0IWp7RYFOFm+jKn1H+CTWyZyyWxeKs4CtZI/ATk0Kc0jj5JIzBHCDCE7I/+4ax8G0UMSWKi/y/s7PXKGx81yn/+65NSFUVSzEvugPCA9byuPp/82bfOSX2LEUnAdtdQtf0n79QpUmOex2KF9CINWFTafCPrZk0atqUsr2k+v1HAM3q/d6SwJ/dbVd+i+6FIwlhGJbk+V0C+/LXTQg+U9b54Hrev1fdKxUgV+uj+x+pbH9MIaAQWPgJx+E/g1mRTphkDFtisiipyOc1DzNvu6MF5bNtvqes7Vvmi8mDM24ud4IWxps5DW35lgq3Dzfi1pIT0ZeQVBeBVM42S01tX3CVZybOv8DLk90jP8WciFNPM6xrt01m2W9I23ytUUet44+ujNZuV/Vl3/bLY0sJJyJMZ1F11UjwV703mlFlr60CdorQdjyq5bnPQYYQIeiqPi+f6h+auOf3UKmpzCv+0Dv6vr1RGeDymtfNJdOaAZ2JZbpLws6ndo8LOYp3+7P8+FMrN+fP/d05qUKG9AKFn3ail04bq66NZsjNB8llgFDOEZggWmIQm0RGvclW9IDCcPcTjvQnr2pAEUWbaNGryMDeINWfMc81j3M+WVrIzWj/mOeN9UuaaIXWUlaZCXDvubcBCpm61//HGn+xx4vuDr9412dN0e42ARmCCCCzaELUJ3v+8a8bio7ToQp7z7kJn+IIYflGasxmiCaulouWkUBCC1gOP1gfXfywlWRtk4/IDKk9phi8l1H28I1myQRKCrm7xt1erJdCJ0A5MpkczX+NlSd14aLTDs7rf13I9RHB87TXjjm1Ly5MECCoMB5EXVXN63PZz0cCWXSzpe55S4TrDg0EZdHdLAkhcXHyCpKw7iGfVIX543bRpBBYbAn54S+qaw56Xid5fTz+iFbCMZyQJtSBD0RZNVihFbZWcNtuT/MTaz+NW4mG2H60f8/h4nyRXDa03K8eZ591q/2Y/+lMjoBFYGAhogjOPnhNVxJjroy2MAIUStsFjU5qzCSILH0gXcqZo9ShA2tRbpZTiVuZtDSnFhc+cuTVbapbYUndL8srdavLv76oXfysIT1u1DHkj6ysMQ1zCh/2JuaUzd0ET7NlTdUKSEMJFFbiB6lMS6Kgd88yM/Z9RBMdTfVJY22c+Wsqa/Qa5Cfqk64PvypCnR+KTMiTrjl8UKtg5V2zRBGc+Pjh9TRoBjYBGQCOgEZhBBDTBmUFwddfThwAV7A6u/hRITaVcajwG+W6Pyi261PwhcnOugATdGSrIOn2jjt9TnM0uifmr1cKwukFXlyI6Pnh4gl0NCO8YEl8DauLMA4IjgwFxXz8maVsfhFfp7jELj9rzysSRWyaDXpd4qj82gKBXZL0RUhHobVbkgV4Tf+t13OMliYOHKwmqcSyIGmd3wpvSJQFgwGPKEIKZtHq/CiUbQMjbkN94+xyfki1JJdtVk4j9qdhfbOx3X3kXx/FK2GI8zzFSTLW//G1Fbnh4aKAX9/khnskqCXTiGcwD87fXSqC7EZiWGh4mxu9o0wjMAgLnIZ9MBbIAinl29oQLbs7C0HoIjYBGQCMwZwhogjNn0OuBJ4sAw9ZYsDQ/rVSut56W6o7zqnYOVe4+rHpZ1QBi/RzW2JkL4/XZ0nLUkrx6L7w7PvF11EsAk9shkIv5YN76i5JUuluRECbk+1CQ9GaLk9QN96jd7mtHUfF25NpBUJJX7bmpuT2jQAY9fZKx50mQF4vyUfYKEJRt4l+xWXo/fkHibYkqbIw4MXTMHNu5fGOo32B/OwhRuRrDWbRF7R/0gLBcOXLTuPSk0RhC52+rEpIyW0ahDAe8IDY3xFt75qZz5mqHr+UqcrfahZQuzp4k9twSkJ0SsefgmlE8VptGYKYQ+Mo/xfodn6nRdL8aAY2ARmB+IKAJzvx4DvoqJoEAi5JuWn6blCBsjbWK2vrr1dnNvdXS1lcra/P3yGrITieM1DWaRNfT2jQOE3pn4Vq1UGRgftiwuCqOSOa+z4Bs3CG+poowgRm5QGfJVhCgXAn2toVISKxr53GBV8fXWiXpOx9T5IYeHTeS+wcRKuYs2qS8KI6cUklec5uS1g72too9s1B5XkyC4wAxMY2TfpPg0DNG86FoaiwLK6UNISTtS5KQnBHRzIO8IffldyL2zdXGIAidaQxb9DdfVQv3xTvTQc5KxZED0oOFIYSLxQYHB5H87hWXi0nqBlFOdECSPzVZUpKckpCAomLaNAIaAY2ARkAjMM0IaIIzzYDq7mYPgdTEDDmw6jFpAam5hCKobtT7oTx2RetJlaNDb05hepnK0Zi9q5r/I9GjRJGBRIR3Ja/aG6k0Bhnp5LUH1U30q7Cw2PfjR/5O74nn1EHHsvXI1dmn1vvOvxaauPtR6JR5PAx1o+fHc+0DkJXrBsHBRB6+DBGE+NlAeEyzgwzROOknyaJRHCGWxScZnjoSyQQs9PQE+zvEnrVc5d8wR4rEwls/uwUKY10rhRDoWfJ31CH3qT4iV4t5WyR7JuGLT80xyA6Inx0iChFesVidz7N9wSBIrmdAmppbJC4xRYZRsNjnt0MN0SAz9mC89MLrFtfRi4rJHllWWCApyUlis+k/R/PsUerL0QhoBDQCCxYB/RdlwT46feEmAiQxeakrpBry4tdaT4HkQCIYZOfj2tfVfspKs2CqtjACrstHxHEXPCsgON46hPqN5MMkr9qnhAUojBDsrAufELXmaw6TDntWkTo6ONAXIjdmc0/Vx4rgUNUsPikT+Trwxqy/UxEQEht6K+IsNXao2qZya+DJoQ35B4xcJrNDy2cca/qMmB+5PopwDQXRd4pkHfplNUbSyn3zguDEMywNOUH0aqlcLXi4AiA7fmBMwkPyY9qQq1O8XOrOYhfCHoGTnd4deHnsmUUSh5o/02nDeClgfQa30rfX65Wunj4JoCByWzBLOrsRphnsxz1H5hzFxQ2L0xYvuWmZkuSPByHqkuzMdHE650cx31vBQJ+rEVjoCPzbu/Vy6nr3Qr8Nff1TRGA55Of/6Ml1Uzx7/pw2vX8pp+G++Nad0sDaFgcCVEGbDWM42tqC3bIia72wlhIV1mjtrgY5UvFDWZW3XdYV7BGGt2kDceAE+sYFJPfvkOT1B1Xx0vjEVEV4OOElARrLGIIWbQxPizZ6VUyjxyXYWa88LQwns8Ozk+BMUYcHcC2OvFWKXKlQrYjwtEhxAbO/IZ/bXJUBkgGQGxrJmq/lmhIuSGB+C0MVR46FTpjDFZWrlQIlPixJpTsU4WFB2ADIDj1jga5GS9jgsAR7mtUyABU8hgTaslao/B2G/tkyC26ZnPSdekGJR1Ac4lbtes0N6QqmSGtvt6p/MoQOY+kpUEKYRSMbOgekGUUrCzLiJbv7hmzduPZWL0GfrxHQCNwiAqxdhH/aligCfP6LweYdwSGo2SnhkJXFALK+h9lDIMmRKnvKHpQOVyNkpd+Xfm83tLeGUTz2nDR0X5PNyN0pylyHSVfkG+XZu8L5M5Ln6jFxLt8kTggBMF+FYWRUhSNZGIIC2lg2bAoPoFEcK+jBrPvUDvyIt1kI5UgeEnNqGD7myC+Dl8XIN2HoFr08CUWbxVG4RhwIzaJRoW00G/L2hw4Fu5pC61wJ9neqbT5nejyG5xHBibhQbPAa7Rn5aqFHjUVKAyA1ysMD706wB/cG0qkMx+hZ4+KRDxDi50A4WzE8PMjhoUIbwtsm891m8VrKm/u7bkjG7k8pb1v09U10++ylq3KjGxXvE4bFKGgP7Ef9NcMB/OPfUdYn6XANI2wtKH0fn5ODe3dMdEjdTiOgERgFgSH8csXHj/oLOMpZerdGYPEgMC8JzuKBV9/JXCGQm1okh9b9vNR2lKtCocEhP0JlPHKm/jD2XZItkJXOTLr1N9ZzdX/TMS4nt+7KE1BMu1Oy9j+t8iWGAj5xg/hMxlj4lGZDgU3mzlhrATEsy7Qhr+FxoSiBIjjwRJjGMC0SHCcIDnODaCRMJD6jmdWLZMsuEn9TuAYRw7lo9CBZw79G62s+7ScODijQcWGxUgpU+CExzdypADxgwT6IO5jGY8CTC9FleJ5tRKHNAYW2hOR0s2XMTz8L1dKQE9N78nlJ3faQJKF20GTM5/NJS3u3dPuTxZ8Qj4r2w2MQm8ieTQLkwzlDCenSiXyk8opKWbcKIXkOCzmOPE1vaQQ0AuMg8P6VTrwstsuGFWniQDioNo3AUkNAE5yl9sSX0P3GI7djVd42KcpaIxXNJ1S9HN5+l6dF3r/2nJRmb5KNyw7gP//ZCaObj9AP1JxSYVIJIwn77qrjIAQDk7pUhlYxr4QT87QdD0nf6ZcVqbDBo5ACuWwaQ7CGfIbHJQhvwRByTuJRK8c8NgyyFWiPJDM+TOglRtibOgk/gt1NSunNBu9H2uZPoDp7h5JiNkK4ylQz1p5Z6BYHLw1Jn0n8lNcFxISkkARwyBOOlWd4HsUduNDikzOVZ0fJUmdDoS0xOQIOeolChmfoOv86+uuD0MRtE/IEUVCgp88lNZ1B6fYmgNyMeJpCnRor8fHD4gD5obHNUFRODvcHBoclwZ4uHb5hye/rR05OhhYeIDDaNAJTQCCA37PyG/1S0eSSDctTNdGZAoZTPSUrzSEluU5JtCdIR59falrd+Bs51d70eVNFQBOcqSKnz1swCCRCxWl78T1KVvoiZKV7PMYb8Lquy6pw6IbC/VKas1lIiJacIXTLffV9Sd/xKLwdfTKAULXJ2iCIhbf+HIjSToRLlUrOJ/6DIjAUDKBRKKDv3E/D3SLcyg8VN9a/ofnhlaAN+Vyoj9MlNhT4pI0VnqYa4IcbymxUKIt3JEn2Xb+kdiuyBdfAEIqUuq8eNZsums94FFR1QrmOC21woN/I3QGOJImmYASPDSFXylvP5Tw3UWQ0b6QGDwq5wkMUy0PmQTHYQXhS0rbcr0irOnGUH26PR7xxTmn3QCEOE6q4Udo58Ye+IIM1kuKkBTk3A0YM202tBwLD0g7y4xUnhAc8kpE+tgfqpg70Do2ARiACgSBeHGiiEwHJjG047fHyi3cXy46VkaJGTd0D8u236qStxzdjY+uOb0ZAE5ybMdF7FikCWckFcuean0OeQIVcbj6OCdkA3hr7kavzgdR1XpZtCFvLTlm+SO9+9NvyNV6WQNlu5OF8jBnx4OgNcczqebE2dJUfxkS7T1LWHEAeD2SbE1IRYhZELkkjatG8C89Kh7W5qm1jEpxAR03omB/rJDgUOmDY1XjG/JGeE89K2tYHLQUzhxHS1QThhLdkaCAscjBeXwv1OL1vSSjaykUptIEk+jsRzkYPD8mjpQYTi41y8Y5DZClZPQTilLH7CfU8R8OmuaVNWgMZwknUWJbqtMlGhMqwVf9AYFSCwz7YV02rRwrsvZrgjAWqPqYRmAQCmuhMAqwpNv2NB8tk/XKjfEFHv095rdOT7bI8K0l+7b5S+erz16bYsz5tKghogjMV1PQ5CxYBJmCXZG+EUt8qudrysdR0XFQiBH3eTjla+aKsyFyLIqK3i9NuqHst2Bud5IX3HPve+GeAdHS++Q+jtBuWgaqTaolPylDhZ0EWtxyFMPlRYLSdRUajzH3pHeEyGaMyW/e735Y4eDaozhaEQpx1Uj+ZvhZ6W36/bWk5ahGQVhJFFlf1K7IDcQIqtMFrV5ENEook5HTfoGT6hiQxhmpOAIpu3R/+UDL2fVqp20VjMzg4JDZnpnR2+qCBwLyb0fw3xpn4d/3KAABAAElEQVQ8DNkBbIzejkeYHM2wjuXLM4VjJIyEtkWPr7c1AhqBySOgic7kMZvIGWUFySFy8/7lTnnmaAOiQkSe2LdM7t+eL0XZSVKclyQ32icXAj6RsXWb2AhoghMbF713kSNgT0iULUV3IDRtEzw4R6Hi1KDuuKHnOgqH1sja/L0qfycBeSXaJocAvSZz4TlhHk8Qi7YwAqxvY89cppaUNftDXrWk5o+kabBLOlLtqrETks0G2RmUDJAe24hDht6enqP/DpLzcyi8GinK0e92SzA+UbzI2WLz0WlL+HomskYi5EO422C8Q1xuhqkZoY4eXNdH18ZW95tI/7fapr5df8duFUN9vpFzdvhi+4xB0Y6XBGPZQic6W0rTZO2yVGns8kpZXrKsyEmSqhaXHLuK/9d6/bJtZbpsLc6QvEyHePF/B9vxWBdwIfF4YGe+JDkS5PCFdunzGCUGCrMS5bb1Roh05H4n9mcpOF880Rwzn+aezUZhasre//gjI/eT743ePNcqJSA2Xj/q8+E6tM0eAprgzB7WeqR5iECaM1tuW/W4NPdVy6XGYwidQR4I3nBfafkIoWyXQYLulPy0kjGvvLUPEseYlY3VjoniqQij0rY0EbBnLZsXN07JbOZJ5ce5penGu6Fr8jrihUtbGggPsmGTTcLjBfHx90v3Rz9AuNonI2SkXS4PCuoirwbffSu5IUFJtMdJAmYRXKclo+8EbJAIpSRirKCR78bEW9Zc8CH3JpyEa5zkRZ6Oy+0NEZwg9KRb50EMu1tPUtQz1T9uDQF+3+fD99lKdA5uyFaehlu7s9k5m+Tmvm35EYOtLmQNLr88tT9NtpdF5sFsLc2Qe7bkyXffq1dJ/4/tLlR/t1vwf8pHFcaLk12rMkN9NqNI8XEQItq+tcb+ToSdvXC8OWJMc6MgyxDNOVnZLTnpDllTmCppSQmqzte33qjF/3GxBVjM8/Xn9COgCc70Y6p7XGAIkJwsR3FZEpTK1jNS2Y46MAjtcfl65Xj1T6UgvUx5e1IcNyc8D4IMlSOHh+3vXv8LYxYS9ecVLTBk9OVOFwJJ09XRNPWTPjyGciB+HzyJCWppwVc+DjOxFBCejMsvSenquyW3aLu6Cq/Pjxy2m6WcE21xkpuCPy2B/hDxSU0YwltT4/cnzeaFJLRX9UHCM+xIk05XEG84uRU2P8LTvJCgtppJmKz7Znt9hLPN9rB6vEWIwEx+n8MvDMYHLj/DIVtL0qUgc4z/F8bvZs5aDMA70gQPTQ5e0GSl2kLkphrqZe8hXCw9ySaP7ioQJzw2X7irWP78mStSjyLDpbnJKjfQJDibio38Gd7IOijPmQRna6nxf9f52nApguibzYIkN203SNIn90a+0GI+DkUGGjp0eFo0bjO5rQnOCLrt7e3y9ttvS1VVlVpaWlqkqKhIVq5cKRs2bJDHH3982usyMCG4vLxctm7dOpPPeNy+ea+c5BcUFIzbdjE3sMWjZsCy/VKcsxGk5ai09tWq2+Vne3+9rMnbKWsKdgnbmVbdfl7cfuM/vYqWE7IVHp9YRjGD9649E+uQ3rcEELhz7c8JRS7mi9l7u1QOzuAECgEO4/8GFwiPPaNQUvPXhG4hEAgq70tox8gKJxErkOOzPDtDnM6bJ0zb1obrH3m9XoSODIgb0tBevxEmYvZHzw7HMC09yS6fvSN8rrl/tj99CEGpuN4z28Pq8RYZAg68CJjJ7/Nb59tkvDC1hU5szK/EN96okepmt9r806fXq0/+v/K1lytVMWHuqG3zyJefWKPC0m7fmCPna3sNglOUpjzNVEAj4TFtfZGRh0vJZ4oE0M7XxRatobeaQio0hsoNYW53tbFfEaqV+SmSm5aoRAb+53NXxxVkUZ3oH9OCgCY4gPHw4cPyd3/3d+JyuSJANckOic8rr7wif/AHfyAbNxrSthENp7Bx6dIl+fu//3tFLL75zW9OoYdbP4WTi+9///vyzDPPyF/8xV8seYJjIkpPzf6Vj0gbSA29M/Tk0ENzre00wtauKhECeny8KBx6rfWUeZoSLCjKXAMltsi3N6EGekUjMMcIeEDGuz2t0txTLoMJE/dFlEFGnTlr8XHhnDS73SYJwZv7YKz5jS6/1De3w4NjeGUy0pJlXYkRTnL9Rhtq5xh5LJAmQIHZDBmIEfbFSQPH0KYR0AhMLwKLhdgQFZc3GCI3yXgRUzjihXrnYkeI3LBddYtbqtvcsgqEg21IAJ/Ys0x4TglyeDLhdY63vPDJTHZIAXJy6MmhuTFO1QiJUjssP0hWrfatN2ukvM6o+/b43kJ5aGeB5KUnyvaVGXK6Ur8csWI1k+tL/q/HW2+9JV/96lfHxbiurk5++7d/WxGhW/W4kDB95StfUWOuX2+8bRj3Amagwa//+q9LQ0PDDPS8OLpkyNqhdb8A4nIBROZjlZvDHJ3TdW9KXWoREqEHZHA4Mmnw3I0jOOdp5B8s+V+txfElWMB34Q96pWegTbrdrYrUsP6Tf9AIDZMwTxnzDlkbatuKQ0p5MLqhM9Eh9hgFO/3Ip2HIWXx8aihEzTZkl0FB3g3ebLqCSdIzaFwA6c8Q2vqDkeFpHIuFQTmGNo2ARmB6EFhMxMZEpK0vHMZKfkLPL1+OMF8m2qjOSIKTneqQpk6vapMD78rGFamSAUJD+xD5OJtL0rBtVyIGW4qN8LQLdX2WPMHIngcQwhtASK0d/2e19XpD5IatPrjSKQ/uyFcvs5cjT+d05Kl6awYRWNKzMIal0YtiGsO0PvvZz8rDDz8shYWF0tjYKC+88IK89NJLqskQkly/9rWvybe//W1Il05whmB2bvns6ZkfDL67O1wB3XJ5etWCAFXU1uTvlBVZ6+Ry00fS0GPo2He4Gi2twqsuX49cbz2tQt3Ce/WaRmBmEWAuWO9AR4jI9MBLY4ZOTnVkSqXvLXto1NC61NRkcau8WZOcGG8xuYsCAVZL8SdA/pn74hCONqgW6/HIdaM/hoykpiwtufZIHPSWRmB6EFiMxMZExgePccjwXxDJDS0R/39EW9LIPnqZaefhZbl3S6JsAolhng6toqkf87s42b82S7Yh98b04IwWnqZOwo9eT0CFonX2R6rX9bgC6v9DKrYlouCxttlDYEkTnJ/85CcRYWkMQXvwwQdD6JeWlsrv/u7vSn5+viI1PFBTUyMvv/yyPPnkk6rdiRMnpLa2Vq1v3owwji1b1Dp/VFZWyunTBl/PysqSBx54QOgxOnv2bKhNV1eXChHLzMxUY/f19cnrr7+ujqempsojjzwiHIPnkJCtXbtW7r333ohwMobWvfrqq+ocEi9em5WAkaAxHI12xx13qDcJH3zwgfj94V9EbtNLxePMPdIWiQAne7tK75Oy3M1yvuE96fd2RTawbF1vOyPLMldLRpIhG2k5pFc1AreMAHP3XL7uEJnphmemD+QGOmRj9p2KULDMpALJTM6XrJQCSbQlydtX/j3mOTkoeLun7AG0CcekRzdMA/noQC5Pog2qaCA005YwjdtwUnVtyA+CY0i2Ro+ttzUCGoHxEVjMxCbW3bsGBpUcM/MAN0Mi2gwTY1u+MFkNZTMayQjtInJq7t2SK6sLwi9SmDtDkkSCs3nEe+OHbH3FDSPkTJ0Y40d7r08RnCx4h/h/If6bVsbaNyQ3tPoOLTGvgJilH0ua4DDH5v9v7yzA5SrOPj4Q94QIgSSEQCBAsOAapLi7Fy8tVqSFIl8LFIq0UKBAoUUKxZ2iDZRCgeLubsElkAQIgYT95je377mz557du3t15f8+z71HRs7M/5ydmVfHCMYBBiSLttlmG3fTTTcFBoP0J598MmFwMDfjD9piiy3yGJwXX3zRmX/N2LFjQ/3XXXede/XVBi0AZWBayLPgggsGBgftjpXB6f/pp59O6if/Pffc46644gp39NFHu5VWWolbburUqUkZrtddd103YMAATgNdcsklzrQ1I0eO9KYjc+blJ9Ptt98e8sLciMEJUGT+w7+GjUJf+OC/mencZKGJqRqO5Zj4VAoRzLel7aFP+CFVKnXxviH9PUPZr8egYIb15YxP/aK7wem0UttcarvoB34zmJphcoap2awfGiboQnV098zLIBgZGJo+/ujPu3Vp6vDf0zMw+JLFNGbIEm78vKs2+62wAeesGV+6If0HuA98SFVvGZKYpMX1cQ5TxoTfHBNGHsJJD/VmIz98N9ULaiQkSGOpayFQCgIrLTzIhyluDIhTSplayPPSe9PdBB/JjJDXr3443T31xlSHj8zOa4wK/jb08YXJDYGBXv/gK0cENmNACEwAkwSTE9NL703zJmj/41jihOj8Pm+KtujI/sG/Z7tVR7rrHnw/MDqYpxm9+XH+WGv3dWwfBMTg/A/XlVdeOWg2smDu3r27W2aZZdykSZNC8uTJk7Oytfm9jz/+2PEHdevWzUcUaljUoLEhKMBll13m5ppLEs42B75IhTP9YvCVjx4rkqMhaapfYL/56bPevG3pZvN2VIY1xm3v+vt9f1pCr338VNgbqCVl27vM3P1Hu2XmW8cv4Hskj/rB+0ZhKvhKFAQiSazgE6LtTQ1+M953xjM1MDTNMWowdwNgZvzfQB+pjWhtvX3o5VKI/GxsC3XxzPhSo9by5pil+wXOM3yY3zOni/vE27Zn+dFYG776drZj4QEDg7NuMermzUPGeIlq/+6N77NYfqUJASHQFIF6ZG5A4Qa/Eed4H/K6u9cs7/2j+d20Vb732psu4Zr0Bzwj8sxbDQwOQpnn353mlh/bsInny+83BJqa+vUs99GX3yYBC54uEh6aOqFnfZ1v+UhtY4b1dhMXGxz+ZvkHdP2fydydz3zsNd5N/YIaSut/eyBQtwwOWg/Mw4zwuSlGcTq+ObNnz84zAytWNk479thjQ0S2K6+8MtxGo3LCCSe4PgVszYcOHRoCEqABeuCBB9zxxx8fGJ0ZM2YEBufnP/95XH1J50svvbS7+OKL3b777uuoByKAwnLLLefmnXfekuqo10wvf/iIl543mvYVw+GVjx528wwY4zc2bNSmFcvf3mkfffmm6z+8gcEhQlxz1L/nYD8x9Anagrc+e6a57J2SjinVCvNvFIQT+KEQ8Q4mjmhf44av4KZ5U8IPp77ZKW1r7qFoxKZ9+7nXyHhG5utP3BR/xPSsGKGF69tzkJvLMyYDvZkZJmf9/HVLNXMwQzA4vbr1c8uP2cDXN7TY45uk9end2830mhbvt+s+nzFHk71srAAmbGycB2HuUYh6dfd76PiIrN1z3/gxcWChbLovBIRAnSMwbUa2oGSK94E55cZX3c5+vxuYDcLLQ+xF87iPYHbLYx/lIfesN1NrZHAaNTcwO0Rb+8EzKc/7AAOl0Jm3vO7Q3izvNwYl4ADMzTRvDvfIa1PcPx7Jf24p9SlP6xCoWwYnHRIas61iFPu0zJo1y/EX3ytWNk6bZ5558rQuMDb4+hSiffbZJ/jdkL766qsHnxwLesAeOi2hXr16hWfGfcYsrVg7WvKcWiuDRP2dKS+V3K3ZfgH7zOR73coLblZymfbM+PqnT7rRfo+fHp5peeOTp92nX71X9HErL7BpYHDImzZjKlqwAxMX8vsSERwEzcd9r14THOt7+zDfExfaxkvserpRcy1SMQzO1575aoxqht/MJz4KX+HFPjDCeCSaGW9qNsAzIPE+TK2FepCvc0jfkW650et6vBr2eiinzq5du7qB/fu5IZ9/6ab5HcRnd+mfacqB5iYdeCD9HMxIus2a5ob07O4GDhjaovE1XaeuhYAQqE0E7n7mU8dfFn3khSmn/eP1EGhg6MAeXms8232Rcv63ck96E7Yn32gqwLv2v+87/sohzNguv2+yu/L+yW74XDBHzn3k980SdQ4CdcvgEDiABX5DZJ8GX5hir4DNMI3QqvTo0bz5hNVt5VpyXHLJJfOKcW0MzgcffJCXVuiiLdpRqO56uv/JtHeD+c/3PtTud7Nm+oXczGZ9Cj77+n337hcvuXkHjO10qGZ5DcfL3rxuqVFr+r18Vi268eiwfqO8H8SoYB71ug+aAKElWGT4//y+/OIc5gGtyUdT3wr7A7FAXmDwEq5/78E+xG+PoE35/KsPQhrl0T4sNMxvlOrT3vj0aR9mu8EeuW+Pgd6vaTGypO4PSsITv/ThQ02wxmmeUN7Qc+/dl0QNY68X9ica1n8+N+WrD0N6Z/975M3bGkM0F2hMty5+Yd8LU7MG7QyMTTEn/wLVlHUbn7KVFtikxRogHoYJ7/hxC/q9bZ52n3873c3RtZ+b6UNFQ80FHoDxgYh41GP2NDe453dusXFts9dYQ836LwSEQL0iMNNrjt/7tMFKpSMxwPSNMNSizkWgbhkcfFowOzMmgY03CxEOsi+91Ci5HzVqVGZWzNZiMp+Z+F6550hIY0L7YoR5WRbz0h7tsGfW83Hc8OW92dPyCQR8Fzh7w+iwv0jM+HzvGaCGezPdF1995Ib3G5OU68yTd70GaszQJbwmYLCbb9Ainvl6uUlzYEQWm3eVcB+TPNvrBwYny6eIRfk33013K4zZMM8PZi5vPkZAhlFzjXMs8PGRwWwMjQumWLQFGjFwoaTer7xJmbVplPcF4XnU/eKHD4a88b8+PqAAxDv4ePrbntkZFRgEcCeM95t+/6JKoe5de+QxOGBJUIRBMDSYmnmmBkavoyneuLO1z151+aXd8y+95j73m39+PDXnv5uGkALwMHxTMTUwNjnPWDWEdR3Wdw432G/qOX6RReJsOhcCQkAICAEh0CIE8lfPLaqiegvh12IMzsMPP+yee+45l7WJJ5HLCA9tRDkjFmtGcdhl7k2f3mjPaXnKPeLvEwcSIOqaEVHWYjMzux+3A1M6CxFt6Tq2DQK8e6Tu/PV2xZ26MaGqBGLJ+cL7/w1mc4vMs6J7/8vXEgbG2gdTgv8N+6oYs2Fp8ZF0FshocJb1Jk4wMGh0Xvv4Sa9NmepGesZmbq9hwQRq4bmX90EKHvYmWp8Gkyu0Q8bgDOvfKDAY0m9E8sy5B4wOjyvkQ9PLm9pBMJpsroppWkyY1r2QwRjFeTrqfHCfEb7fw0OIZsI0E0K8LZmLjupHc88ZO2aUGzx1mhszvI97x0tOsXufwZ44cDkRwdgQynVI/+5u9LBervvsb7yp28goh06FgBDoLARGevOqDwb37KzH67mdjMCIuRoF6Z3clFY9vq4ZnF133TU47psW5De/+Y076qij3PLLN0rp//3vf7vTTjstARmfme233z65Hjx4cHL+7ruNjttob9i/JotipgQGpBgRVtqYLtr5z3/+M8lOgAIoZoC4ph0WFOHBBx/M1PKQr5x2kF9UGwjge0OQAcy72MQ0jjTWdc6uiZbqhQ+aak0MgU+/muweeuOWcDnvgAXdQt2WCedPvXu3+2BqQ/h1mCf8eGBmFhi6lDePe8RL9t9qYHA804NUv8uc3fxivzGMJswQhO8JTBYEA5VFvbo17GlgTCaaHpz25/KMBP43C3rtDxuvvjPlxaziHXpvPu/7hOlZrVPPnj3dMK8d//qbb9w3Xb90Q4f2dTn/LmfOmu0DszT0nj2Se3b1/773JoqzvnQDfbS0Pr3nks9NrX8c6l/VILDe0nM7/kRCoJoRqGsGh71ntt56a3fttdeGd8geNIcffnhgDogmBqPw2Wef5b3fPffcM4+hiB3zMWM744wz3MILL+zuvvvuvP1u4kqwWTdik9Bzzz3XzZw5M2wqavfteN9997kjjzzSLbvssu6hhx7KM5XbbLMG53XM1tDmWEjpM8880+20007uk08+cTBIhShux1VXXRXqX2edddyECRMKFdH9GkGAfXyGLDzSMwET3Nufv5j4wyw4dEIILPDxtHe8mdd7BXv7oY/IZoQfBzTju68S5sbSXv/kqcDgdJmzSwhd/KGP2IXmCAZkQO+hfqHbJ8//g6htmGoN6duw2ex3s751U77O9qOZ0zNjRlO+/sAzXDcHp338VtYat8P/mJwJFcHgWDvr4Ujwlf79PIPq/zCX/WbGTPfV1z6M9HcNYe67d+/mN/Ds4Xr7gAldugyvB0jURyEgBISAEOhgBBpXCB384Ep5HAwLzMXNN9+cNImAAnFQARKYtHfeeWe3+eabJ/k4IeRy3759nUVlswAApA0aNCjZYJNro9jEjQXANddcE8JEH3zwwZYl74j5HH8xEdJ5tdVWS25xfv3114drzO5OPfXUcE674/YlBfwJ7fj888/DLXyQ+BszZowYnBikGj2f/m2DD8z8g8d7hmOFEO2NTR/RehC+uNhGpkBCRDAj27xxdq6pNhKHf6Nefm8WfGPQtLBPy7C+o7yZUoOZGeZqaJRgcGBu5vbhtSFCGFv9Vo8dv5s1w07dW589H5gbbhC84MNpb7rRPnBBH2+2xv4uzUUrSyrSSZsiwPjTr6834PR/IiEgBISAEBACHYVA8djIHdWKTnwOJhWHHHKI++Mf/+gWX3xxFzvx0yyYAzb5PO+889wee+zRxIwCU7CTTz45b/8Y6lx//fXdcccdl/SMid5oEe9Iu+mmm9plOBJMIPadsUTM4+K9aci3xRZbuBNPPNGyhON+++0XQkjHWhmCIZxyyimJiRsZ43bQnyFDGncKx2StLQIj5DVMFxWLwCsfPeoDI3zngw0sGvZSQbNCCOJ3Pn8hmHYVazi+Nka2BwvO/mkiYprRrNkN6R/9b18aopwN9UwO9On0yYnGaLhnbob4AAXQhwXM00hDY2Q05euP7TQcp8+YEo74Sc3p+yQSAkJACAgBISAE6geButfg2KvGLOuss84KDsuYemHexZ41hIRujsaPH+8uv/xyRwCAL774wmH6ZowEAQqy6NBDD3V77bWXe++994J5WcxoxPnHjRsX6kajxOakaFhiJsbywpwcdthhwcztjTfecITBNt8czNuyiLoxTZs8eXJgbDC3y6o7q6zuVT8CM70GhBDQi86zkltlgc28SVfvEBHuFR9KuhwybU6/HnN535m+3qm8kfEgyIDRt7O+DqcfefM3fHLMtI2bn3rNDk73I33kNAv9TFjrzzzjU4i+jrRDc/UZ7gMmTE+yDunX4MuDtogodyIhIASEgBAQAkKgfhAQg5N610h80cqYk34queglzFApDJFVMmDAAMdfKVRqmwh/jYaoVIIRm3/++UvNrnw1hsCbfj+a+Qd7zWX3Bod9IqARZrkcImgBkczws5kw39rusbcnBaZiqA8YgI8PhPP/t983MDife2YGpoOoa5aGuVl649FPfSAEC1EdMqb+ffGNZ/p9JDciki0xYnU33YeYDkEGvE+QaYYK+e+kqtKlEBACQkAICAEhUEMIiMGpoZeprgiBchHAN+WlDx92y4xeJ/jGvPnZM+VWERiLd6a8EBgloqCtt9hugYHBnwYiUMAT79yV1ItPDVHc2P8G+nRag5YGBgjfoH49B4X7haKnhcT//SMy2wrzbxQCCqw5riG6IcwWgoqZvr6XvRmeSAgIASEgBISAEKgvBOreB6e+Xrd6KwSaIvDel6+6L7/5xDM6D4UAA01zNNwh+EAhc6/n3rvfvfjBQz79O6/J6RqCBeCnQyS2B9+8OTBBcb0x8xJrbvDFgXjWR9PeDufF/hHt7SFff2yuBgM15euP/P1bPdPWGOSgWD1KEwKlItCtq9/ERyQEWolA165afrUSQhUXAkURmMNLO1NbsBXNr8R2RoBAA88//3zylKWWWirx50lu6qTqEGDhf8fzF1Rdu1vSYDbcxPxsujdLg1HpKOretVeImoapWlbAg45qR9ZzVl9o67rYByer77V279p/veMuv70xTHqt9U/96RgEhg7q6c7/9cod8zA9RQjUIQIyUauwl46TP1HbREKgWhHoLK0Jfjxx6OhqxU/trmwEBvVTVL7KfkPV0bqB+o6q40WplVWLgBicqn11ang1IdCtS3c3ykcIE9UnAoN6a1fwWnnzY+frXytdUT86EQF9R50Ivh5dFwiIwamL16xOVgICE+b7USU0Q20QAkKgFQiMmruP695tTvfd9x1nftmK5qpohSKw0Kh+FdoyNUsI1AYC8nKrjfeoXggBISAEhEAHINBlzjncAiMbwqp3wOP0iBpFQBqcGn2x6lbFIFAXGpxXX33VPfvss+7ll18Of2zIyUaYbOS56qqrug033LDTN7g877zz3FtvvRU+jI033thNnDgxnN98883uv//9bzhnM9Iddtihwz8e4lAQ+GCJJZbo8GfrgUJACAiBSkNg7Kj+7uW3FKGv0t5LtbSnR/c53YihvauluWqnEKhKBGqawSEi2bnnnutuuummJi/nvffec/w99thj7rLLLnN/+MMfOnXDyxdffNE999xzoZ1xkAGYnkcfbdjLo3//jrf9fuGFF9yf/vSnsK8ITJhICAgBIVDvCKw2YZi79b736h0G9b+FCKyy1DAfTl/hxlsIn4oJgZIQqGkTteOOOy6TuUkj89lnn7nDDjvMTZkyJZ1U19f/+te/3AEHHODQgImEgBAQAkKgAYFxPtCAzNT0NbQUgY1XG9HSoionBIRAiQjUrAbnhhtucA8++GACw5AhQ9z+++/vllxyybCvDJqb6667zr3yyishD0wO5mC77757UqYSTrbeemu38soNsfIHDx7coU368ssvO/R5epgQEAJCoBoQmGOOOdxGq45wZ1/dMH9UQ5vVxspAYKHR/R0mjiIhIATaF4GaZHB++OEHd/XVVyfIwRhcdNFFrl+/xqgl66yzjmMTzT322MN9/fXXIS9MjzE4aHPuuuuucH+uueYKeTF1w39n2WWXdauttprr27eve//990O+jz76yE2fPt316dMn+PesueaabuzYsUkb7OTbb791d955Z2CsMKFbbLHF3LrrrmvJTY6ffPJJ4pvTtWvT1/XGG2+4Rx55xL3++uuud+/ebsEFF3SrrLKKm3vu/LC0TzzxRMjDA2CYBgwY4B544IHgW4OPzcILL+w22GCDUAd56PtTTz3FaSDwANOBAwe69ddf327rKASEgBCoSwQmLjPcXXzLG+6rb2bVZf/V6ZYhsMnq0t60DDmVEgLlIdB0xVxe+YrM/cwzzzgYA6O99torj7mx+0OHDnWnnHKK++abbwIzMmjQIEsKjIz5nBCMoFu3bu7dd98N6ZhuLbLIIu7ee+91p512WlImPrnqqqvcL3/5y8A02P133nnH/eY3v0nq4T51oUmC2cmi+++/PzGzgymL/XMuv/zywLjB0MV04YUXukMPPdStvfbaye3//Oc/7pZbbgnXH3/8sXvooYccTJnRpEmT3PXXX+/OOOMMBy60KTZNg7EDDxgoMTiGmo5CQAjUKwKEit5yrfncpbe9Wa8QqN9lIjDvsN5ulSWHlVlK2YWAEGgJAjXpg2PRyAyQFVdc0U6bHMePH++WX355FzM36UwffvhhHlPCIr9Hjx7u9NNPT7LOOeecLg4CMHv2bHfqqacm2iG0JCeddFJePWiUevbs6T744AOHiVw5dPfdd7sLLrjAGXPD8/mD0Egdf/zxicYmXe+NN94YmBv6AONmRDtizZfd11EICAEhIASaIrDFmvO5BbWfSVNgdKcJAt6q0R280yKuW9eaXHY16a9uCIHORqAmNTix9oZFPCZmMV155ZVu6tSp8a3kfOedd87U9mDS9bOf/SwEIsD8Cy0RJmrTpk1zo0ePdn/+85+DeRemYGhuIJgcIrWNGzcuhHo2fx/SMI3bddddg+bmxBNPdGhYSiW0PaZdogyhrg866KAQ6QyN0sMPPxyquvjii90JJ5yQWe1OO+3kdtttNzdr1qzgm/T222+HfNbGY489Nmh8wAoaOXJkqAsTPJEQEAJCQAg47885h1+0LuoOOe0xP5bmBIkQKIjAVmvP5xaeb0DBdCUIASHQtgjUJIPDor0Y3XrrrUFrkpVniy22yGRwYEbwUYmJ688//zwELcD/BS0Mf/jKWBvMv+ell15Kis4///zuxz/+cbju3r27+/nPfx4YICuTZCxwgqlcrPGhLszKIBgXY3DYP4c60747MCuY7aHx4fkbbbRRYNAob4wfZnkxYwhjAyMnEgJCQAgIgUYERs3dx+2y4QLBH6fxrs6EQCMC8w3v47Zff0zjDZ0JASHQ7gjUJINji33Qmzlzpvviiy+KmqCVgnLs+2L50aSwASYMxeOPP57HdFgeTNMgzNyM0OgQhccIRmL48OFB22P3ih3RCsXEHj5G9jy7hgFLBxyAwTJzNvLFpnXff/+9Fa3ZIxu+4vuEKeObb74ZfLDmnXdet8ACC7hNN93ULb300h3ad95Ze2+kisbPTDfjjWSzOspvBl+xUonIhGg+25rQQJpg4Ec/+pFbb7312voRzdZXDm5WWVYZ/PwIW290+OGHu46OimjP1rHtEdh0jVHujfemu/ufavT9bPunqMZqRGBAv27u8N3Hu+4yTavG16c2VzECNcngjBo1Ku+VPPvss26NNdZI7mFCZpoVFrs46zdH6cUIpmlHHXWUYyPMmEaMGBEiq9k9YyRY4BjFfi92Dw1QqQTDFhOR1AoRmp40g9OrV6+87FntyctQQxeED8ecEPPBmDDR4+/f//6322STTdwvfvGLOLndzjtqI9VCG8lmdQxsbHPZrPT0vfT3lE5v6TXmktYOovx1BpWDm7UvqwyCA+sL+YimKKodBNi08eCdFgsdEpNTO++1tT2BuTlhvwlu5LDqNu2+7bbb3H333VcyHAQ5Sq87Si5cICMRa9l03AifZltf2b32PmYJr5p7JhFuzz///JANixn8oyG2JcHKBpowYYLbYYcdwrn+tR0CNcngLLfccsEfxpgKQkQT1rlLly4BOT4mIz64UhicNBOAb4oxNwQLYI8dghWgjWGBbAyUaWow+TIiIllMSPCJbFYqDRuWH4WFH0wh35g0s8czDIdSn1cr+XhfZ511Vl53MN8jUIMFayARE0ai5KHpaE9Ci/S73/0uPAKtXrWSfePV2n61Wwi0BQIN/jhictoCy1qow5gbTBirnYgAGwtomuvPjBkzmstSdvpXX32V14a0tUrZFbagQJbwqrlqEIYbdgSVMsKiwu7HVjSWrmPrEahJBgemhcXptddeGxDCZwWTkKOPPjrPr4SNQP/yl7+UhGKawYn3iCFssoVOxhTNmBsqNr8aNDtGTz75ZNDy2L177rkn8X2xPMWO8803X14yP3wYOIi6L730UgdjM2bMmLDPTl7mMi5i6Yj1o4ziFZfVpCU0DCbxsMMOc0sssUTQ5jDQwCgao3P77be3O4NTLRupElzDNpvNeqkE4BAVRwAhCCHpjdIaYbuvY3UjYExO715d3aQHP6juzqj1LUZghA8HfcQei7taYG5aAoKEXi1BTWXaGoGaZHAAac899wzqP0IfQyz8t9tuO4f/CdHPUBvGjEjI5P/Fi3q7l3WMOXE2zGTzTzRGl112WV52mA+IPWz+9re/hTyYqxx88MFus802Cz5C11xzTV6Z5i5gXvAJok/Q2WefHfwr6BvMDUzW008/7VZaaSW35ZZbNlddwXQYRSPMt84999zQXtpejYT0xQiNCZo+ozXXXDPsDcQmrBC+OZhqpbVdbHiKySNR9AjIYEwk7z+m5jaK5RuImeRCG6mSD7M59iTC3JBAD4suumhBhqPcjWTjNhc6R/uYZqoL5WWDWPoCwfTjA4Yggd8bbYdRov1I3zB54DvlNwKjSVrsP5d+BiYKCANee+21kI8yselpnL8jcCsHawQE5gPF5M8mwxCSTkwVIKR4G264Yfi2+G3zm0MIwu8YP6cswsSWPa3Iy7iwwgorhKiNbEoMIZjZaqutsorqXjshAJOz7zbj3AqLD3FnX/Wy+2Ja9h5n7fR4VdvJCGy+5ki384YLOvZJqkXC9Oz3v/99wa4xvmVZjhQsUKcJW2+9dTKPS+DVPh9BzTI4MCCETD7mmGOSDStZsBbyV8HJfJ999gmS/VKgZkHMIhdiw8wjjzwys9jkyZPD/YEDB4bQ0Oecc064ZrGK6ZwR4axx7i6V9t1336CVwh8HRi3NJGEqd8QRR5RaXWa+sWPHJvfBjmdgCletDA6LdHtnMKWYhxEJj4UyzBx+NwcccEDYmyitsQMINj+192fAsOCGJk6cGHCx/ZRsY1TSsjaKZbGP2t/I8scbqfLt/Pa3v83cz4hFL+831p60ZCNZe35bHeMNYvldsLks347RFVdcEXzX7r33XscmtkaY65GGf1Qcvc/S0bBRd+y7wsa0MEVoZmMTzY7ArVysYWSw3zYitDvMS3yfd0nbLTS75eX6Jz/5SYiQaPc4/v3vf3eXXHJJonXkHua2TJxgA+HbJwYnQNHh/5ZdZLA7+1crugtues3d81jjpsod3hA9sEMQmHtwL3eQ3+dmsTEDO+R5nfUQxpRSBV4ImG2cZ7xDAMPYj5AQoQ9zLxuS48dJXoReCG1YjxHsh/yFCCEZ+wEyp7MGWmihhRzrMgI2pakjBF48EyEqQaeYH+gD83QhYjsTE3rFkW7ZagSBIMT8xrzAeoVARPQZf1TWLVl+26whEdKCIX02ISBCQasTXKvZJL4Qnln3a5bBobN86Phc4FOBkxxS+ZgwU+JHwY+IUMnxR5aW3MflON98882DRJ2NMc18i0XytttuG8JM22KGH7eFhN5mm23Cx0qbpk+fHqpEaou2icXgVVddFe7F6t1C7YD5wLyOCGoMFjFzhIT8wAMPzFv8FqqHB8ZpsQYLPxSiirFINQIjosfF2h1Lq/QjAynfAoMEfyyq+YMZtsF0rbXWytv81PqERDzN3FgaRwZmmBS0aTGGpMUR9LiGiYkx516aYAqIZIZk3gimi0ELYhBlI1lzWKQ/WRvJkt+0mFZPuUe+cSaSQoT5Z8xgWD7TIvCNY4cM0S9rM9d8R3xPEH5oOJEee+yx4Tr+hwYLoi6YHCuD9oJF/n777RfSOwK39sIajaAxN2iZTftLx4goh3bHGGgYPjTCRnxzCFHQnhlzY2k6dh4Cfbyp2kE7LurWX3ked+v977sHn/nEM6Sd1x49ue0RIAT0xquPcGssO9z17N7g59v2T6nOGlno21qIdQnjW2xJMWnSJIfWn7XRySefnGdVU0iwY0ggVCZ6rRGWDljQIPgzk33SOkLgxXMQWPN85gcj1nSmrbd7dmRtaHMkFj4WqZc9EW3NxZzIHMf60AjMGOPPOOOMPIsH+pleM4AtrhowW4888kiogrlSDI6hWeVHFlBIMPmDqWARCrePBCKWfqe7CQNh0vl0GtcwIXvvvXcIj8uHxcIfqbwtXLfffvusYm7dddcN5mqUYTE2vzcrM4bmpz/9aZMyaBT4yyLMeVAVUw/mOyyIYOqyJOBsBMpfFmHmU6ivRENhzxxCU6OaHjJkSFYVVXEPJoa+XHjhhXmDEAtmGAb+0CCwCSv7CRkxuJx55pl2GYJJoMVisY1WgQU2REhjorQxWKeJby3eKHaxxRYrupEqA5wxN3xbaCKR5jDYcY6vEFIdJDMw6fgX2SatPLs1G8mm2x5PSOk0rsEii8Fh0Y3fCaaA//znP/N8UMADhpFFORMbfYGQPBUifgdoJ3hfhFzmfUE33nij4/eGmr8jcGtPrPntnn766WF8ijGDUUVAY6aQf/3rXxOY2NcKQQe/fYQdTPDt4eSbPFAnZSOwyPwDHX9TNh/rJj30gffPed99Ob1BWFF2ZSrQ6Qj4oc2tuMRQt/FqI9z4BQYmc3inN6wDGoDmgTmoECEwzgrQYyH/EdSxTjJtPBoYs6xIW7IQfYx5D1PwNMHcxIId0lnbYZkBo8F80BECL57LvIx7gFHcLuubpZVzZG6DwIU53wScCC0RPMZrQwSctmagDOsTBN+sNfmrR6pNI9ECbxJHX/Y6QW1XjLkpUDzzNqpVVIbUa8xNZsboJgwNDBY/WmNuouSyT3ku9bFozmJuyq4wVQCsxo8fX9XMjXWJ/VpYHDJoxho7S0cbx6BqUifux74yXGPKhkQEKfvuu+8emFTuQ/d69XsW2UaxME7s6VJoI1VjIGPJFItaiwLIEUbNyEJ32uTBfZhm0xrC4LORbFZfrY7WHgt9wzDz5ucE3jHttttuwUQLxgitmZFFPrRrOyL9g7mB0LjBVNlzeWdmetoRuLUn1jDBZv6RNkOwTXjRXll/wQOm3cwy8NVhs2JRZSIwV/8ebsf1x7iLjlnVnXPkiu6QXRZ1m0wc6RYZM8D16dXFzyFzVGbD67RVfqp2PbrP6eYZ2ttNXGZut9cWY91JB05wV5w40f1qt8Xd4gsOSsaheoEIJoJ5p9Cfaduz8FhxxRXdP/7xj/CX9tMhTDKWNgh4bGynjlhwF9fJPIeGBG0GAh4zK4dxMl/otMAL64E77rgjWBHAhEAmKOQ8S3iFjyRtLuTvSTmEpkasDWB2aBeC0dhf2/KUc2TNQBvQ9tBnoxgX+hDPS5g002bKxfOrla2XY02bqNXLS1Q/y0MA7dyJJ54YAj7gzM0f2oDYlAy17i677BKYmJjBoWw6vj9Mh0lOzKY23SJTP6fvF7qON3PF9hZtoVGsrsaXC4rbjvo5niBgelkAx3VaXaUcWUAXsiWGuUYLk0W2UCctvVdOLJGLtT8WxS5dX1qlzjugXwQxgNBgQnEf2wu39sQaQUlMSOGM6TPpXfz+yZvGBmGEqLIRmNPvmzPCL5r5W2OZfJ+B2T80mNBWdg/qo3XsbxSPpfXR69b1shheCKZsLkBwZ5oFTG+Z45hPEOChlbY0G//SrcIP2YLSIEhDoEb0U8gW/1kCL9JNUGiBmmDWsISImQSYibSgEAbIXBKoB0oLnOgHTA6EwAltVkvNhsGB+RdmDGElrhRYmUAm8OI8tnyg3TvuuCO3Q5lDDjkkBPqJ3RhCYh38E4NTBy9ZXXSOYAyPPfZYWBATnplBCCc9Bjr+UPVibkakOIiF9nPPPRc0PbG5j0nKY0zjTSjJa/4hcZ5yo6TEm7kiMYsl9nG9xuDEk4BJsuJ8WQ6JcXqxcxgVGLtyKZZcmbTM6rBJjutiE6Llz9KO0idjcGzw7gjc2hPrGBf6nvUu+R5iSuPXntq6+Lk6bx8EWFT7X0X7VK5ahUArEYCpQEBYiIzpSKczlsXzZzzWMcfEY3wpQi98hGNCy28MTkcKvNICJ9oRU/o6TmvuHGYlnjsReBmZwIvr2M+W9Ug8J2C5hLbMggxY+Xo4isGph7esPjrshrFRNUJKFJtNMYgQ1tgYHPLZIImE3HxECGuMXW88GMeDC6ZnSFrSlLVQTeeJrwmAYY75RNwy86w4D+c2EfBcI/zMYsLpsZyNZOOyrTmPB9l0PfGgnU7Luk5PIjCgxtyR3/rfEbjZs3huW2Mdf1fUn0VpDSL7fMULh3qcyLJw0j0hIATaHgFMs1sr8KJV8RwQMzukFZs7SIfSc2osxOssgRftSs//cbtIL4fSuKT7bHWlhV523471KvQSg2NfgI41jQBSDaQfxjQQyQ5/F9TSEHa7RKqKyXxd8G0yIpAD0UhWWWWVcIvAFWh+jNLmQnY/a2CKB/i02huJli1U0d5MmDDBqgpOlAzgSHcsjKZtGksm1O4wZ3aPABKxOjupqIpOwJyIPATygO71vk6xZs362hG42bNoR2dgjTkHf6atIlw0foVMhpjo2QbHtE8kBISAEKgEBIoxLfFcWGpbmeNiRisWNpkQqqMFXrQdYWrsC50WzpXaP/KVIvAiXyz0MtM+7kOsFdL3GlJq/78YnNp/x+qhR4DBlZDX7BMC4UfBvkcMDEi/iRQWq3xhfmzwRMXMtWkMCGOMLSySLMJM232YGKKXlUqxpAcfnngjVRzFCXsJMUAS9htbXmyEeSaEPTBOm1BbbiQbKoz+4ShJSPJCBA7F0guVK+c+DCC2xIRnR4NGBBkj3o+9q47ArT2xtj4VO/Ito9G74IILQrYXXnjBEcSC7xim2KITFatDaUJACAiBakYAQY7tP8icQNRJIxNCdYTAiyBMWFKYFgXHfjOfY95ia4r2Jpv/eA5rBCxOML3HeoN5wtrW3u2otPrF4FTaG1F72g0BmA9CNuJ8boTpVtp8C01PvEkqknEW+YTMJi+MEBFKYkIChR9POjJMnCd9Hg9KDNDxRqpI5OM9iGhz3G7qoj/mUN7WG8nGbWVvlWIUM2rF8rUmjTCZaCzSWjZU77YHDvV3BG7tiXWpGMHg8C3jVwbBZBujDaPTGqlhqW1QPiEgBOoPAbQBRCMtRkTJXG+99YplaXUaG1qycMfSgj1lLNAPFW+22Wah/o4QePEgBG9sVA0RpQ3rAuZm9rRJ778YMrXxPwIsEP3V9k5jPxysSWgHlg/1SnUVJrpeX7L63YAA6t4//vGPbv/99082TIyxweyHaGFoI2y/EUsnKgqbULJZqIVyJg1pOuZvbPBpgyr3S1Et20aq5DdiwW5BCmCoiDoTq5/JB8NFSM14rx7us//OUUcdFTaa5RqCWaOOLbfcsuGG/1/MVIBMLTEXsMoLleWZ8XNLwSfO83//93+B4YPRMSLCDKaGiy++uN0Kx47ArVys477EjS103/LE6TG2BHDA0ZdIf3x/aA/5nggzjabLqCOYT3uWjkJACNQ+Amgl8Dst9mfBX9oTDcY2rBjYT439v4yYw8102wReloaQkL3Z0LIYZQkKLQ2hERt4YvmBYDOefywPR+ZizOGMMKGmXTwvDgxg6W19ZE3A3G/jPZobIqvB3PB80uuRpMGpx7dex31mIcjilD/8cTBVg6HAt6O5gYgB7Ne//nVADwk5fi2Ui6OFGbRoZwptnmp5ODa3kSqSIf7w9cGZnIgoSOhtIIvr4rzcjWTT5bmmP6W0PatsHKQhTmehbiZ38X3OmYyynnfCCSfkZUXljqkePkkwmTGjmZfRX3QEbuVgjRlfVh8xb8i6b/3529/+Zqd5R/Z3gBnGN2uTTTbJY4LZ6drIglDYtY5CQAgIgXIRiAUt5ZSNhTLpcnGd8Xk6n13HeRDmYDHBJtG2NQBzO0JGhDwxMccuuOCC7sorr8yz1mDRzzyRJShkXEZ4xrwLsTbYc889g2acvXegWGDHOItglEBGaNVhMEgnTPRhhx0WBFHpMnF/QoX/+1foPslxWhpbgiaddtppwRKECLA8f6mllgrtpl0WArvQ2iFuQ62cz+FfRK5WOqN+CAEhIATqAQEmd3xvIBidU089NfghIbFjkjOziIkTJ7rjjjuuHiBRH4WAEKhDBAgugBk1e4jB5BSjUgWF1MHSGHM8zMfn9wF9Yoam2DMwm2Mcxv8HwVZHEOZ57PmDtQd/CF5jbRP74pjZ8tFHHx18djuiXZ39DGlwOvsN6PlCQAgIgTIRIIqfMTiYjGCGmEWYMoqEgBAQArWKAPvuFNp7J91nLCDMbzWdlr6GoYFJKZfQ5sSRV8st35L8mNJhEmdEIBw2QsWsDnM5Y25IR5tVLyQGp17etPopBIRAzSAA48KkReSgOPqfdRAzw9133921ZpM5q0tHISAEhIAQqFwEYKgwq7PtIIi0atFW41YTdXXMmDHxrZo+l4laTb9edU4ICIFaRoAJ7cEHHwwmGphGsP8Ce0AQeIEJTyQEhIAQEAK1jwB+N/gkxRuPx73Gb+mYY47J2xQ6Tq/FczE4tfhW1SchIASEgBAQAkJACAiBukHghx9+CJtPw+QQyQ4zO4ISYWrX0WZzlQC6GJxKeAtqgxAQAkJACAgBISAEhIAQEAJtgoD2wWkTGFWJEBACQkAICAEhIASEgBAQApWAgBicSngLaoMQEAJCQAgIASEgBISAEBACbYKAoqi1CYyqRAh0DAKvvvpq2LWZXYr5Yw8ANiDFsXzVVVd1G264YcFNQDumhc69/vrr7vzzzw+PY1Ox448/PpyzezQ7T0NsUNlZIYyJPoZtMvsFiISAEBACQkAICIHaQ0AMTu29U/WoBhH47rvv3LnnnutuuummJr1jJ2f+2EH5sssuc3/4wx/c/H5jss6iadOmuUcffTQ8nnDFRm+99VZyn52hO5q+/fZbd/nll7urr77a/fa3vxWD09EvQM8TAkKgphC47bbb3H333dekT126dAmbbjLOswHn+uuv73r37t0kX73fYDPR559/3i2xxBL1DkW79F8MTrvAqkqFQNsiwG70hANujtjw67DDDnN/+ctfQsjg5vLXU/pPfvKTwAjWU5/VVyEgBIRAeyHwzjvvJEKrYs+49NJLg+CtnjaZLIYHaWzU/Kc//SlYE5x33nnNZVd6CxAQg9MC0FRECHQkAjfccEMeczNkyBC3//77uyWXXNIhKUNzc91117lXXnklNAsmB3MwNnqsJNp6663dyiuvHJo0ePDgDm/aF1980eHP1AOFgBAQAvWOAGPvr3/9awejw5xV78QmnL/73e8CDOPGjat3ONqt/2Jw2g1aVSwEWo8Ace0xqTKCMbjoootcv3797JZbZ5113FJLLeX22GMPx2aPEEyPMThTpkxxd911V7jPRpDkxdQN/51ll13Wrbbaaq5v375u1qxZwdwAlTkx9CE2i2QAXnfddTN9e1588UX38MMPOyR58847r1tppZVCuax/n3zyicNMDeratenQ88Ybb7hHHnkk+PBgzoC0b5VVVmliSvbEE0+EPNQDw0QbH3jggaDqR+W/8MILuw022CAxiWBPgPvvv99h5mfENW2m7yNGjAi3n3766YDbxx9/7DBnw7wCXyF8m2ReYcjpKASEgBBoigDj/0knneQYg7///vswRl988cWO8RT68MMP3UMPPRTG3Kal6+vOl19+WV8d7qTeNl1ldFJD9FghIASaIvDMM884GAOjvfbaK4+5sftDhw51p5xyivvmm2/c2LFj3aBBgywpMDKmAicYQbdu3dy7774b0pEkscMxjNQhhxzi3nzzzaScndxyyy3u9ttvdyeeeGJgJuw+jBY+P0xoRldddVVgoOw6PsJUmA8RTNkyyyyTJOMbQ320I6YLL7zQHXrooW7ttddObv/nP/9xtAli8mTSJHCA0aRJk9z111/vzjjjDAcuMDLWf8tDfyCYGzZCwycny5b8jjvuCFjStoEDB1pxHYWAEBACQiBCoEePHmFDSbvFPMQGk1gbGJlQya7ff//9IHxj/J4+fbrr06dPCJqz5pprhnnM8pUqpCu1PhN6UT9zwAorrODuvffeEMAHQR8+Mcw5vXr1cuRlbiCoD0zc0ksvHfJb2+JjKUI6hI1PPfVUUoy+IcRkfsFXyaiUusjLvEobIQR2tBNzdgs8tOiii4a0evwnBqce37r6XDUImMbDGrziiivaaZPj+PHjm9xL30CKFhNaEgISwBzFzA3ai6+++iphONDUMAjvs88+oThMBeYGRnPOOWcYoBmsYcrKobvvvttdcMEFSRHqgmB20EgRhY2JkgkzTTfeeGO4xeRKfiSHEAM+7T3ggAPCdbF/saMs0dV4FvURDY46Ma849dRT3QknnFCsGqUJASEgBIRAhABjaUwwD0a33nqrO+200+wy74ig7Je//GXQxJOAtYEJqQoJ6WBQSq0vFnrBAFx55ZWOOc4IIRmMyDbbbONOPvnkxDKCdPLiz7nTTjtZ9nAsVUiHOTnRUI2sb8zFxuCUWhd1IKzDigLCCsHOuSb40LHHHstpXZIYnLp87ep0tSAQa29YdGNiFhOD7dSpU+NbyfnOO++cqe3BpOtnP/uZgxkhVPLs2bMDcwNjwYKeiWXjjTcOZlrYTT/++OOhzpjZQrNihFSLyG0cn332WferX/0qlLX0YkfMxmziIh/mYAcddFBwvGSyssEaU4dCDAYTzW677RZM7JAWvv322+GR5pOExI3y++67r5sxY0ZIg/FZbrnlQpstjDUJdb+DsgAAL1JJREFUO+64Y5i8OKf8gQceGCR8SPLAK40/+URCQAgIASGQjwDzCprvmLAWgBC0nX766UkScw9m0kTghCiLUGn11VcPWp0koz/JEtIxN7a0vpdeeilUj2UD/kGYJ0MI6kxYR/0zZ84M9/nHNgiYR48ZMybca42QLqn0fyetqcvmS6sTS4l6JjE49fz21feKRyCWeGU1FimYqafT6VtssUUmg7PrrrsmkjErQ9Q1mA1MBZC6oQlBRR77yph/D/lIM9p7770Do8A1gQ9gjjARK4UwlSMogtGPf/zjYFbGNYyLDdjsnwMWcXvIM3LkSIfZHhMke+5stNFG7s9//jNJCeMHczJ69OiQJyT4f5glcA+KzfmuuOKKwKTB/GBCh3Qs/cxQSP+EgBAQAkIgQYC544gjjghCMpgEtAdxYBcYCDOXgnEwhoZxmDEbP0f8KxGwQTA51JHlhJ8W0rW2PiwjjjnmmMDgMJ9Nnjw56Rf7tXHvueeeC+bSZpKNAAwGp1whHRoVTKwRTkLMYQjvMM8rt66kkdEJTA3MF2ZwxSw+oiI1eyoGp2ZfrTpWCwjgQ2KEBIkJI16QW1o5x9j3JS5n9suouTHPMnMvy2MDe+zvQppNWpYvfW33s45MYDGhCTKy59k1gQ/Sm3NiXmcmbeSL99dJt9/qSR/X9PbeMIporyCCLPCH1of6SEdDJO1NGjldCwEhIAQaEEA7TpCYQnTkkUcm4zNBYPhjTEdrAnODoIs/BEom2DOhWrrOLCFda+o7+OCDg78NzyHwjjE4zLUwN7QRSwCYEUvD3xUqV0iHiV08l8DYmLCNebc1Aj+CELFNBMK+2G81NLQO/4nBqcOXri5XDwKjRo3KaywmYGussUZyD2mXTQI4F2K72xxlhWi+88473e9///sgNbPyqOWJ1mYDrjESNrBbPgbTmMqJOBZL+Kgj1gzFdXJOO9IMDtqZmJASlktESjv66KPdOeecE8zQ4vKYTBByGydTzPLiiSnOp3MhIASEgBBoisDiiy/udtlllybaBLQVCJLQ0mMGbfNMXENayGVpWUK6ltbHnEGgGaN4TsGaIQ5rDTNiZAKx1grprD6Ora0LrNPzcVx/vZ2Lwam3N67+VhUCmErBMBhTgU0zkVJs0GVxbsTAVgqDk2YCqJsgAzZgr7XWWsG5EtMAnPhZ+EM44ENIoGLCTyhe+Kc1PHHe9PmwYcPybuEPE08icWKa2SPNcIjzteQcaReMIwzko48+GmyvMUEwTAjrieMpPjoiISAEhIAQyEcA7Yb5MzIuIyBDA5KebyiF4Oioo44Km13GtWA6jCWBkQnV7NqOaSFda+rr2bOnVRuO8TNjZodEmwPjAq0V0rVlXWlc4rrr8VwMTj2+dfW5ahCAacGn5dprrw1tRh1++OGHB41DzFQQFhI/mlIoPeGwqLeFPOUJy4x9NITK3MjMBrB/hgkxzREaDnMeJQ/mXqVSOsoOkdtg4KAnn3wyRGqDscHWebHFFiu12sx88cRlfUHqB9OI2QF/e+65p/vpT38ayhNUgNDZFlLb9nPIrFw3hYAQEAJ1jADzCibDpRD+Jy+88ELIipUAwWGWX375ICjbZJNNkrkli6GgUHoOa019hZ7Bc+I5g+ssaq2QLq6ztXWlcYnrrsdzMTj1+NbV56pCgEU3TvYWTICF/3bbbRcmExgRmBBjNuKOlTI4kz8twbrkkkuCNoNnorUwgvkw2nzzzR0O+RB7xWB/TZhq9qiJw01b/kJHmBfMDegTdPbZZ4fNQJkoCUNNxBx8gthAdMsttyxUTUn3Y9U9YUgJdY1DJs9+7bXXQh08H23NAgssEKKoxUwNG4iKhIAQEAJCoHUIxPvAEBrZwiMz3sdzmQmi0k9LL+RbW1+6/nKuWyKki+fmuI8tqStuaxqXOK0ez8Xg1ONbV5+rCgEYEEImE+XF4ucTYaaQvwrhmtmvJi0NKtRptC/4tthinjj9/KWJdDQeMApEOGOTUAtjfa/fg4A/CMd8C/cZbjTzj/DNaKVQ9TO5XXPNNXkl0FQRnae1xD46OLVCSA/5QzNEKGieT+Qf0s8888wmj2KPAjltNoFFN4SAEBACZSMQC9UeeOCB4NiPqTQbR8cUC9Xi++nztq4vXX+x65YI6WJh29t+W4Nzzz03hKEm2EFHCfyK9alW0hp21KuV3qgfQqBGEcAJ8qyzzgqLcbQLaYKZYQ8ZTKpMA2N5mvNTYXIgTCWL+Ji4JnwnJmkQDIDtiYOJGiZx7ABtKn6OSy21VBKmmTKWxnmhdsB4UBcmCthtx0RENtpmbShWTzotlpKRtscee7ghQ4ZwGoh0Iq2xa/UZZ5wRnm9pdkQittVWWwUGM55ELV1HISAEhIAQKA8BIlMa4bNJhDX8d+K91ki3iGWWt9Cxresr9JxC9xHSWXRTE9IRtMf27EkL6eJNqxFWItRDYAiVW1ehNum+c9Lg6CsQAlWCAFIfFtv8TZ8+PezuzGCKWjtmANLdYTC955570rfzrsnD5mVoaYhmg1TK6rzpppvy8trFwIEDQ3AC2sDO0LTDfHeynsfmmvxlEeGwLYobTqZI7mDqYj8jK8dGoPxlEYECsp5NXoImYJrGpAljQ2hOk6SRxvORIoIBz6dN/BVizLKer3tCQAgIgXpBIB4b4/Pm+o+JM/PM1VdfnYSEZizedtttQ+RO2/z5/vvvd+yN1lzd5daXFn7F7Y2fFZ/HedLnJqRjmwN8WuNNQRHSYSVg8yllsZrYdNNNw344VhfhsbGQKLeuuI3F+mXPqafjHD4MX66eOqy+CgEhIASEgBAQAkJACHQuAvhuInBicY/AKV6st6RlbV1fS9qARqY5IZ3VO3Xq1BAaGhPx2LrA0supy8ro2IiAGJxGLHQmBISAEBACQkAICAEhIASEQJUjIB+cKn+Bar4QEAJCQAgIASEgBISAEBACjQiIwWnEQmdCQAgIASEgBISAEBACQkAIVDkCYnCq/AWq+UJACAgBISAEhIAQEAJCQAg0IiAGpxELnQkBISAEhIAQEAJCQAgIASFQ5QiIwanyF6jmCwEhIASEgBAQAkJACAgBIdCIgBicRix0JgSEgBAQAkJACAgBISAEhECVIyAGp8pfoJovBISAEBACQkAICAEhIASEQCMCYnAasdCZEBACQkAICAEhIASEgBAQAlWOgBicKn+Bar4QEAJCQAgIASEgBISAEBACjQiIwWnEQmdCQAgIASEgBISAEBACQkAIVDkCYnCq/AWq+UJACAgBISAEhIAQEAJCQAg0IiAGpxELnQkBISAEhIAQEAJCQAgIASFQ5QiIwanyF6jmCwEhIASEgBAQAkJACAgBIdCIgBicRix0JgSEgBAQAkJACAgBISAEhECVIyAGp8pfoJovBISAEBACQkAICAEhIASEQCMCYnAasdCZEBACQkAICAEhIASEgBAQAlWOgBicKn+Bar4QEAJCQAgIASEgBISAEBACjQiIwWnEQmdCQAgIASEgBISAEBACQkAIVDkCYnCq/AWq+UJACAgBISAEhIAQEAJCQAg0IiAGpxELnQkBISAEhIAQEAJCQAgIASFQ5QiIwanyF6jmCwEhIASEgBAQAkJACAgBIdCIgBicRix0JgSEgBAQAkJACAgBISAEhECVIyAGp8pfoJovBISAEBACQkAICAEhIASEQCMCYnAasdCZEBACQkAICAEhIASEgBAQAlWOgBicKn+Bar4QEAJCQAgIASEgBISAEBACjQiIwWnEQmdCQAgIASEgBISAEBACQkAIVDkCYnCq/AWq+UJACAgBISAEhIAQEAJCQAg0IiAGpxELnQkBISAEhIAQEAJCQAgIASFQ5QiIwanyF6jmCwEhIASEgBAQAkJACAgBIdCIgBicRix0JgSEgBAQAkJACAgBISAEhECVI9DlWE9V3gc1vx0R+O6779zaa6/tBg4c6BZddFH37bffurffftvdfffd7t///rdbccUVCz79888/d2uttZZbfPHF3ahRowrmU0L1I5DL5dyUKVPcU0895W666SbXo0cPN3z48A7p2IwZM9xbb73l7rrrLvff//7XLbfccs0+94cffnCfffaZe+KJJ9yNN97oBgwY4IYOHdpsuc7O0Jk4Z/Wd8WHy5MnuP//5j7vlllvcSiut5Oacs3blZi351rJw68h71djmjsRHzxICQqA2EZjDT5i52uyaetUWCOy+++7uiiuucHfccYfbaqut3LRp05Jq55prLgcTU4imT58eGKD33nvPTZo0ya288sqFsib3P/zwQ/f444+7rl27ui5duoS/JDF1Mnv2bNezZ083ceLEVEr7XH700Ufu0ksvdf3793c//elP2+chVVgrMpLf/e53btasWUnr//SnP7kDDzwwuW6Pk48//tgttNBCju/MaMyYMe7NN9+0y8zjoYce6mgf34/RJZdc4nbddVe7dJX4rjsL5wSU1Mno0aPdu+++m3eXxTS/yVqjln5rnYlDNba5M/Gq1md3xlj1z3/+0z3wwANul112cYssski1Qqd21zoCMDgiIZCFwEknnQTzm/v1r38dkp955pncBhtsEO5xf955580qlnfPS8hznlnJDRs2LPf+++/npWVdeEYot9hiiyXP4Dn25xmeUJddc/RMU1Y17XJvww03TNpy++23t8szqrFSrwnJXXfddbk55pgjweevf/1ru3fFMyi5+++/P+e1Bslz/WTb7HO9xiF3zjnnJGX4jq666qq8cpX4rjsL5zxgoouXX3455xc4eTh6zViUo3ZOW/qtdSYC1djmzsSrWp/d0WPVI488kvzmV1hhhWqFTe2uAwRq15bAr1pELUfghhtucEcddZQbMWKEO+KII0JFSy65pPODaVIpWpbmaJlllnF77bWX++STT4K0p7n86623nnvhhRfccccdl5f14IMPdpjDfP/99+7LL7905513XjCF+fTTT/PytedFnz59kurRSokaEBg8eLDbeuutgxmjYVLKt2F5W3rEFGq11VZzG220UVJFt27dkvNCJyNHjnT77bdfnilVulwlvuvOwrkQjuPGjXNbbLFFkozG1TO5yXUtnbT0W+tMDKqxzZ2JV6U+++mnnw7acMYtL1hr0syOHqt69eqV/M4/+OADh7mvSAhUIgLNr1ArsdVqU7siAAOx5557Os/gOxiL3r17J89LLwSThCInv/zlL90FF1zg7rnnHnfnnXc6mJjmKO1HsfHGGycLUvwlMBHD7h9VeUfRySef7JhMll122Txzpo56fqU/pyXfRlv0qaXPpdzMmTMzm1DJ77ql/c3saCtvxoxsrTI3MUSVhH3crmLn1djmYv2ptzTmPhgJKOtddvRYtcQSS7gzzzzTPf/8827fffdN5uV6ey/qb+UjIAan8t9Rh7fwrLPOclOnTg1Smu22267Vzx87dqxbY401QlCC3/72tyUxODipx5S1eELLM88888TZ2vV8wQUXdBdffHG7PiOu/LXXXnPXX3+9e/bZZ93222/vNt988zhZ5+2IQEe+a3yXCMwA8w8Dfcwxx+Rpw9qxm6paCAiBCkcAv1SjWFtj9zpyrLJntrd/pT1HRyHQGgTE4LQGvRosiwnYGWecEXpGRKT55puvaC8xG7v55puDwyHmbOuuu65beumlm5RBa0PUNaJcockhulprCQfz0047LUTvghFAuoWZDM7jCyywQAg+8OKLL7oHH3wwCVpA/zBrWnjhhfMe/9hjj7n77rvPvfPOOyGa1iqrrBLaaBGhvv766xA97vXXX3dPPvmkw/QuZjjQemFKgOMlztc//vGPgwbM+4i4W2+91RGQAWaRdqUJTdm//vWv0E5M+ZjEUPvDaNInnv2Pf/zDffXVV4lpQLoOu6Yc0cS8nXQoN378+NCPdBS7rPaizaAdRMjjXe7uA0xgFgXhsHzttdc6+g/upGVNttYOjjBoV155ZYi8hznTDjvsEKKrxXk4L7XNVg7mm3f16KOPhgAD3hfEkooevQ+Ze+ihhxzfBO+DbyGL2vNd837B8Y033ghBGYg05/2X3KuvvhreF+3h3q9+9auspmXeKxVnosaBGxggMEBLyjecFibYQ7755pvwLRFpjt85URSRJg8ZMsSyFDzedtttIVADGh5+Q/wmwXuPPfYI/SUYgZm0weDxx2+O7xXCBLRv374Jo4em1vvwhd+xPXS33Xaz0xARr5S+ESSF74C83ocwtAeT2MsvvzxEi1xnnXWSOjlp6beWV4m/oP88F60zQTD4fWHel3bQJh/fBr9fIhIeeeSRYTziu+E7oSzvDYFHltCnLdvc3JjIO+Pbs98UjDnfCVjSB+aBzTbbLBlDYkxKxYMy5bwzAo4wHyEUYlxlvAXnrIiOjPWMd2gieB9LLbWU4/0XwjVuv52/8sorIRIjz+vevXuog3mT+tJEQB7eKXMgkUUx6+U7RLhBlFLmxNVXXz0pxu+VsZx+GPG7ImIktO2224bfFFFNy5mXWjPOM1bDcNGGl156KfwRYAazNQizdsbWfv36hWv7Rzn7nR9wwAF5mqhS3gPleSbfGvPv4YcfHjBjfiHIwj777JP5ndnzdaxTBPyPRyQEEgT8gJs4EPpBJLlvJ3/+85+TdP+TaRIQgEAAxx9/vGVPjgQbID9/XvqT3C904ieeJD9luDbyi/OcX2TncHaE/KSf8xNZXn6vMQppfrLL+QE3L+3oo48Oafzzg27OL7pCup9kcj4KV5LXR3ML+Xz42+Se9cEPqEkd3jcpL90v0nKeqcp5VX7efb9gyz333HNJOU78Qi/nJ7aQb9CgQTm/iEzK4DzqB/+cZxpzP/vZz/LKZV34yTYEXaCN4OMXrqEuP9nk/CSaFEm312vYcmeffXbOa8OSZ1MHQSQ80xae7SfvvDRvppfzk05SJycEkjB8PAOZ41uwa44Ej/ATcV6ZUttshXgXc889d6jXL6ByfrGX9wwwT9MXX3yR23nnnUM+b96Y+9GPfpQD67htnkEOxdrzXXsmNXkn4Gfvh3bwrZ1++um55ZdfPvmu0/2w63Jx5vfiF0MhCIRfWOX4s77TDr8otKqTo19I5PguyEd+z2iHc35L9957b5KP78rq8sxMct9Hqsv5aINJGt+PX7zlPNOU84xuk2AhXpCS47cK8RuhTt6vEb9ZH50tqW/ChAkhqZy++QVsUp76+R346JB5bWGcMmrJt2Zl4yPv3Ycgz3lT35xfQOf8YjC0A7x89L4kq49WmddH2ki694FM8DesPXOXlItP2qLNpYyJzAPpMYH5wjO/eRhz7QUmcRNzpeJBoXLeGXOX91MJz4+/2U022STv+Z65yp166qkBa74p+87B1vvzZf4e8irwF3zH+++/f/Ie+d3ae/WCn5yNJ1bOC5jycPECstyOO+6Yd4/neyFYmJMot9NOOzVJt/fvmbAc34td27HYvNQW4zzjhT3Ljt58zrqZYACu6bGG/NyzeaPU90A/DVt7JkFh/PYVSVs23XTTpA06EQKGANIBkRBIEPBSuGTQ8KF0k/t2EjM4LGB9AIHcX/7yl2RhzQDE4MsCKSYvhUvqjRcucZ74PM3geClRzkuvQrQuJgGew4QW06qrrpo8A6bByEvk8xZb//d//2dJYWFvg6Y3P8sx6HoH9FCPTVIwISy+YBQsr/dNSurw0uVc/GzyMPkTYYpJMB6c0wuTeBLzkqnwfJgze07MmCQPzDjxe9DkvNQwlKO8l6TmWKzxLqjLa2JyXgMUSma1lwnYS99yXvOUPNvaQN9+85vfBMbA7nFML1zSC28W7JSzxTFliMJnVE6bKeOldUnbWPQZeX+x5H6awfHSyrCQ5dkwRl7aGYp5CXMeA9be75oIhPYdeKl2aAP4GZ6l/Casv+XiDHNgz/FS15zXpOQxOd5s1KoORzBikUYZr7EJ98DH6vB7XyX5CzE4ZPCS81CG/D6cdFKGE8YMq4+jD7+epHvtVZJGpDajn/zkJ+H+iSeemCySyukbeMNk2XNZhMW/ae7zXUAt+dasnfERBsyw9FqXkMTizNqAUIWxEfKS6Nzvf//75DdreRAW8NuMmXl+1wh2YmqrNiPssGcXGhN5n/FcQX4EON5sODBl8TfKuGR9LAcP+lbqO+Ob9lqa0O75558/wOK1S6FN6TEBjK1/3iw0fEv2rXKf6KHNEb9hq+Oiiy4K2RHWmOCE9xPXw+8EptzKcGSO8tqunNeG593/4x//GOpj3oJ5iMt4K4ic1wQFPFsyL7V2nPea5iZzBO8Uol20FWbPa/zDPSKwxu33Gsxwn3+lvgevvcyBic1l1IfAIK6XeUskBNIIiMFJI1Ln1/HAbYu+GJKYwUHqauRNOcJkYoOOTeaWztEksN5kJcfCsxilGRyrNz56VX9eFT7wQDLoISmNKdam+P1EkiS/90lSBimQ38g0SPBYlKX7H4cjZhEWE5OctY1+xpoa0x6QzuBvBBMSS/GZsKB4gUefSqF4krQJl3Im0eTZMIhGcXtZ5MXvI56I/d5HViTHO47be+655yZpnMSLmrgN6UmORTZUTpu9WUSiiYN5RCtjZOHM6WN6MeNNfJL3cthhh1mRcIz70t7vmoWffR+mGYXh5Ldg92NJaF5DUxfl4oz2j2fwXYIjxILZnouGMKZ4DLj66qtDEr8L027G33AhBgchAvXzm7HFbfwMvjfTxJHPvjMEDCzCrG0xIwsT6P0NAoNmdZXbt/i75xkwVg8//HAOybd9sy391qxN8ZG6bGF20EEHhSSwtHu0IT2OMa5a/9EuM05ALC7tPsf499yWbS5nTLQxnfZceOGFoZ38Q0sTtxVhB9QSPEp5ZzB79jw0Y7aQZoxac801w7P5B8Nsv/t4/vJBcJLy8fedFIxO0GDasxBa2PshC3OLpSEA9GZVSUkfDCBJi5+NRgONjpWD6TUtB0yO3eeIRj1Npc5LbTXOIyCL22TzljfTC/dJh7zpX55wi/HeqCXvIf5dMBb4CKq5U045JQgRsXQQCYE0AgoT7X+pokYE/MIxuSAsZanE5pd+Ikmy44+SJr8wC7f84O3i56TzZV1704vgb4Edvl8ohCzY9MbkJ9vk0i8gknNO/KI479ou8Ckw4hl+cnP4zfhFT9jY1NI44k9gVKx+P4EGG2vL65klOw2+AnZBHXGd2NlDsY9DKWGw/Y86BCOwer10PNjoY6ePD4GRReLhOsYDH4n4Om6vX4ha8bDBaey7VOo7jH2VqIxvo9w2+4V28LWiPE612Kw3RzyDcOJG+C6USvF7aYt3jS+Vkb1TfJj8Aslu530byc0yTrJwpjh+anzb+CrhiwAuMfl9gZJL/GT8AiW5BmuIbxp/Afwr8APIIs+cBL8oQnCfcMIJzjMqIa9fWDXJzvcWb6xK+Fv8J3hG3B6vQQi2+/iv8N1Qd/xuyukbjYi/c869mVDYjJjfDP5BUEu+tVAw4x9445+BL8Uf/vCHkAMfr/i9x/0lQ9xGQvPbt4PvG/4NRvhoGLVlm8sZE/mGjeL3Qh3MCUb4TUCtxaPQO2ODX3zEIOYFfGl+8YtfuG222Sb4fIYE/w9/SBvTvAY5GSeJ8mkUj5N2Lz56pj655J3Y++HmlltumaTxe8AfyCjGyjM/djv4/PAdGnmNSOJnk57j0r9dysS4Fxur2mqcj5/H8+2Z3vws+Grib8sc7zWuiZ8jc783CyR7oJa8h/h3wabjzJP44niNY7O+wvZcHesLgcYVW331W70tgEA8gDIglkPxwpxBOk0Mekbl1s2CAKdj/ryULDietkUENSYkv1lZWJjRNq95CfuqMDj7zSDzJi9re7lHmwDS5ZgomAxuvPHGkOT9MMJAHe8Ov/7666eLNbnG0ZfFoRGO2vYuCOMJ8axS6iJvofY2l0Z6FllbLI1vo9w24/BsFC+c7F7WEUfnmAkrtVxWXaXeK4SdN81zXqsRJn4We/zOWGDhyA/hlMwCoTWUhTP1Eebd+yEEZ2gCiBDkAEGBUfybx2naS6QtKe/7R+DhTSqTtPQJ9cTMMYwcwSniRXlchlD0tuj3Wo2wGCQQCc7/OA4zXnCEOSN4BwIMLwWOqyirb3kF/QVjSrzQtPSWfGtWNuvIe/XSZ3fZZZc570/g7r333rAIt7wx/nav0LHQ99WWbW6LMRFcYXAJ4ADFTENr8Cj0zniG9/0MgUxgCmDUvVlTwBuGxL5LAmYY8Zvz5mzhkuPEiRPDuQW6sHzpIwFBjGJGlXsmELB0b+5pp0WP1g7LBF4ESEgzOPEcanlbeiz0LVFfsbRCz6OMCTG9pUcICGB5GXcsYA33WvsesoQm9iwdhYAhIAbHkNAxIBAvRkyjUCo03vwgyepVyMk5J7ZYsZvsZdNSQnrvzRZaWjyvHNI3FhxIhpEWG51//vkhBHV6w1FLb6sjGgYYG6S43l8nRFn629/+FqpnocEmqc0Ri8iYiOAWa9PitM44j78Lns+3UW6b4zpipqVYf+Iy5Cu1XLE6W5rmzf4c+1UgcUQbgbaFRT2LW34LLH5bsqiI25Pur/0GWSx5U67AKLDQ9n4rgSG2SG2xRDbW+FE3EY7QIpRKMCI+wEAQGNA/73OWRDFM10EEMe/fFaJKkfb3v/89RA/ztvmOjYYnTZoUirBYItIV0vh4fCKxnL6Fykr4F+PYFt+MN4ML+4nB0Hpz1aAhJoKWLfpj/EtoXmaWtmxzW42JRA0zIoqiUXvhAaZoH/nmjIGHQWYjYJgSFtjxuIM2yZs4WbNKPsZMjWljrTBaGjQNJiQo9d3GWFGX4ZVmaMphhq1NHX0kopuNLTybsS7WUHGvLd4D9YiEQDEEyhPRF6tJaTWBACZaRlkMTrEBlhCmRoR8jYmJxqRRPppWnhlGnK/QeXqgz8oXS2PtWVn5WHgZYUrBogymAvMYk0CRTljWQlSsPWmM0tfpOpkwMXWAoSE87t577+18dKewyIv7lC5n12mJY2wWYXkwZym0WEu3L76Oz6krfW31F0uLvwu0CYRjLbfNcX4W3d6vI350co5ZiBHfWUxo5wpRXC6dp63eNWZeEKZZ4IAGEqYHTVM5DGmhd5CFM89jwYcWBMIUDK1eLE2NtakxzuT3vhQcSiK+VRgWFrBmToJmgT4WIrQ4RuwDxMIQ08qYsff+eEGTw+a+aSqnb+myha5jDEr91grVRUhg3jfMDQwajCxhhGPM4/N0Pel3nb62/G3Z5paOidYWjmihGfON+M1DrcXD6ksfr7nmmhCa30fWcmgh4+8H7NEMQjFOCJZixtDqjDU0di8+mqaHe97HJmFUuSaUvzE3XGMdUAoRFtyIccE70YfL9PsuNhZRoFh6uq74Oj6nnvQ19wpRnJdxFAEbZpgQ4wzmnxBhpb0vVjhvi/cQKtI/IVAEATE4RcCpxyT2iDFCEpOmeDCL02CGWAxAmLL4KGNxciJR4yb20c1RejEeS3wKlY1N1vA3MEaGiTY2mYsnMMyFaCsDM3sQYEJilJa+WX2km2mR5Y3TvNOl3Q5HJj2j2JSMe+zRQHvwD0FS7Z3dwySASVOphFTbh+9MsmOTjGSSyZfJnmsYKNMMkbFYe21yIl/c9vR1ui+Fvg32qzHCNwOGrtw2x4sKbOj/+te/hipZTMT+XnyztsBgco0nUhbe9l3hF2G2+FRkpjTWzhiftnjXaCPMd8wHXXA+kpbzIYCDpDNmNuz5xY7l4Mx3b4s76rTfSMwgGiakox2NvyW0mrTViN+HD+Rgl3mmkfyGwBQ/LR/QIcnD5r7xO0oS/AnMDGanRtjWo9FC6hvjwnuMxybyl9s3ysTvNT4nzagl35qVTR/RRBmhMYD4PuNvL8af9Lhd6bEk/m3Gv7+2bHM5YyLtzSL2OjPCPwbNFdRaPGJsrH6OYAjziC8SWhR8auLvxcZyTIKNwJLvDJ9LtGkIuND2NOerh6mvCZ74LaLtN4oZFYRlPiS9JRU8IoyjDUaMD0Zp5jfrdxRjUs5YFX9L5Yzz8fNoZ/yNsicO/qtGjNM+mEhgvNAiG4PTkvcQPzc+t2fpKASaIOB/oCIhkCDgB44k3KaXPiX37YRwjf4jCn9eShuiEBEVy08U4R6hQuM9a6ycdwZOylmUFUuLj14ClSOkLnvA2HM4+skqhJ72C4M4e965lxbnlfE+FyFEsDe5yLvvJ40Q8pjQohaBhshBhIgl2o8918J8ko+Qy+xjYWlEcSFUKu31zF3Oa1+SNPJ4J8qQ5m2wc16blZdGiFxCavpJOS+aEvvOeEYk7P9BCFFCXxIlxqKO5XU2deE3kMuLWGPttCOhtf3CKpQq1l6wHz16dNJe3idRnugnUZvAzur0i86c134l+zaAt6Wx1wxhU4lOZlGLvGQ4hMG2ppfTZsrEoVz9AiPsWUEIWm/alTyX54MhkbEgz1zl4cJeELSNfsTlaCORtNrrXRNW3LDxDF7Yt4k9j/j+iFpGhC2/OEveUWh8gX/l4uzt+5Nnr7zyymHfJ/Cz9nD0JjFJSGi+db8gzEsHN+qhnF/QhZb5xVbOL/by8lmaXzwlIXOpn+hnhI63iEtx1wg1b22JQ4+Did3PCllPHeX0Leu7JwocY16aWvKtpevg2jOISR+IYsU3xu/G+sXR+06FCIR+kZvzjEHeb4yw6l64E75LL6DIK8eYyJjHbxNqqzaXMiaGB/p/nglN2kTkSsZQz8TkiARG3xg/6JNROXjwGy71nTGn8DzGUMJlexO18M1xj2h9nhm2JuS8Ji1pM+nxH78tz+gkeQudeD+2ZFxhfiHSG+Od7RPD2MIcEJPfuDl5Fr8vr3XKecFKskcX7SCSp71PK2uhp0nnG1rDbwNApMvWjFUtHee9NiznLQySftAmz8SEfYEYa+Nxg+iMRFZjPeA1raEM36hRqe+BOT/9u2B+9No3q0pHIZCJAKpIkRDIQ8CYERaBLMRjYt8JJi32imGwtcmBhY83swmhTOP8dg6zRF4210sP4JaHI4toqzPrSHjbYkRYYFu4MtgyGRCylD1pqI/FBAMvC04GTkIys+C0Z9Fn2mp7EfAs9nKx9PSRTcjS9+yaCToOT233OVpo3qzN3uJ8nIM3E1JzBLNhOFsdMCuE2vXS9VDcSyoLtvdBvzkpTKuVjY8+EELmffIwUcM8cc5GeSyi47JekhkYtaz3Xkqbrd9MrmwSaXUTopZNYwlPyz2YFPrPvjgwT0YsuLz0PCnHO2HxYeGwCUvMZoDsr9Je75pvIWZMrA/pI4x2MWoJzmwWCSPIs/i+ER6w8Ig3xwUTNhs1gqk1fCjHb4rFGwwBRAjYdNvt2mskQx4WvHbPjln7VYAN6TBR8TdCqHXGFcYZhAFZVGrfbAFs7YiPCCfS1NJvLV0PC2t+E+DOM/ktsND1AUwSbPiO+Y3GjF7cPpgcvuH4XnzOu4Laqs2ljInWz5jBsT7SNq9FCUIfr9W3rOFYDh4Ih+J+xufpd0ZerynKy89eKewzlhYQeW1FjjDmtNHqZOxg0QxzXyrxTaXHW75X5hwYzzTFDA7PtXmKI79FQlXH37+VhymM24owwkfla/FY1dJxHsYxfseGHUfG/HhsjtPic757o1LfA0KBuI74vJR50Z6nY/0hMAdd9h+MSAgkCKDm9pJRhwMlYVhxGjbCeROHSByPMUnhGvMxQnT6hbhlyzv6ycdhpgBhQuC1CXnp8YUf4IP5hmdOghmAH1CDepv7XmIVooHhBFuM/ETv8EfAidnaRJvxQzHnzbg8JgLWD7/IauLIzHPJY23yE1LoO/f9xBhMSvzEFtKtvZihEPUJUxTuUZZy1ANunOOnQChT1PZ+EA95UPd7qWUwWyPSmBH2+0S/KoUwN3jLm6fh55GO6kN53m+h9qL6p638QbQ17gvYU5Zhg77wBwb0B18mfLgwQcMEivfOOeZxzVFzbY7LY5qE3wpRhrx0M7TFMzTBHI22ZBH9ABPwNRMrAjvQDxzvjdrrXWM6h2kmtvX4CfAOwAgfAHwBYtMSHOpj0zprG0d+By3Bmf5jekRkKzOV4h5+SZitYUaSRbSR3xLmNkQ3MwI3sCz0HfE9gCVH8tBuvhX77q0eO2LaQ9viZ5AGFrzTYt9QqX3L+u5pE1Tou2nJtxYqTP1jfMFUlsAP4AExbtrYye+K3xl9sd+f/cY4co90xgwbY8hL+xlnuGfUFm2m3mJjoj2LyH2MrRAmsJg3YiLGeM+7LkSl4EHZct8ZpmqYm/G9Ea2tWBvIY33k98ZY1RJiXsHniPKMt7yjLMJU2AtkQhL48LtnTMKk0zPxWUWSe4yPmF17gVXin9Oasaql4zzzWfybj79RfkNcg6v98Y3aOUfmY5tbrHPcL/Ye0r8LylEv/efbL/aO7Rk61ikC/oMUCYEmCGAS4n8SQfKLpqM1ZBIYtBWiRgRs4zc/QAcVf2NKw1lsXoUZk6g6EUBqbZtaxhtXWm8wkWJjXH5v/HlGxJJ0FAIVjUCswUGbJiqMQKzBQdskEgJCoH0RaBT71CmDp25nI3DAAQc4v6gOkhXvi5KdqYS7OEXi8EnkoLYK7VzCY6siizn9+594kJKnG41WDOkWlA6zmc6r68pFgIh4SOqhrMAdSD6RzEJoGAkpLRIC1YCAacBoK1J1UWEEhFVhbJQiBNoDATE47YFqDdSJ2pcoT5gcEBnF2+2W3SuitHjfl2B6QrhZ1MmiRgRiczki52A2YIRJAjurs2gg+ta2225rSTpWGQLxe2ZT1/RviShnmK9gouXt3Kusd2puvSKAKVwcyQ2TT1FhBGJ8MGuLx/vCpZQiBIRASxEQg9NS5OqgHCFj2YOCXaDTGwCW0n0W6djPeofuvP1lSilbD3nYeds2LmThiy/ImmuuGfZOwLYdm338btgF2uz26wGXWusjGhnblwOGlXDk3ONdo7mBeSWdPWOkvam1t1+b/WFMYl4wDTO9RNPvo2SFPX9qs9ct6xX+JT6IifMmakkF+BbhrxiHmE4SdSIEhECbIKAgA20CoyophADmV3ICLIROgxOtD4EZnFRxOGcPkPl9gAc2xiPggah2EGCvHR/1xyHJZYEDQ4uzMZtjFnJyr53eqye1hABml5hb4jBuwhdz/IZZJ9CAqAEBAh/8/e9/T4JHWJAInOQxQy5lrxxhKQSEQPkIiMEpHzOVEAJCQAgIASEgBISAEBACQqBCEZCJWoW+GDVLCAgBISAEhIAQEAJCQAgIgfIREINTPmYqIQSEgBAQAkJACAgBISAEhECFIiAGp0JfjJolBISAEBACQkAICAEhIASEQPkIiMEpHzOVEAJCQAgIASEgBISAEBACQqBCERCDU6EvRs0SAkJACAgBISAEhIAQEAJCoHwExOCUj5lKCAEhIASEgBAQAkJACAgBIVChCIjBqdAXo2YJASEgBISAEBACQkAICAEhUD4CYnDKx0wlhIAQEAJCQAgIASEgBISAEKhQBMTgVOiLUbOEgBAQAkJACAgBISAEhIAQKB8BMTjlY6YSQkAICAEhIASEgBAQAkJACFQoAmJwKvTFqFlCQAgIASEgBISAEBACQkAIlI+AGJzyMVMJISAEhIAQEAJCQAgIASEgBCoUATE4Ffpi1CwhIASEgBAQAkJACAgBISAEykdADE75mKmEEBACQkAICAEhIASEgBAQAhWKgBicCn0xapYQEAJCQAgIASEgBISAEBAC5SMgBqd8zFRCCAgBISAEhIAQEAJCQAgIgQpFQAxOhb4YNUsICAEhIASEgBAQAkJACAiB8hEQg1M+ZiohBISAEBACQkAICAEhIASEQIUiIAanQl+MmiUEhIAQEAJCQAgIASEgBIRA+QiIwSkfM5UQAkJACAgBISAEhIAQEAJCoEIREINToS9GzRICQkAICAEhIASEgBAQAkKgfATE4JSPmUoIASEgBISAEBACQkAICAEhUKEIiMGp0BejZgkBISAEhIAQEAJCQAgIASFQPgJicMrHTCWEgBAQAkJACAgBISAEhIAQqFAExOBU6ItRs4SAEBACQkAICAEhIASEgBAoHwExOOVjphJCQAgIASEgBISAEBACQkAIVCgCYnAq9MWoWUJACAgBISAEhIAQEAJCQAiUj4AYnPIxUwkhIASEgBAQAkJACAgBISAEKhQBMTgV+mLULCEgBISAEBACQkAICAEhIATKR0AMTvmYqYQQEAJCQAgIASEgBISAEBACFYrA/wOukTFjFC2wUAAAAABJRU5ErkJggg=="
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding in the Optimizer\n",
        "\n",
        "You may have noticed we're missing one key part of model training, the optimizer! The recommended way to apply the optimizer in TorchRec is through PyTorch's `apply_optimizer_in_backward` API. This gives you parameter level granualtiy and as such lets you define different optimizers or optimizer parameters for each paramter in your model.\n",
        "\n",
        "With this level of control, you can define a different optimizer for a set of parameters or for embedding_bags as a whole. A key thing to note here, you need to be aware of is the parameter naming. EmbeddingBagCollections will be named something similar to `embedding_bags....` and EmbeddingCollections `embeddings...`. Inspect the model parameters through `model.named_parameters()` to understand how your model parameters are named.\n",
        "\n",
        "TorchRec uses `CombinedOptimizer` which contains `KeyedOptimizers` within. A `CombinedOptimizer` effectively makes it easy to handle multiple optimizers for various sub groups in the model. A `KeyedOptimizer` extends the `torch.optim.Optimizer` and is initialized through a dictionary of parameters exposes the parameters. Each `TBE` module in a `EmbeddingBagCollection` will have it's own KeyedOptimizer which all combined into one `CombinedOptimizer`.\n",
        "\n",
        "#### Fused optimizer in TorchRec\n",
        "\n",
        "Using DistributedModelParallel, the optimizer is fused, which means that the optimizer update is done in the backward. Hence the term \"fused\". This is an optimization in TorchRec and FBGEMM, the optimizer embedding gradients are not materialized and direclty applied to the parameters. This brings significant memory savings are embedding gradients are typically size of the parameters themselves. You can, however, choose to make the optimizer \"dense\" which does not apply this optimization and let's you inspect the embedding gradients or apply computations to it as you wish. A dense optimizer in this case would be your [canonical PyTorch model training loop with optimizer.](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html) \n",
        "\n",
        "Once the optimizer is created through DistributedModelParallel, you still need to manage an optimizer for the dense parameters. This you will do through the canonical PyTorch training loop, to find the dense parameters, you can call `in_backward_optimizer_filter(model.named_parameters())`. Apply the dense optimizer to those parameters as you would a normal Torch optimizer and combine this and the model.fused_optimizer into one `CombinedOptimizer` that you can use in your training loop to `zero_grad` and `step` through.\n",
        "\n",
        "#### Let's add an optimizer to our EmbeddingBagCollection\n",
        "We will do this in two ways, which are equivalent, but give you options depending on your preferences\n",
        "1. Passing optimizer kwargs through fused parameters (fused_params) in sharder\n",
        "2. Through `apply_optimizer_in_backward` \n",
        "Note: `apply_optimizer_in_backward` converts the optimizer parameters to `fused_params` to pass to the `TBE` in the `EmbeddingBagCollection`/`EmbeddingCollection`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "output": {
          "id": 8405107842888302,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0918 212104.678 split_table_batched_embeddings_ops_training.py:712] Using global weight decay = False\n",
            "I0918 212104.681 split_table_batched_embeddings_ops_training.py:1025] [TBE=1122ea02-d61b-48d1-91c1-3b7b8527ea13] Contents: ['product_table', 'user_table']\n",
            "I0918 212104.681 split_table_batched_embeddings_ops_training.py:1025] [TBE=1122ea02-d61b-48d1-91c1-3b7b8527ea13] Using fused exact_row_wise_adagrad with optimizer_args=OptimizerArgs(stochastic_rounding=True, gradient_clipping=False, max_gradient=1.0, max_norm=0.0, learning_rate=0.02, eps=0.002, beta1=0.9, beta2=0.999, step_ema=10000, step_swap=10000, step_start=0, step_mode=2, weight_decay=0.0, weight_decay_mode=0, eta=0.001, momentum=0.9, counter_halflife=-1, adjustment_iter=-1, adjustment_ub=1.0, learning_rate_mode=-1, grad_sum_decay=-1, tail_id_threshold=0, is_tail_id_thresh_ratio=0, total_hash_size=8192, weight_norm_coefficient=0.0, lower_bound=0.0, regularization_mode=0)\n",
            "I0918 212104.682 split_table_batched_embeddings_ops_training.py:1025] [TBE=1122ea02-d61b-48d1-91c1-3b7b8527ea13] Using rowwise_adagrad_with_counter=False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Sharded EBC fused optimizer: : EmbeddingFusedOptimizer (\n",
            "Parameter Group 0\n",
            "    lr: 0.01\n",
            ")\n",
            "Sharded EBC with fused parameters fused optimizer: : EmbeddingFusedOptimizer (\n",
            "Parameter Group 0\n",
            "    lr: 0.02\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'embedding_bags.product_table.weight': Parameter containing:\n",
              " Parameter(TableBatchedEmbeddingSlice([[-0.0059, -0.0100, -0.0129,  ..., -0.0060,\n",
              "                               0.0085, -0.0018],\n",
              "                             [ 0.0055,  0.0149,  0.0130,  ..., -0.0099,\n",
              "                              -0.0013, -0.0128],\n",
              "                             [ 0.0055,  0.0072,  0.0066,  ..., -0.0057,\n",
              "                               0.0046,  0.0028],\n",
              "                             ...,\n",
              "                             [ 0.0139, -0.0004,  0.0118,  ...,  0.0059,\n",
              "                              -0.0127,  0.0018],\n",
              "                             [ 0.0119, -0.0104,  0.0022,  ...,  0.0109,\n",
              "                              -0.0099, -0.0042],\n",
              "                             [-0.0024, -0.0066,  0.0084,  ..., -0.0105,\n",
              "                               0.0034, -0.0137]], device='cuda:0')),\n",
              " 'embedding_bags.user_table.weight': Parameter containing:\n",
              " Parameter(TableBatchedEmbeddingSlice([[ 0.0111, -0.0150,  0.0025,  ..., -0.0134,\n",
              "                              -0.0110,  0.0041],\n",
              "                             [-0.0111,  0.0131,  0.0132,  ..., -0.0073,\n",
              "                              -0.0019,  0.0104],\n",
              "                             [ 0.0018,  0.0141,  0.0114,  ..., -0.0151,\n",
              "                               0.0051,  0.0132],\n",
              "                             ...,\n",
              "                             [ 0.0098, -0.0073, -0.0036,  ..., -0.0132,\n",
              "                               0.0103,  0.0036],\n",
              "                             [ 0.0026, -0.0085,  0.0023,  ...,  0.0026,\n",
              "                               0.0109, -0.0102],\n",
              "                             [-0.0040, -0.0130,  0.0002,  ..., -0.0143,\n",
              "                              -0.0056, -0.0108]], device='cuda:0'))}"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Approach 1: passing optimizer kwargs through fused parameters\n",
        "from torchrec.optim.optimizers import in_backward_optimizer_filter\n",
        "from fbgemm_gpu.split_embedding_configs import EmbOptimType\n",
        "\n",
        "\n",
        "# We initialize the sharder with\n",
        "fused_params = {\n",
        "    \"optimizer\": EmbOptimType.EXACT_ROWWISE_ADAGRAD,\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"eps\": 0.002,\n",
        "}\n",
        "\n",
        "# Init sharder with fused_params\n",
        "sharder_with_fused_params = EmbeddingBagCollectionSharder(fused_params=fused_params)\n",
        "\n",
        "# We'll use same plan and unsharded EBC as before but this time with our new sharder\n",
        "sharded_ebc_fused_params = sharder_with_fused_params.shard(ebc, plan.plan[\"\"], env, torch.device(\"cuda\"))\n",
        "\n",
        "# Looking at the optimizer of each, we can see that the learning rate changed, which indicates our optimizer has been applied correclty.\n",
        "# We can also look at the TBE logs of the cell to see that our new optimizer is indeed being applied\n",
        "print(f\"Original Sharded EBC fused optimizer: {sharded_ebc.fused_optimizer}\")\n",
        "print(f\"Sharded EBC with fused parameters fused optimizer: {sharded_ebc_fused_params.fused_optimizer}\")\n",
        "\n",
        "# We can also check through the filter, we set include=True to show us the parameters that have an optimizer applied to them\n",
        "dict(in_backward_optimizer_filter(sharded_ebc_fused_params.named_parameters(), include=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "output": {
          "id": 1510298262960428,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0918 212105.606 split_table_batched_embeddings_ops_training.py:712] Using global weight decay = False\n",
            "I0918 212105.610 split_table_batched_embeddings_ops_training.py:1025] [TBE=8c183a68-c646-4cf1-be7d-7d222ef4e925] Contents: ['product_table', 'user_table']\n",
            "I0918 212105.611 split_table_batched_embeddings_ops_training.py:1025] [TBE=8c183a68-c646-4cf1-be7d-7d222ef4e925] Using fused exact_sgd with optimizer_args=OptimizerArgs(stochastic_rounding=True, gradient_clipping=False, max_gradient=1.0, max_norm=0.0, learning_rate=0.5, eps=1e-08, beta1=0.9, beta2=0.999, step_ema=10000, step_swap=10000, step_start=0, step_mode=2, weight_decay=0.0, weight_decay_mode=0, eta=0.001, momentum=0.99, counter_halflife=-1, adjustment_iter=-1, adjustment_ub=1.0, learning_rate_mode=-1, grad_sum_decay=-1, tail_id_threshold=0, is_tail_id_thresh_ratio=0, total_hash_size=8192, weight_norm_coefficient=0.0, lower_bound=0.0, regularization_mode=0)\n",
            "I0918 212105.613 split_table_batched_embeddings_ops_training.py:1025] [TBE=8c183a68-c646-4cf1-be7d-7d222ef4e925] Using rowwise_adagrad_with_counter=False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='embedding_bags.product_table.weight'\n",
            "name='embedding_bags.user_table.weight'\n",
            ": EmbeddingFusedOptimizer (\n",
            "Parameter Group 0\n",
            "    lr: 0.5\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch.distributed.optim import _apply_optimizer_in_backward as apply_optimizer_in_backward\n",
        "import copy\n",
        "# Approach 2: applying optimizer through apply_optimizer_in_backward\n",
        "# Note: we need to call apply_optimizer_in_backward on unsharded model first and then shard it\n",
        "\n",
        "# We can achieve the same result as we did in the previous\n",
        "ebc_apply_opt = copy.deepcopy(ebc)\n",
        "optimizer_kwargs = {\"lr\": 0.5, \"momentum\": 0.99}\n",
        "\n",
        "for name, param in ebc_apply_opt.named_parameters():\n",
        "    print(f\"{name=}\")\n",
        "    apply_optimizer_in_backward(torch.optim.SGD, [param], optimizer_kwargs)\n",
        "\n",
        "sharded_ebc_apply_opt = sharder.shard(ebc_apply_opt, plan.plan[\"\"], env, torch.device(\"cuda\"))\n",
        "# Now when we print the optimizer, we will see our new learning rate, you can verify momentum through the TBE logs at the top of the cell output\n",
        "print(sharded_ebc_apply_opt.fused_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "bEgB987CcspG",
        "language": "markdown",
        "originalKey": "4c464de0-20ef-4ef2-89e2-5d58ca224660",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Anatomy of Sharded TorchRec modules\n",
        "\n",
        "We have now successfully sharded an EmbeddingBagCollection given a sharding plan that we generated! The sharded module has common APIs from TorchRec which abstract away distributed communication/compute amongst multiple GPUs. In fact, these APIs are highly optimized for performance in training and inference. **Below are the three common APIs for distributed training/inference** that are provided by TorchRec:\n",
        "\n",
        "1. **input_dist**: Handles distributing inputs from GPU to GPU\n",
        "\n",
        "2. **lookups**: Does the actual embedding lookup in an optimized, batched manner using FBGEMM TBE (more on this later)\n",
        "\n",
        "3. **output_dist**: Handles distributing outputs from GPU to GPU\n",
        "\n",
        "The distribution of inputs/outputs is done through [NCCL Collectives](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/overview.html), namely [All-to-Alls](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/p2p.html#all-to-all), which is where all GPUs send/receive data to and from one another. TorchRec interfaces with PyTorch distributed for collectives and provides clean abstractions to the end users, removing the concern for the lower level details.\n",
        "\n",
        "\n",
        "The backwards pass does all of these collectives but in the reverse order for distribution of gradients. input_dist, lookup, and output_dist all depend on the sharding scheme. Since we sharded in a table-wise fashion, these APIs are modules that are constructed by [TwPooledEmbeddingSharding](https://pytorch.org/torchrec/torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000155075,
        "executionStopTime": 1726000155253,
        "id": "O2ptES89cspG",
        "language": "python",
        "originalKey": "03e6e163-af3a-4443-a5a8-3f877fc401d2",
        "output": {
          "id": 543140851566068,
          "loadingStatus": "loaded"
        },
        "outputId": "fcc48088-ccf7-4115-aa3f-0d92761db6d4",
        "outputsInitialized": true,
        "requestMsgId": "03e6e163-af3a-4443-a5a8-3f877fc401d2",
        "serverExecutionDuration": 5.8192722499371,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ShardedEmbeddingBagCollection(\n",
              "  (lookups): \n",
              "   GroupedPooledEmbeddingsLookup(\n",
              "      (_emb_modules): ModuleList(\n",
              "        (0): BatchedFusedEmbeddingBag(\n",
              "          (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "   (_input_dists): \n",
              "   TwSparseFeaturesDist(\n",
              "      (_dist): KJTAllToAll()\n",
              "    )\n",
              "   (_output_dists): \n",
              "   TwPooledEmbeddingDist(\n",
              "      (_dist): PooledEmbeddingsAllToAll()\n",
              "    )\n",
              "  (embedding_bags): ModuleDict(\n",
              "    (product_table): Module()\n",
              "    (user_table): Module()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sharded_ebc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000155256,
        "executionStopTime": 1726000155442,
        "id": "PHjJt3BQcspG",
        "language": "python",
        "originalKey": "c2a34340-d5fd-4dc8-9b7e-3a761a0c5f82",
        "output": {
          "id": 389282680943343,
          "loadingStatus": "loaded"
        },
        "outputId": "ca190c7d-939e-42a5-ef62-88062d2cc4b3",
        "outputsInitialized": true,
        "requestMsgId": "c2a34340-d5fd-4dc8-9b7e-3a761a0c5f82",
        "serverExecutionDuration": 5.3565315902233,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TwSparseFeaturesDist(\n",
              "   (_dist): KJTAllToAll()\n",
              " )]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distribute input KJTs to all other GPUs and receive KJTs\n",
        "sharded_ebc._input_dists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000155445,
        "executionStopTime": 1726000155695,
        "id": "jrEXMc7TcspG",
        "language": "python",
        "originalKey": "88abe892-1ed1-4806-84ad-35f43247a772",
        "output": {
          "id": 1738623510243650,
          "loadingStatus": "loaded"
        },
        "outputId": "c8036426-7d46-4e53-aefb-947b16f4fb99",
        "outputsInitialized": true,
        "requestMsgId": "88abe892-1ed1-4806-84ad-35f43247a772",
        "serverExecutionDuration": 5.3521953523159,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TwPooledEmbeddingDist(\n",
              "   (_dist): PooledEmbeddingsAllToAll()\n",
              " )]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distribute output embeddingts to all other GPUs and receive embeddings\n",
        "sharded_ebc._output_dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "C2jfo5ilcspH",
        "language": "markdown",
        "originalKey": "2eaf16f1-ac14-4f7a-b443-e707ff85c3f0",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Optimizing Embedding Lookups\n",
        "\n",
        "In performing lookups for a collection of embedding tables, a trivial solution would be to iterate through all the `nn.EmbeddingBags` and do a lookup per table. This is exactly what the standard, unsharded TorchRec's `EmbeddingBagCollection` does. However, while this solution is simple, it is extremely slow.\n",
        "\n",
        "[FBGEMM](https://github.com/pytorch/FBGEMM/tree/main/fbgemm_gpu) is a library that provides GPU operators (otherewise known as kernels) that are very optimized. One of these operators is known as **Table Batched Embedding** (TBE), provides two major optimizations:\n",
        "\n",
        "* Table batching, which allows you to look up multiple embeddings with one kernel call.\n",
        "* Optimizer Fusion, which allows the module to update itself given the canonical pytorch optimizers and arguments.\n",
        "\n",
        "The `ShardedEmbeddingBagCollection` uses the FBGEMM TBE as the lookup instead of traditional `nn.EmbeddingBags` for optimized embedding lookups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000155699,
        "executionStopTime": 1726000155879,
        "id": "1GoHWI6OcspH",
        "language": "python",
        "originalKey": "801c50b9-e1a2-465a-9fa3-3cd87d676ed4",
        "output": {
          "id": 828760942750031,
          "loadingStatus": "loaded"
        },
        "outputId": "6888ef2d-6e87-4d5d-9d9c-0021b7b836fa",
        "outputsInitialized": true,
        "requestMsgId": "801c50b9-e1a2-465a-9fa3-3cd87d676ed4",
        "serverExecutionDuration": 5.0756596028805,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[GroupedPooledEmbeddingsLookup(\n",
              "   (_emb_modules): ModuleList(\n",
              "     (0): BatchedFusedEmbeddingBag(\n",
              "       (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
              "     )\n",
              "   )\n",
              " )]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sharded_ebc._lookups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "1zcbZX1lcspH",
        "language": "markdown",
        "originalKey": "f2b31d78-81a9-426f-b017-ca8404383939",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### DistributedModelParallel\n",
        "\n",
        "We have now explored sharding a single EmbeddingBagCollection! We were able to take the `EmbeddingBagCollectionSharder` and use the unsharded `EmbeddingBagCollection` to generate a `ShardedEmbeddingBagCollection` module. This workflow is fine, but typically when doing model parallel, [`DistributedModelParallel`](https://pytorch.org/torchrec/torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel) (DMP) is used as the standard interface. When wrapping your model (in our case `ebc`), with DMP, the following will occur:\n",
        "\n",
        "1. Decide how to shard the model. DMP will collect the available ‘sharders’ and come up with a ‘plan’ of the optimal way to shard the embedding table(s) (i.e, the EmbeddingBagCollection)\n",
        "2. Actually shard the model. This includes allocating memory for each embedding table on the appropriate device(s).\n",
        "\n",
        "DMP takes in everything that we've just experimented with, like a static sharding plan, a list of sharders, etc. However, it also has some nice defaults to seamlessly shard a TorchRec model. In this toy example, since we have two EmbeddingTables and one GPU, TorchRec will place both on the single GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000155883,
        "executionStopTime": 1726000156073,
        "id": "ypVUDwpzcspH",
        "language": "python",
        "originalKey": "e0e198e1-db2a-46b0-91f0-51a5ff80abbb",
        "output": {
          "id": 1473432496682187,
          "loadingStatus": "loaded"
        },
        "outputId": "46d708d1-a957-442f-9db7-642d98644904",
        "outputsInitialized": true,
        "requestMsgId": "e0e198e1-db2a-46b0-91f0-51a5ff80abbb",
        "serverExecutionDuration": 7.8761726617813,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmbeddingBagCollection(\n",
              "  (embedding_bags): ModuleDict(\n",
              "    (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "    (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ebc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000156075,
        "executionStopTime": 1726000156438,
        "id": "5EdlyWAycspH",
        "language": "python",
        "originalKey": "73fec38d-947a-49d5-a2ba-61e3828b7117",
        "output": {
          "id": 1265992801229170,
          "loadingStatus": "loaded"
        },
        "outputId": "93ee2bab-9c46-4e9e-93cb-3c7abc77c1fa",
        "outputsInitialized": true,
        "requestMsgId": "73fec38d-947a-49d5-a2ba-61e3828b7117",
        "serverExecutionDuration": 165.43522849679,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0918 211908.013 comm.py:50] Could not determine LOCAL_WORLD_SIZE from environment, falling back to WORLD_SIZE.\n",
            "I0918 211908.062 stats.py:522] ##################################################################################################################################################################################################################################################################################################\n",
            "I0918 211908.063 stats.py:522] #                                                                                                                                   --- Planner Statistics ---                                                                                                                                   #\n",
            "I0918 211908.064 stats.py:522] #                                                                                                          --- Evaluated 256 proposal(s), found 256 possible plan(s), ran for 0.05s ---                                                                                                          #\n",
            "I0918 211908.065 stats.py:522] # ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
            "I0918 211908.066 stats.py:522] #      Rank     HBM (GB)     DDR (GB)                              Perf (ms)     Input (MB)     Output (MB)     Shards                                                                                                                                                                           #\n",
            "I0918 211908.067 stats.py:522] #    ------   ----------   ----------                            -----------   ------------   -------------   --------                                                                                                                                                                           #\n",
            "I0918 211908.068 stats.py:522] #         0   0.002 (0%)     0.0 (0%)   0.003 (0.0006,0.0004,0.001,0.0004,0)           0.01            0.25      TW: 2                                                                                                                                                                           #\n",
            "I0918 211908.070 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.071 stats.py:522] # Perf: Total perf (Forward compute, Forward comms, Backward compute, Backward comms, Prefetch compute)                                                                                                                                                                                          #\n",
            "I0918 211908.072 stats.py:522] # Input: MB/iteration, Output: MB/iteration, Shards: number of tables                                                                                                                                                                                                                            #\n",
            "I0918 211908.073 stats.py:522] # HBM: estimated peak memory usage for shards, dense tensors, and features (KJT)                                                                                                                                                                                                                 #\n",
            "I0918 211908.074 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.075 stats.py:522] # Parameter Info:                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.076 stats.py:522] #               FQN     Sharding     Compute Kernel                               Perf (ms)     Storage (HBM, DDR)     Cache Load Factor     Pooling Factor     Num Poolings     Output     Weighing                         Sharder     Features     Emb Dim (CW Dim)     Hash Size     Ranks   #\n",
            "I0918 211908.077 stats.py:522] #             -----   ----------   ----------------                             -----------   --------------------   -------------------   ----------------   --------------   --------   ----------                       ---------   ----------   ------------------   -----------   -------   #\n",
            "I0918 211908.078 stats.py:522] #    .product_table           TW              fused   0.001 (0.0003,0.0002,0.0006,0.0002,0)     (0.001 GB, 0.0 GB)                  None                1.0              1.0     pooled   unweighted   EmbeddingBagCollectionSharder            1                   64          4096         0   #\n",
            "I0918 211908.078 stats.py:522] #       .user_table           TW              fused   0.001 (0.0003,0.0002,0.0006,0.0002,0)     (0.001 GB, 0.0 GB)                  None                1.0              1.0     pooled   unweighted   EmbeddingBagCollectionSharder            1                   64          4096         0   #\n",
            "I0918 211908.080 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.081 stats.py:522] # Batch Size: 512                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.085 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.087 stats.py:522] # Compute Kernels Count:                                                                                                                                                                                                                                                                         #\n",
            "I0918 211908.088 stats.py:522] #    fused: 2                                                                                                                                                                                                                                                                                    #\n",
            "I0918 211908.089 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.090 stats.py:522] # Compute Kernels Storage:                                                                                                                                                                                                                                                                       #\n",
            "I0918 211908.091 stats.py:522] #    fused: HBM: 0.002 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                           #\n",
            "I0918 211908.092 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.093 stats.py:522] # Total Perf Imbalance Statistics                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.094 stats.py:522] # Total Variation: 0.000                                                                                                                                                                                                                                                                         #\n",
            "I0918 211908.095 stats.py:522] # Total Distance: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 211908.095 stats.py:522] # Chi Divergence: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 211908.098 stats.py:522] # KL Divergence: 0.000                                                                                                                                                                                                                                                                           #\n",
            "I0918 211908.099 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.100 stats.py:522] # HBM Imbalance Statistics                                                                                                                                                                                                                                                                       #\n",
            "I0918 211908.101 stats.py:522] # Total Variation: 0.000                                                                                                                                                                                                                                                                         #\n",
            "I0918 211908.102 stats.py:522] # Total Distance: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 211908.103 stats.py:522] # Chi Divergence: 0.000                                                                                                                                                                                                                                                                          #\n",
            "I0918 211908.103 stats.py:522] # KL Divergence: 0.000                                                                                                                                                                                                                                                                           #\n",
            "I0918 211908.104 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.105 stats.py:522] # Total Variation: higher means more imbalanced (ranges 0 to 1)                                                                                                                                                                                                                                  #\n",
            "I0918 211908.106 stats.py:522] # Total Distance: higher means more imbalanced (ranges 0 to 1)                                                                                                                                                                                                                                   #\n",
            "I0918 211908.107 stats.py:522] # Chi Divergence: higher means more imbalanced (ranges 0 to 0.000)                                                                                                                                                                                                                               #\n",
            "I0918 211908.108 stats.py:522] # KL Divergence: higher means more imbalanced (ranges 0 to 0.000)                                                                                                                                                                                                                                #\n",
            "I0918 211908.109 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.110 stats.py:522] # Longest Critical Path (Maximum of Total Perf): 0.003 ms on rank 0                                                                                                                                                                                                                              #\n",
            "I0918 211908.113 stats.py:522] # Maximum of Forward Compute: 0.001 ms on rank 0                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.115 stats.py:522] # Maximum of Forward Comms: 0.0 ms on rank 0                                                                                                                                                                                                                                                     #\n",
            "I0918 211908.116 stats.py:522] # Maximum of Backward Compute: 0.001 ms on rank 0                                                                                                                                                                                                                                                #\n",
            "I0918 211908.116 stats.py:522] # Maximum of Backward Comms: 0.0 ms on rank 0                                                                                                                                                                                                                                                    #\n",
            "I0918 211908.117 stats.py:522] # Maximum of Prefetch Compute: 0.0 ms on rank 0                                                                                                                                                                                                                                                  #\n",
            "I0918 211908.118 stats.py:522] # Sum of Maxima: 0.003 ms                                                                                                                                                                                                                                                                        #\n",
            "I0918 211908.121 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.122 stats.py:522] # Estimated Sharding Distribution                                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.124 stats.py:522] # Max HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                  #\n",
            "I0918 211908.125 stats.py:522] # Min HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                  #\n",
            "I0918 211908.126 stats.py:522] # Mean HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.127 stats.py:522] # Low Median HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                           #\n",
            "I0918 211908.128 stats.py:522] # High Median HBM: 0.002 GB on rank [0]                                                                                                                                                                                                                                                          #\n",
            "I0918 211908.129 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.131 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.132 stats.py:522] # Top HBM Memory Usage Estimation: 0.002 GB                                                                                                                                                                                                                                                      #\n",
            "I0918 211908.133 stats.py:522] # Top Tier #1 Estimated Peak HBM Pressure: 0.002 GB on rank 0                                                                                                                                                                                                                                    #\n",
            "I0918 211908.133 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.134 stats.py:522] # Reserved Memory:                                                                                                                                                                                                                                                                               #\n",
            "I0918 211908.135 stats.py:522] #    HBM: 4.8 GB                                                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.136 stats.py:522] #    Percent of Total HBM: 15%                                                                                                                                                                                                                                                                   #\n",
            "I0918 211908.137 stats.py:522] # Planning Memory:                                                                                                                                                                                                                                                                               #\n",
            "I0918 211908.138 stats.py:522] #    HBM: 27.2 GB, DDR: 128.0 GB                                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.141 stats.py:522] #    Percent of Total HBM: 85%                                                                                                                                                                                                                                                                   #\n",
            "I0918 211908.142 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.143 stats.py:522] # Dense Storage (per rank):                                                                                                                                                                                                                                                                      #\n",
            "I0918 211908.145 stats.py:522] #    HBM: 0.0 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                                    #\n",
            "I0918 211908.146 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.148 stats.py:522] # KJT Storage (per rank):                                                                                                                                                                                                                                                                        #\n",
            "I0918 211908.150 stats.py:522] #    HBM: 0.0 GB, DDR: 0.0 GB                                                                                                                                                                                                                                                                    #\n",
            "I0918 211908.151 stats.py:522] #                                                                                                                                                                                                                                                                                                #\n",
            "I0918 211908.152 stats.py:522] # Top 5 Tables Causing Max Perf:                                                                                                                                                                                                                                                                 #\n",
            "I0918 211908.152 stats.py:522] # Top 5 Tables Causing Max HBM:                                                                                                                                                                                                                                                                  #\n",
            "I0918 211908.154 stats.py:522] ##################################################################################################################################################################################################################################################################################################\n",
            "I0918 211908.170 split_table_batched_embeddings_ops_training.py:712] Using global weight decay = False\n",
            "I0918 211908.173 split_table_batched_embeddings_ops_training.py:1025] [TBE=df8f31b2-c400-4b12-a568-38224df7cf93] Contents: ['product_table', 'user_table']\n",
            "I0918 211908.173 split_table_batched_embeddings_ops_training.py:1025] [TBE=df8f31b2-c400-4b12-a568-38224df7cf93] Using fused exact_sgd with optimizer_args=OptimizerArgs(stochastic_rounding=True, gradient_clipping=False, max_gradient=1.0, max_norm=0.0, learning_rate=0.01, eps=1e-08, beta1=0.9, beta2=0.999, step_ema=10000, step_swap=10000, step_start=0, step_mode=2, weight_decay=0.0, weight_decay_mode=0, eta=0.001, momentum=0.9, counter_halflife=-1, adjustment_iter=-1, adjustment_ub=1.0, learning_rate_mode=-1, grad_sum_decay=-1, tail_id_threshold=0, is_tail_id_thresh_ratio=0, total_hash_size=8192, weight_norm_coefficient=0.0, lower_bound=0.0, regularization_mode=0)\n",
            "I0918 211908.174 split_table_batched_embeddings_ops_training.py:1025] [TBE=df8f31b2-c400-4b12-a568-38224df7cf93] Using rowwise_adagrad_with_counter=False\n"
          ]
        }
      ],
      "source": [
        "model = torchrec.distributed.DistributedModelParallel(ebc, device=torch.device(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000156441,
        "executionStopTime": 1726000156665,
        "id": "b5NgRErjcspH",
        "language": "python",
        "originalKey": "f8d87a4e-6a7a-4a02-92f9-9baa794266af",
        "output": {
          "id": 540115061929043,
          "loadingStatus": "loaded"
        },
        "outputId": "b6896040-b14e-4cbd-979e-0169391f9f2a",
        "outputsInitialized": true,
        "requestMsgId": "f8d87a4e-6a7a-4a02-92f9-9baa794266af",
        "serverExecutionDuration": 6.8417005240917,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x7f4f6dd83af0>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model(kjt)\n",
        "out.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000156669,
        "executionStopTime": 1726000156885,
        "id": "VJrSysjjcspH",
        "language": "python",
        "originalKey": "e7e02648-dee7-4b3a-8953-47e8b8771c3b",
        "output": {
          "id": 632661269203209,
          "loadingStatus": "loaded"
        },
        "outputId": "c93453f3-46b5-42ae-b697-73f3fa0f9ddc",
        "outputsInitialized": true,
        "requestMsgId": "e7e02648-dee7-4b3a-8953-47e8b8771c3b",
        "serverExecutionDuration": 5.4804161190987,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistributedModelParallel(\n",
              "  (_dmp_wrapped_module): ShardedEmbeddingBagCollection(\n",
              "    (lookups): \n",
              "     GroupedPooledEmbeddingsLookup(\n",
              "        (_emb_modules): ModuleList(\n",
              "          (0): BatchedFusedEmbeddingBag(\n",
              "            (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "     (_input_dists): \n",
              "     TwSparseFeaturesDist(\n",
              "        (_dist): KJTAllToAll()\n",
              "      )\n",
              "     (_output_dists): \n",
              "     TwPooledEmbeddingDist(\n",
              "        (_dist): PooledEmbeddingsAllToAll()\n",
              "      )\n",
              "    (embedding_bags): ModuleDict(\n",
              "      (product_table): Module()\n",
              "      (user_table): Module()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "BLM673eTcspH",
        "language": "markdown",
        "originalKey": "4b6171d5-ae60-4cc8-a47a-f01236c02e6c",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Sharding Best Practices\n",
        "\n",
        "Currently, our configuration is only sharding on 1 GPU (or rank), which is trivial: just place all the tables on 1 GPUs memory. However, in real production use cases, embedding tables are **typically sharded on hundreds of GPUs**, with different sharding methods such as table-wise, row-wise, and column-wise. It is incredibly important to determine a proper sharding configuration (to prevent out of memory issues) while keeping it balanced not only in terms of memory but also compute for optimal performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "Xc-RUDwDcspH",
        "language": "markdown",
        "originalKey": "e3bdc895-54c4-4fc6-9175-28dd75021c6a",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now that we are able to train distributed embeddings, how can we take the trained model and optimize it for inference? Inference is typically very sensitive to **performance and size of the model**. Running just the trained model in a Python environment is incredibly inefficient. There are two key differences between inference and training environments:\n",
        "* **Quantization**: Inference models are typically quantized, where model parameters lose precision for lower latency in predictions and reduced model size. For example FP32 (4 bytes) in trained model to INT8 (1 byte) for each embedding weight. This is also necessary given the vast scale of embedding tables, as we want to use as few devices as possible for inference to minimize latency.\n",
        "* **C++ environment**: Inference latency is a big deal, so in order to ensure ample performance, the model is typically ran in a C++ environment (along with situations where we don't have a Python runtime, like on device)\n",
        "\n",
        "TorchRec provides primitives for converting a TorchRec model into being inference ready with:\n",
        "* APIs for quantizing the model, introducing optimizations automatically with FBGEMM TBE\n",
        "* sharding embeddings for distributed inference\n",
        "* compiling the model to [TorchScript](https://pytorch.org/docs/stable/jit.html) (compatible in C++)\n",
        "\n",
        "In this section, we will go over this entire workflow of:\n",
        "* Quantizing the model\n",
        "* Sharding the quantized model\n",
        "* Compiling the sharded quantized model into TorchScript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000156892,
        "executionStopTime": 1726000157069,
        "id": "8JypsUNmcspH",
        "language": "python",
        "originalKey": "aae8ef10-f7a4-421a-b71c-f177ff74e96a",
        "output": {
          "id": "456742254014129",
          "loadingStatus": "before loading"
        },
        "outputId": "c1a29e04-2b2f-4ed7-b6d5-3185a8de807f",
        "outputsInitialized": true,
        "requestMsgId": "aae8ef10-f7a4-421a-b71c-f177ff74e96a",
        "serverExecutionDuration": 7.4504055082798,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmbeddingBagCollection(\n",
              "  (embedding_bags): ModuleDict(\n",
              "    (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "    (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ebc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000157071,
        "executionStopTime": 1726000157317,
        "id": "t2plfyrWcspH",
        "language": "python",
        "originalKey": "30694976-da54-48d6-922e-ca53f22c385f",
        "outputsInitialized": true,
        "requestMsgId": "30694976-da54-48d6-922e-ca53f22c385f",
        "serverExecutionDuration": 2.9501467943192,
        "showInput": true
      },
      "outputs": [],
      "source": [
        "class InferenceModule(torch.nn.Module):\n",
        "    def __init__(self, ebc: torchrec.EmbeddingBagCollection):\n",
        "        super().__init__()\n",
        "        self.ebc_ = ebc\n",
        "\n",
        "    def forward(self, kjt: KeyedJaggedTensor):\n",
        "        return self.ebc_(kjt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000157320,
        "executionStopTime": 1726000157494,
        "id": "5FRioGEmcspH",
        "language": "python",
        "originalKey": "2a4a83f1-449d-493e-8f24-7c1975ecad9d",
        "output": {
          "id": "1619365005294308",
          "loadingStatus": "before loading"
        },
        "outputId": "9a915474-904b-40f1-8549-524a7a5d6242",
        "outputsInitialized": true,
        "requestMsgId": "2a4a83f1-449d-493e-8f24-7c1975ecad9d",
        "serverExecutionDuration": 3.8229525089264,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ebc_.embedding_bags.product_table.weight torch.Size([4096, 64]) torch.float32\n",
            "ebc_.embedding_bags.user_table.weight torch.Size([4096, 64]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "module = InferenceModule(ebc)\n",
        "for name, param in module.named_parameters():\n",
        "    # Here, the parameters should still be FP32, as we are using a standard EBC\n",
        "    # FP32 is default, regularly used for training\n",
        "    print(name, param.shape, param.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "OSTy4SU8cspH",
        "language": "markdown",
        "originalKey": "665352e2-208f-4951-8601-282d036b0e4e",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Quantization\n",
        "\n",
        "As you can see above, the normal EBC contains embedding table weights as FP32 precision (32 bits for each weight). Here, we will use the TorchRec inference library to quantize the embedding weights of the model to INT8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000157499,
        "executionStopTime": 1726000157696,
        "id": "oV-KPRqDcspH",
        "language": "python",
        "originalKey": "796919b4-f9dd-4d14-a40e-f20668c8257b",
        "output": {
          "id": "560049189691202",
          "loadingStatus": "before loading"
        },
        "outputId": "593fcaef-7609-4969-b8fb-021a3c607f6a",
        "outputsInitialized": true,
        "requestMsgId": "796919b4-f9dd-4d14-a40e-f20668c8257b",
        "serverExecutionDuration": 14.22468572855,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized EBC: InferenceModule(\n",
            "  (ebc_): QuantizedEmbeddingBagCollection(\n",
            "    (_kjt_to_jt_dict): ComputeKJTToJTDict()\n",
            "    (embedding_bags): ModuleDict(\n",
            "      (product_table): Module()\n",
            "      (user_table): Module()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch import quantization as quant\n",
        "from torchrec.modules.embedding_configs import QuantConfig\n",
        "from torchrec.quant.embedding_modules import (\n",
        "    EmbeddingBagCollection as QuantEmbeddingBagCollection,\n",
        ")\n",
        "\n",
        "\n",
        "quant_dtype = torch.int8\n",
        "\n",
        "\n",
        "qconfig = QuantConfig(\n",
        "    # dtype of the result of the embedding lookup, post activation\n",
        "    # torch.float generally for compatability with rest of the model\n",
        "    # as rest of the model here usually isn't quantized\n",
        "    activation=quant.PlaceholderObserver.with_args(dtype=torch.float),\n",
        "    # quantized type for embedding weights, aka parameters to actually quantize\n",
        "    weight=quant.PlaceholderObserver.with_args(dtype=quant_dtype),\n",
        ")\n",
        "qconfig_spec = {\n",
        "    # Map of module type to qconfig\n",
        "    torchrec.EmbeddingBagCollection: qconfig,\n",
        "}\n",
        "mapping = {\n",
        "    # Map of module type to quantized module type\n",
        "    torchrec.EmbeddingBagCollection: QuantEmbeddingBagCollection,\n",
        "}\n",
        "\n",
        "\n",
        "module = InferenceModule(ebc)\n",
        "\n",
        "# Quantize the module\n",
        "qebc = quant.quantize_dynamic(\n",
        "    module,\n",
        "    qconfig_spec=qconfig_spec,\n",
        "    mapping=mapping,\n",
        "    inplace=False,\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Quantized EBC: {qebc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000157700,
        "executionStopTime": 1726000157862,
        "id": "fAztesVacspI",
        "language": "python",
        "originalKey": "c1fdd88b-73af-47a8-8aec-4f9422051ee7",
        "outputsInitialized": true,
        "requestMsgId": "c1fdd88b-73af-47a8-8aec-4f9422051ee7",
        "serverExecutionDuration": 4.0535479784012,
        "showInput": true
      },
      "outputs": [],
      "source": [
        "kjt = kjt.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000157865,
        "executionStopTime": 1726000158060,
        "id": "Wnpwa0TmcspI",
        "language": "python",
        "originalKey": "f5f911e8-ab78-4fd7-b4a1-7a545b5bd24b",
        "output": {
          "id": "434299789062153",
          "loadingStatus": "before loading"
        },
        "outputId": "3d9d74d8-190a-4300-9456-eea1d77deb08",
        "outputsInitialized": true,
        "requestMsgId": "f5f911e8-ab78-4fd7-b4a1-7a545b5bd24b",
        "serverExecutionDuration": 9.1104581952095,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x7fcd65f906a0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qebc(kjt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000158063,
        "executionStopTime": 1726000158228,
        "id": "UUs5fXNncspI",
        "language": "python",
        "originalKey": "99559efa-baaa-4de1-91d3-7899f87fe659",
        "output": {
          "id": "499581679596627",
          "loadingStatus": "before loading"
        },
        "outputId": "219afe85-97d9-4243-ccc6-4ea184df75ff",
        "outputsInitialized": true,
        "requestMsgId": "99559efa-baaa-4de1-91d3-7899f87fe659",
        "serverExecutionDuration": 3.4465603530407,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ebc_.embedding_bags.product_table.weight torch.Size([4096, 80]) torch.uint8\n",
            "ebc_.embedding_bags.user_table.weight torch.Size([4096, 80]) torch.uint8\n"
          ]
        }
      ],
      "source": [
        "# Once quantized, goes from parameters -> buffers, as no longer trainable\n",
        "for name, buffer in qebc.named_buffers():\n",
        "    # The shapes of the tables should be the same but the dtype should be int8 now\n",
        "    # post quantization\n",
        "    print(name, buffer.shape, buffer.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "fdM7UihocspI",
        "language": "markdown",
        "originalKey": "2b1a9c89-b921-4a35-9f64-0c63b09a2579",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Shard\n",
        "\n",
        "Here we perform sharding of the TorchRec quantized model. This is to ensure we are using the performant module through FBGEMM TBE. Here we are using one device to be consistent with training (1 TBE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000158234,
        "executionStopTime": 1726000158552,
        "id": "mha4FntncspI",
        "language": "python",
        "originalKey": "19c18bbb-6376-468a-a6dc-8346d30ceb48",
        "output": {
          "id": "882684747065056",
          "loadingStatus": "before loading"
        },
        "outputId": "3df67221-4b57-4e3a-e726-4387aa2b72e1",
        "outputsInitialized": true,
        "requestMsgId": "19c18bbb-6376-468a-a6dc-8346d30ceb48",
        "serverExecutionDuration": 108.51271077991,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Could not determine LOCAL_WORLD_SIZE from environment, falling back to WORLD_SIZE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharded Quantized EBC: InferenceModule(\n",
            "  (ebc_): ShardedQuantEmbeddingBagCollection(\n",
            "    (lookups): \n",
            "     InferGroupedPooledEmbeddingsLookup()\n",
            "    (_output_dists): ModuleList()\n",
            "    (embedding_bags): ModuleDict(\n",
            "      (product_table): Module()\n",
            "      (user_table): Module()\n",
            "    )\n",
            "    (_input_dist_module): ShardedQuantEbcInputDist()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchrec import distributed as trec_dist\n",
        "from torchrec.distributed.shard import _shard_modules\n",
        "\n",
        "\n",
        "sharded_qebc = _shard_modules(\n",
        "    module=qebc,\n",
        "    device=torch.device(\"cpu\"),\n",
        "    env=trec_dist.ShardingEnv.from_local(\n",
        "        1,\n",
        "        0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Sharded Quantized EBC: {sharded_qebc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000158555,
        "executionStopTime": 1726000159111,
        "id": "0iBD90t3cspI",
        "language": "python",
        "originalKey": "f00ae63f-0ac4-49c0-93fe-32d7fac76693",
        "output": {
          "id": "876807203893705",
          "loadingStatus": "before loading"
        },
        "outputId": "1eefc8f5-05fa-4f10-a805-9228a8735ffa",
        "outputsInitialized": true,
        "requestMsgId": "f00ae63f-0ac4-49c0-93fe-32d7fac76693",
        "serverExecutionDuration": 345.11629864573,
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x7fcd65f88ee0>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sharded_qebc(kjt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "08ue1zeVcspI",
        "language": "markdown",
        "originalKey": "897037bb-9d81-4a33-aea1-de1691217d41",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "### Compilation\n",
        "Now we have the optimized eager TorchRec inference model. The next step is to ensure that this model is loadable in C++, as currently it is only runnable in a Python runtime.\n",
        "\n",
        "The recommended method of compilation at Meta is two fold: [torch.fx tracing](https://pytorch.org/docs/stable/fx.html) (generate intermediate representation of model) and converting the result to TorchScript, where TorchScript is C++ compatible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000159118,
        "executionStopTime": 1726000159308,
        "id": "SRzo1jljcspI",
        "language": "python",
        "originalKey": "bdab6e95-3a71-4c3d-b188-115873f1f5d5",
        "output": {
          "id": "491668137118498",
          "loadingStatus": "before loading"
        },
        "outputId": "16de8f35-024c-48a4-af41-e76189d803ae",
        "outputsInitialized": true,
        "requestMsgId": "bdab6e95-3a71-4c3d-b188-115873f1f5d5",
        "serverExecutionDuration": 28.788283467293,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph Module Created!\n"
          ]
        }
      ],
      "source": [
        "from torchrec.fx import Tracer\n",
        "\n",
        "\n",
        "tracer = Tracer(leaf_modules=[\"IntNBitTableBatchedEmbeddingBagsCodegen\"])\n",
        "\n",
        "graph = tracer.trace(sharded_qebc)\n",
        "gm = torch.fx.GraphModule(sharded_qebc, graph)\n",
        "\n",
        "print(\"Graph Module Created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000159312,
        "executionStopTime": 1726000159490,
        "id": "NsgzbUdHcspI",
        "language": "python",
        "originalKey": "909178d6-4dae-45da-9c39-6827019f53a3",
        "output": {
          "id": "1555501808508272",
          "loadingStatus": "before loading"
        },
        "outputId": "4688827b-eba1-4a0b-e1fe-cd3ce0e3f11e",
        "outputsInitialized": true,
        "requestMsgId": "909178d6-4dae-45da-9c39-6827019f53a3",
        "serverExecutionDuration": 2.2248737514019,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "torch.fx._symbolic_trace.wrap(\"torchrec_distributed_quant_embeddingbag_flatten_feature_lengths\")\n",
            "torch.fx._symbolic_trace.wrap(\"torchrec_fx_utils__fx_marker\")\n",
            "torch.fx._symbolic_trace.wrap(\"torchrec_distributed_quant_embedding_kernel__unwrap_kjt\")\n",
            "torch.fx._symbolic_trace.wrap(\"torchrec_distributed_embedding_lookup_embeddings_cat_empty_rank_handle_inference\")\n",
            "\n",
            "def forward(self, kjt : torchrec_sparse_jagged_tensor_KeyedJaggedTensor):\n",
            "    flatten_feature_lengths = torchrec_distributed_quant_embeddingbag_flatten_feature_lengths(kjt);  kjt = None\n",
            "    _fx_marker = torchrec_fx_utils__fx_marker('KJT_ONE_TO_ALL_FORWARD_BEGIN', flatten_feature_lengths);  _fx_marker = None\n",
            "    split = flatten_feature_lengths.split([2])\n",
            "    getitem = split[0];  split = None\n",
            "    to = getitem.to(device(type='cuda', index=0), non_blocking = True);  getitem = None\n",
            "    _fx_marker_1 = torchrec_fx_utils__fx_marker('KJT_ONE_TO_ALL_FORWARD_END', flatten_feature_lengths);  flatten_feature_lengths = _fx_marker_1 = None\n",
            "    _unwrap_kjt = torchrec_distributed_quant_embedding_kernel__unwrap_kjt(to);  to = None\n",
            "    getitem_1 = _unwrap_kjt[0]\n",
            "    getitem_2 = _unwrap_kjt[1]\n",
            "    getitem_3 = _unwrap_kjt[2];  _unwrap_kjt = getitem_3 = None\n",
            "    _tensor_constant0 = self._tensor_constant0\n",
            "    _tensor_constant1 = self._tensor_constant1\n",
            "    bounds_check_indices = torch.ops.fbgemm.bounds_check_indices(_tensor_constant0, getitem_1, getitem_2, 1, _tensor_constant1, None);  _tensor_constant0 = _tensor_constant1 = bounds_check_indices = None\n",
            "    _tensor_constant2 = self._tensor_constant2\n",
            "    _tensor_constant3 = self._tensor_constant3\n",
            "    _tensor_constant4 = self._tensor_constant4\n",
            "    _tensor_constant5 = self._tensor_constant5\n",
            "    _tensor_constant6 = self._tensor_constant6\n",
            "    _tensor_constant7 = self._tensor_constant7\n",
            "    _tensor_constant8 = self._tensor_constant8\n",
            "    _tensor_constant9 = self._tensor_constant9\n",
            "    int_nbit_split_embedding_codegen_lookup_function = torch.ops.fbgemm.int_nbit_split_embedding_codegen_lookup_function(dev_weights = _tensor_constant2, uvm_weights = _tensor_constant3, weights_placements = _tensor_constant4, weights_offsets = _tensor_constant5, weights_tys = _tensor_constant6, D_offsets = _tensor_constant7, total_D = 128, max_int2_D = 0, max_int4_D = 0, max_int8_D = 64, max_float16_D = 0, max_float32_D = 0, indices = getitem_1, offsets = getitem_2, pooling_mode = 0, indice_weights = None, output_dtype = 0, lxu_cache_weights = _tensor_constant8, lxu_cache_locations = _tensor_constant9, row_alignment = 16, max_float8_D = 0, fp8_exponent_bits = -1, fp8_exponent_bias = -1);  _tensor_constant2 = _tensor_constant3 = _tensor_constant4 = _tensor_constant5 = _tensor_constant6 = _tensor_constant7 = getitem_1 = getitem_2 = _tensor_constant8 = _tensor_constant9 = None\n",
            "    embeddings_cat_empty_rank_handle_inference = torchrec_distributed_embedding_lookup_embeddings_cat_empty_rank_handle_inference([int_nbit_split_embedding_codegen_lookup_function], dim = 1, device = 'cuda:0', dtype = torch.float32);  int_nbit_split_embedding_codegen_lookup_function = None\n",
            "    to_1 = embeddings_cat_empty_rank_handle_inference.to(device(type='cpu'));  embeddings_cat_empty_rank_handle_inference = None\n",
            "    keyed_tensor = torchrec_sparse_jagged_tensor_KeyedTensor(keys = ['product', 'user'], length_per_key = [64, 64], values = to_1, key_dim = 1);  to_1 = None\n",
            "    return keyed_tensor\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "print(gm.code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000159494,
        "executionStopTime": 1726000160206,
        "id": "CjjJLc6pcspI",
        "language": "python",
        "originalKey": "ec77b6ea-f5b1-4c08-9cb9-93faf6a57532",
        "output": {
          "id": "978016470760577",
          "loadingStatus": "before loading"
        },
        "outputId": "4a1d33db-4734-4fad-d186-e8f7c80dd400",
        "outputsInitialized": true,
        "requestMsgId": "ec77b6ea-f5b1-4c08-9cb9-93faf6a57532",
        "serverExecutionDuration": 540.64276814461,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scripted Graph Module Created!\n"
          ]
        }
      ],
      "source": [
        "scripted_gm = torch.jit.script(gm)\n",
        "print(\"Scripted Graph Module Created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1726000160212,
        "executionStopTime": 1726000160395,
        "id": "BWKPRaI3cspI",
        "language": "python",
        "originalKey": "9eb089f1-2771-419d-a48e-3b7330c0a1e4",
        "output": {
          "id": "1020643789855657",
          "loadingStatus": "before loading"
        },
        "outputId": "46d30eac-2c9c-4bae-a0ae-3614084790c5",
        "outputsInitialized": true,
        "requestMsgId": "9eb089f1-2771-419d-a48e-3b7330c0a1e4",
        "serverExecutionDuration": 2.8529539704323,
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    kjt: __torch__.torchrec.sparse.jagged_tensor.KeyedJaggedTensor) -> __torch__.torchrec.sparse.jagged_tensor.KeyedTensor:\n",
            "  _0 = __torch__.torchrec.distributed.quant_embeddingbag.flatten_feature_lengths\n",
            "  _1 = __torch__.torchrec.fx.utils._fx_marker\n",
            "  _2 = __torch__.torchrec.distributed.quant_embedding_kernel._unwrap_kjt\n",
            "  _3 = __torch__.torchrec.distributed.embedding_lookup.embeddings_cat_empty_rank_handle_inference\n",
            "  flatten_feature_lengths = _0(kjt, )\n",
            "  _fx_marker = _1(\"KJT_ONE_TO_ALL_FORWARD_BEGIN\", flatten_feature_lengths, )\n",
            "  split = (flatten_feature_lengths).split([2], )\n",
            "  getitem = split[0]\n",
            "  to = (getitem).to(torch.device(\"cuda\", 0), True, None, )\n",
            "  _fx_marker_1 = _1(\"KJT_ONE_TO_ALL_FORWARD_END\", flatten_feature_lengths, )\n",
            "  _unwrap_kjt = _2(to, )\n",
            "  getitem_1 = (_unwrap_kjt)[0]\n",
            "  getitem_2 = (_unwrap_kjt)[1]\n",
            "  _tensor_constant0 = self._tensor_constant0\n",
            "  _tensor_constant1 = self._tensor_constant1\n",
            "  ops.fbgemm.bounds_check_indices(_tensor_constant0, getitem_1, getitem_2, 1, _tensor_constant1)\n",
            "  _tensor_constant2 = self._tensor_constant2\n",
            "  _tensor_constant3 = self._tensor_constant3\n",
            "  _tensor_constant4 = self._tensor_constant4\n",
            "  _tensor_constant5 = self._tensor_constant5\n",
            "  _tensor_constant6 = self._tensor_constant6\n",
            "  _tensor_constant7 = self._tensor_constant7\n",
            "  _tensor_constant8 = self._tensor_constant8\n",
            "  _tensor_constant9 = self._tensor_constant9\n",
            "  int_nbit_split_embedding_codegen_lookup_function = ops.fbgemm.int_nbit_split_embedding_codegen_lookup_function(_tensor_constant2, _tensor_constant3, _tensor_constant4, _tensor_constant5, _tensor_constant6, _tensor_constant7, 128, 0, 0, 64, 0, 0, getitem_1, getitem_2, 0, None, 0, _tensor_constant8, _tensor_constant9, 16)\n",
            "  _4 = [int_nbit_split_embedding_codegen_lookup_function]\n",
            "  embeddings_cat_empty_rank_handle_inference = _3(_4, 1, \"cuda:0\", 6, )\n",
            "  to_1 = torch.to(embeddings_cat_empty_rank_handle_inference, torch.device(\"cpu\"))\n",
            "  _5 = [\"product\", \"user\"]\n",
            "  _6 = [64, 64]\n",
            "  keyed_tensor = __torch__.torchrec.sparse.jagged_tensor.KeyedTensor.__new__(__torch__.torchrec.sparse.jagged_tensor.KeyedTensor)\n",
            "  _7 = (keyed_tensor).__init__(_5, _6, to_1, 1, None, None, )\n",
            "  return keyed_tensor\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(scripted_gm.code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "id": "DQiGRYOgcspI",
        "language": "markdown",
        "originalKey": "9a1dda10-b9cf-4d9f-b068-51ae3ce3ffc1",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "You have now gone from training a distributed RecSys model all the way to making it inference ready. https://github.com/pytorch/torchrec/tree/main/torchrec/inference has a full example of how to load a TorchRec TorchScript model into C++ for inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebXfh7oW9fHH",
        "language": "markdown",
        "originalKey": "4ca6a593-9ac9-4e2f-bc9a-8c8a1887ad41",
        "outputsInitialized": false,
        "showInput": false
      },
      "source": [
        "## More resources\n",
        "For more information, please see our [dlrm](https://github.com/facebookresearch/dlrm/tree/main/torchrec_dlrm/) example, which includes multinode training on the criteo terabyte dataset, using Meta’s [DLRM](https://arxiv.org/abs/1906.00091)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "captumWidgetMessage": [],
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "custom": {
      "cells": [],
      "metadata": {
        "accelerator": "GPU",
        "colab": {
          "background_execution": "on",
          "collapsed_sections": [],
          "machine_shape": "hm",
          "name": "Torchrec Introduction.ipynb",
          "provenance": []
        },
        "fileHeader": "",
        "fileUid": "c9a29462-2509-4adb-a539-0318cf56bb00",
        "interpreter": {
          "hash": "d4204deb07d30e7517ec64733b2d65f24aff851b061e21418071854b06459363"
        },
        "isAdHoc": false,
        "kernelspec": {
          "display_name": "Python 3.7.13 ('torchrec': conda)",
          "language": "python",
          "name": "python3"
        },
        "language_info": {
          "codemirror_mode": {
            "name": "ipython",
            "version": 3
          },
          "file_extension": ".py",
          "mimetype": "text/x-python",
          "name": "python",
          "nbconvert_exporter": "python",
          "pygments_lexer": "ipython3",
          "version": "3.7.13"
        }
      },
      "nbformat": 4,
      "nbformat_minor": 0
    },
    "fileHeader": "",
    "fileUid": "601082c5-2094-4e06-9d1c-96e87cce2799",
    "indentAmount": 2,
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "torchrec",
      "language": "python",
      "name": "bento_kernel_torchrec"
    },
    "language_info": {
      "name": "python"
    },
    "last_base_url": "https://bento.edge.x2p.facebook.net/",
    "last_kernel_id": "b6fe1a08-1d4d-40cd-afe6-8352c4e42d25",
    "last_msg_id": "c02547e3-e4c072dc430f066c4d18479a_594",
    "last_server_session_id": "e11f329f-b395-4702-9b33-449716ea422e",
    "outputWidgetContext": []
  }
}
